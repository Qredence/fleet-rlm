<!-- Chunk 1784: bytes 7440250-7443997, type=function -->
def optimize_with_tracking(
    program: LegacySkillCreationProgram,
    trainset_path: str | Path = "config/training/trainset.json",
    output_path: str | Path = "config/optimized/tracked/",
    optimizer_type: Literal["miprov2", "gepa"] = "miprov2",
    model: str = DEFAULT_MODEL,
    experiment_name: str = "skills-fleet-optimization",
    **optimizer_kwargs,
) -> LegacySkillCreationProgram:
    """
    Optimize with MLflow tracking enabled.

    Requires: uv add "mlflow>=2.21.1"

    Args:
        program: Program to optimize.
        trainset_path: Path to training data.
        output_path: Output directory.
        optimizer_type: Which optimizer to use. Supported values:
            - "miprov2": delegates to :func:`optimize_with_miprov2`.
            - "gepa": delegates to :func:`optimize_with_gepa`.
        model: Approved model name to use for optimization.
        experiment_name: MLflow experiment name.
        **optimizer_kwargs: Additional keyword arguments forwarded directly to
            the underlying optimizer selected by ``optimizer_type``. Common
            options include (but are not limited to):

            For ``optimizer_type="miprov2"`` (see :func:`optimize_with_miprov2`):
                - num_candidates (int): Number of candidate programs per round.
                - num_iterations (int): Number of MIPROv2 optimization rounds.
                - max_bootstrapped_demos (int): Max bootstrapped demos to use.
                - max_labeled_demos (int): Max labeled demos to use.

            For ``optimizer_type="gepa"`` (see :func:`optimize_with_gepa`):
                - num_generations (int): Number of GEPA evolution generations.
                - population_size (int): Number of programs per generation.
                - reflection_model (str): Model used for reflective feedback.

            Any unsupported keyword arguments will be passed through and may
            raise a ``TypeError`` in the underlying optimizer.

    Returns:
        Optimized program.

    """
    try:
        import mlflow
    except ImportError:
        logger.warning("MLflow not installed. Running without tracking.")
        if optimizer_type == "miprov2":
            return optimize_with_miprov2(
                program, trainset_path, output_path, model, **optimizer_kwargs
            )
        else:
            return optimize_with_gepa(
                program, trainset_path, output_path, model, **optimizer_kwargs
            )

    # Enable MLflow autologging for DSPy
    mlflow.dspy.autolog(
        log_compiles=True,
        log_evals=True,
        log_traces_from_compile=True,
    )

    mlflow.set_experiment(experiment_name)
    logger.info(f"MLflow experiment: {experiment_name}")

    with mlflow.start_run():  # type: ignore[attr-defined]
        # Log configuration
        mlflow.log_params(  # type: ignore[attr-defined]
            {
                "optimizer": optimizer_type,
                "model": model,
                "trainset": str(trainset_path),
            }
        )

        # Run optimization
        if optimizer_type == "miprov2":
            optimized = optimize_with_miprov2(
                program, trainset_path, output_path, model, **optimizer_kwargs
            )
        else:
            optimized = optimize_with_gepa(
                program, trainset_path, output_path, model, **optimizer_kwargs
            )

        # Log the optimized model
        mlflow.dspy.log_model(optimized, "optimized_skill_creator")  # type: ignore[attr-defined]

    return optimized


# =============================================================================
# Quick Evaluation
# =============================================================================


