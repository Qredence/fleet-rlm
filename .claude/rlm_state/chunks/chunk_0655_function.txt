<!-- Chunk 655: bytes 1037073-1040362, type=function -->
def debug_metric(example, pred, trace=None):
    score = your_metric(example, pred, trace)
    print(f"Metric score: {score:.3f} for prediction: {pred}")
    return score

# Should see variation in scores (not all 0.0 or all 1.0)
```

✅ **Solution**: Fix metric to provide gradient (range of scores)

**2. Training Data Too Similar**
```bash
# Check diversity
jq '[.[].task_description] | unique | length' config/training/trainset_v4.json

# Should be close to total count (little duplication)
```

✅ **Solution**: Add more diverse examples

**3. Program Already Optimal**
- Baseline score >0.85 means program is already good
- Diminishing returns after certain point

✅ **Solution**: Focus on other improvements (performance, monitoring)

## MLflow Warnings

### Symptom
```
warning[possibly-missing-attribute]: Member `log_params` may be missing on module `mlflow`
```

### Solution
**These are expected** - MLflow is an optional dependency. Warnings are safe to ignore if:
- You don't plan to use MLflow tracking
- The count is exactly 11 warnings (all from mlflow_logger.py)

To eliminate warnings:
```bash
# Install MLflow
uv pip install mlflow
```

Or suppress warnings:
```python
# Add type ignore comment
import mlflow  # type: ignore[import-untyped]
```

## Getting Help

**Check logs**:
```bash
# API server logs
tail -f logs/skill-fleet.log

# Background job logs
grep "optimization" logs/skill-fleet.log
```

**Enable debug logging**:
```python
import logging
logging.getLogger("skill_fleet.core.dspy").setLevel(logging.DEBUG)
```

**Run comprehensive tests**:
```bash
uv run python scripts/test_phase_implementation.py
```

**Check DSPy status**:
```python
import dspy
print(f"DSPy version: {dspy.__version__}")
print(f"Configured LM: {dspy.settings.lm}")
```


============================================================
END FILE: .fleet/skills/dspy-optimization-workflow/references/troubleshooting.md
============================================================

============================================================
FILE: .fleet/skills/dspy-optimization-workflow/scripts/quick_optimize.py
============================================================

#!/usr/bin/env python3
"""Quick optimization script with sensible defaults.

Simplified wrapper around DSPy optimization for common use cases.

Usage:
    # GEPA optimization (fast)
    ./scripts/quick_optimize.py --trainset config/training/trainset_v4.json --optimizer gepa
    
    # MIPROv2 optimization (better quality)
    ./scripts/quick_optimize.py --trainset config/training/trainset_v4.json --optimizer miprov2 --auto medium
    
    # With custom output path
    ./scripts/quick_optimize.py --trainset config/training/trainset_v4.json --output config/optimized/my_program.pkl
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from pathlib import Path

import dspy

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from skill_fleet.core.dspy.metrics.enhanced_metrics import comprehensive_metric
from skill_fleet.core.optimization.optimizer import get_lm

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


