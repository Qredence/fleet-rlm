<!-- Chunk 1254: bytes 4673269-4674813, type=function -->
def benchmark_miprov2(
    trainset: list[dspy.Example],
    testset: list[dspy.Example],
) -> dict:
    """Benchmark MIPROv2."""
    print("\n" + "=" * 70)
    print("ðŸ”´ MIPROV2 - Bayesian Optimization (Light)")
    print("=" * 70)

    start_time = time.time()

    # Configure LM with usage tracking
    lm = get_lm("gemini-3-flash-preview", temperature=1.0)
    dspy.configure(lm=lm, track_usage=True)

    # Create program
    program = SimpleSkillProgram()

    # Baseline
    baseline = evaluate_program(program, testset, simple_metric)
    print(f"Baseline score: {baseline:.1%}")

    # Optimize
    logger.info("Running MIPROv2 optimization (auto=light)...")
    optimizer = dspy.MIPROv2(metric=simple_metric, auto="light", num_threads=4)
    optimized = optimizer.compile(
        program,
        trainset=trainset,
        max_bootstrapped_demos=2,
        max_labeled_demos=1,
    )

    # Test
    optimized_score = evaluate_program(optimized, testset, simple_metric)

    elapsed = time.time() - start_time
    improvement = optimized_score - baseline

    print(f"Optimized score: {optimized_score:.1%}")
    print(f"Improvement: {improvement:+.1%}")
    print(f"Time: {elapsed:.1f}s")

    return {
        "optimizer": "MIPROv2 (Light)",
        "baseline": baseline,
        "optimized": optimized_score,
        "improvement": improvement,
        "improvement_pct": improvement / baseline * 100 if baseline > 0 else 0,
        "time_seconds": elapsed,
        "cost_estimate": "$5-10 (LLM calls for optimization)",
    }


