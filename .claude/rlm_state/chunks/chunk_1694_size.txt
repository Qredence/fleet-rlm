<!-- Chunk 1694: bytes 6722516-6872516, type=size -->
def json_serialize(
    value: Any,
    *,
    indent: int = 2,
    default: Any = "",
    ensure_list: bool = False,
) -> str | list | dict:
    """
    Serialize value to JSON string if it's a list or dict, otherwise return as-is.

    This helper reduces code duplication across DSPy modules that need to pass
    structured data to LLMs as JSON strings while also accepting pre-serialized
    string values.

    Args:
        value: The value to serialize (list, dict, or already-serialized string)
        indent: JSON indentation level (default: 2)
        default: Value to return if input is None or empty (default: "")
        ensure_list: If True, ensure result is a list (for Pydantic model lists)

    Returns:
        JSON string if value is a list/dict, otherwise the original value

    Examples:
        >>> json_serialize([{"a": 1}])
        '[\\n  {\\n    "a": 1\\n  }\\n]'
        >>> json_serialize("already json")
        'already json'
        >>> json_serialize(None)
        ''

    """
    if value is None:
        return default

    if ensure_list and isinstance(value, list):
        # Handle lists of Pydantic models
        return [item.model_dump() if hasattr(item, "model_dump") else item for item in value]

    if isinstance(value, (list, dict)):
        return json.dumps(value, indent=indent)

    return value


============================================================
END FILE: src/skill_fleet/common/utils.py
============================================================

============================================================
FILE: src/skill_fleet/config/config.yaml
============================================================

# config.yaml - Single source of truth for `skills-fleet` LLM configuration
#
# Default model: gemini/gemini-3-flash-preview (LiteLLM format for Gemini 3 Flash)
#
# Required env:
#   - GOOGLE_API_KEY
#   - LITELLM_API_KEY
#
# Optional env:
#   - DSPY_TEMPERATURE (override temperature globally)
#
# LiteLLM v1.80.8-stable.1+ required for Gemini 3 Flash features

dspy:
  adapter: chat

models:
  default: gemini/gemini-3-flash-preview

  registry:
    gemini/gemini-3-flash-preview:
      model: gemini-3-flash-preview
      model_type: chat
      env: GOOGLE_API_KEY
      env_fallback: LITELLM_API_KEY
      timeout: 60
      parameters:
        temperature: 1.0
        max_tokens: 8192

    gemini/gemini-3-pro-preview:
      model: gemini-3-pro-preview
      model_type: chat
      env: GOOGLE_API_KEY
      env_fallback: LITELLM_API_KEY
      timeout: 120
      parameters:
        temperature: 1.0  # Gemini 3 models require temperature=1.0 per documentation
        max_tokens: 16384

roles:
  router:
    model: gemini/gemini-3-flash-preview
    description: "Routes requests and selects workflow patterns"
    capabilities: [pattern_detection, team_selection, complexity_assessment]
    parameter_overrides:
      reasoning_effort: high

  planner:
    model: gemini/gemini-3-flash-preview
    description: "Creates detailed plans and orchestrates skill selection"
    capabilities: [task_decomposition, skill_orchestration, dependency_analysis]
    parameter_overrides: {}

  worker:
    model: gemini/gemini-3-flash-preview
    description: "Executes work steps"
    capabilities: [file_operations, skill_execution, content_generation]
    parameter_overrides: {}

  judge:
    model: gemini/gemini-3-flash-preview
    description: "Evaluates results and validates completion quality"
    capabilities: [quality_assessment, validation, critique_generation]
    parameter_overrides: {}

tasks:
  # Skill Creation Workflow (6-step process)
  skill_understand:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: medium

  skill_plan:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: high

  skill_initialize:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: high

  skill_edit:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: high

  skill_package:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: medium

  skill_validate:
    model: gemini/gemini-3-flash-preview
    role: judge
    parameters:
      reasoning_effort: high

  # Conversational Agent (Interactive CLI)
  conversational_agent:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: high  # High thinking for complex reasoning in conversation

  # Evaluation & Optimization Tasks
  skill_evaluate:
    model: gemini/gemini-3-flash-preview
    role: judge
    parameters:
      temperature: 1.0  # Keep 1.0 for Gemini 3 models
      # Note: reasoning_effort removed - not supported by Gemini via LiteLLM

  skill_optimize:
    model: gemini/gemini-3-flash-preview  # Using flash for reliability
    role: judge
    parameters:
      temperature: 1.0  # Gemini 3 models require temperature=1.0
      # Note: reasoning_effort removed - not supported by Gemini via LiteLLM

# Optimization Configuration
optimization:
  # Default optimizer to use
  default_optimizer: miprov2

  # MIPROv2 optimizer settings
  miprov2:
    auto: "medium"  # Balance between optimization depth and cost (light/medium/heavy)
    num_threads: 4
    max_bootstrapped_demos: 4
    max_labeled_demos: 4
    verbose: true

  # BootstrapFewShot optimizer settings
  bootstrap_fewshot:
    max_bootstrapped_demos: 4
    max_labeled_demos: 4
    max_rounds: 1
    max_errors: 5

  # Training data paths
  training:
    gold_skills_path: "config/training/gold_skills.json"
    quality_criteria_path: "config/training/quality_criteria.yaml"
    optimized_programs_dir: "config/optimized"

# Evaluation Configuration
evaluation:
  # Number of threads for parallel evaluation
  num_threads: 8
  display_progress: true
  display_table: true

  # Quality thresholds
  thresholds:
    minimum_quality: 0.6
    target_quality: 0.8
    excellent_quality: 0.9

  # Metrics weights for overall score
  metric_weights:
    pattern_count: 0.15
    has_anti_patterns: 0.10
    has_key_insights: 0.10
    has_real_world_impact: 0.10
    has_quick_reference: 0.10
    has_common_mistakes: 0.10
    has_red_flags: 0.05
    frontmatter_completeness: 0.15
    code_examples_quality: 0.15


============================================================
END FILE: src/skill_fleet/config/config.yaml
============================================================

============================================================
FILE: src/skill_fleet/config/optimized/miprov2/metadata.json
============================================================

{
  "dependency_versions": {
    "python": "3.13",
    "dspy": "3.1.0",
    "cloudpickle": "3.1"
  }
}


============================================================
END FILE: src/skill_fleet/config/optimized/miprov2/metadata.json
============================================================

============================================================
FILE: src/skill_fleet/config/optimized/skill_creator_bootstrap_v1.json
============================================================

{
  "phase1.gather_requirements.gather.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      }
    ],
    "signature": {
      "instructions": "Initial requirements gathering from task description.\n\nExtract basic requirements before detailed analysis:\n- What domain/category?\n- What level (beginner/intermediate/advanced)?\n- What specific topics to cover?\n- Any constraints or preferences?",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description (may include clarifications)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Domain:",
          "description": "Primary domain: 'technical', 'cognitive', 'domain_knowledge', etc."
        },
        {
          "prefix": "Category:",
          "description": "Category within domain: 'programming', 'devops', 'data_science', etc."
        },
        {
          "prefix": "Target Level:",
          "description": "Target level: 'beginner', 'intermediate', 'advanced', 'expert'"
        },
        {
          "prefix": "Topics:",
          "description": "List of specific topics to cover (3-7 items)"
        },
        {
          "prefix": "Constraints:",
          "description": "Any constraints or preferences (e.g., 'focus on Python 3.12+', 'no deprecated patterns')"
        },
        {
          "prefix": "Ambiguities:",
          "description": "Detected ambiguities that need clarification via HITL"
        }
      ]
    },
    "lm": null
  },
  "phase1.analyze_intent.analyze.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Deeply analyze user intent to understand what skill is needed.\n\nThis is one of three parallel analyses in Phase 1. Focus on:\n- WHY is this skill needed?\n- WHAT problem does it solve?\n- WHO is the target user?\n- WHAT value does it provide?\n\nUse chain-of-thought reasoning for thorough analysis.",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description with any clarifications"
        },
        {
          "prefix": "User Context:",
          "description": "JSON user context (user_id, existing skills, preferences)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Task Intent:",
          "description": "Structured intent with: purpose, problem_statement, target_audience, value_proposition"
        },
        {
          "prefix": "Skill Type:",
          "description": "Type of skill: 'how_to', 'reference', 'concept', 'workflow', 'checklist'"
        },
        {
          "prefix": "Scope:",
          "description": "Scope description: what's included and excluded"
        },
        {
          "prefix": "Success Criteria:",
          "description": "How will we know this skill is successful? (3-5 criteria)"
        }
      ]
    },
    "lm": null
  },
  "phase1.find_taxonomy.find_path.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      }
    ],
    "signature": {
      "instructions": "Determine optimal taxonomy placement for this skill.\n\nThis is one of three parallel analyses in Phase 1. Analyze the\ntaxonomy structure and find the best location for this skill.\n\nRules:\n- Prefer deeper paths (more specific is better)\n- Consider existing skills in similar categories\n- Follow taxonomy naming conventions\n- Avoid creating new top-level categories",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description"
        },
        {
          "prefix": "Taxonomy Structure:",
          "description": "JSON representation of full taxonomy structure"
        },
        {
          "prefix": "Existing Skills:",
          "description": "List of existing skill paths for reference"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Recommended Path:",
          "description": "Recommended taxonomy path (e.g., 'technical_skills/programming/python/async')"
        },
        {
          "prefix": "Alternative Paths:",
          "description": "2-3 alternative paths if primary has issues"
        },
        {
          "prefix": "Path Rationale:",
          "description": "Why this path is optimal (mention similar skills, category fit, etc.)"
        },
        {
          "prefix": "New Directories:",
          "description": "Any new directories that need to be created (empty if using existing path)"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence in path selection 0-1. <0.7 means may need user confirmation"
        }
      ]
    },
    "lm": null
  },
  "phase1.analyze_dependencies.analyze": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Analyze skill dependencies and prerequisites.\n\nThis is one of three parallel analyses in Phase 1. Determine:\n- What skills must user know first? (prerequisites)\n- What skills complement this one? (related skills)\n- What skills might conflict? (conflicts)",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description"
        },
        {
          "prefix": "Task Intent:",
          "description": "Analyzed task intent (from AnalyzeIntent)"
        },
        {
          "prefix": "Taxonomy Path:",
          "description": "Recommended taxonomy path (from FindTaxonomyPath)"
        },
        {
          "prefix": "Existing Skills:",
          "description": "JSON list of existing skills with metadata"
        },
        {
          "prefix": "Dependency Analysis:",
          "description": "Complete dependency analysis with: required, recommended, conflicts"
        },
        {
          "prefix": "Prerequisite Skills:",
          "description": "Skills user must know first (hard prerequisites)"
        },
        {
          "prefix": "Complementary Skills:",
          "description": "Skills that complement this one (soft recommendations)"
        },
        {
          "prefix": "Missing Prerequisites:",
          "description": "Prerequisites that don't exist yet (need to create first)"
        }
      ]
    },
    "lm": null
  },
  "phase1.synthesize.synthesize.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Synthesize all Phase 1 analyses into a coherent skill creation plan.\n\nCombine results from:\n- Intent analysis\n- Taxonomy path selection\n- Dependency analysis\n\nCreate a unified plan that guides Phase 2 (generation).\n\nThis signature uses dspy.Refine for iterative improvement.",
      "fields": [
        {
          "prefix": "Intent Analysis:",
          "description": "JSON TaskIntent from AnalyzeIntent"
        },
        {
          "prefix": "Taxonomy Analysis:",
          "description": "JSON taxonomy path and rationale from FindTaxonomyPath"
        },
        {
          "prefix": "Dependency Analysis:",
          "description": "JSON DependencyAnalysis from AnalyzeDependencies"
        },
        {
          "prefix": "User Confirmation:",
          "description": "User's confirmation or feedback from HITL checkpoint (may be empty on first pass)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Skill Metadata:",
          "description": "Complete skill metadata: name, description, taxonomy_path, tags, etc."
        },
        {
          "prefix": "Content Plan:",
          "description": "Outline of skill content: sections, topics, example count, etc."
        },
        {
          "prefix": "Generation Instructions:",
          "description": "Specific instructions for Phase 2 generation (style, tone, depth, etc.)"
        },
        {
          "prefix": "Success Criteria:",
          "description": "How to evaluate if generated content is successful"
        },
        {
          "prefix": "Estimated Length:",
          "description": "Estimated skill length: 'short' (<500 lines), 'medium' (500-1500), 'long' (>1500)"
        }
      ]
    },
    "lm": null
  },
  "phase2.generate_content.generate.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      }
    ],
    "signature": {
      "instructions": "Generate complete SKILL.md content based on the plan.\n\nThis is the main content generation step. Create comprehensive,\nwell-structured skill documentation that follows agentskills.io format.\n\nRequirements:\n- YAML frontmatter at top (name in kebab-case, description)\n- Clear sections with headers\n- Code examples with explanations\n- Best practices and gotchas\n- Usage examples\n- Test cases where applicable\n\nThis signature is used with dspy.BestOfN to generate multiple\ncandidates and select the best one based on quality metrics.",
      "fields": [
        {
          "prefix": "Skill Metadata:",
          "description": "Complete skill metadata from Phase 1 synthesis"
        },
        {
          "prefix": "Content Plan:",
          "description": "Detailed content plan: sections, topics, example count"
        },
        {
          "prefix": "Generation Instructions:",
          "description": "Specific instructions for generation (style, tone, depth)"
        },
        {
          "prefix": "Parent Skills Content:",
          "description": "Content from parent skills for reference and consistency"
        },
        {
          "prefix": "Dependency Summaries:",
          "description": "Summaries of dependency skills (to reference appropriately)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Skill Content:",
          "description": "Complete SKILL.md content with YAML frontmatter, all sections, examples, and best practices"
        },
        {
          "prefix": "Usage Examples:",
          "description": "3-5 concrete usage examples showing how to use this skill"
        },
        {
          "prefix": "Best Practices:",
          "description": "5-10 best practices and gotchas"
        },
        {
          "prefix": "Test Cases:",
          "description": "Test cases to verify skill understanding (if applicable)"
        },
        {
          "prefix": "Estimated Reading Time:",
          "description": "Estimated reading time in minutes"
        }
      ]
    },
    "lm": null
  },
  "phase2.incorporate_feedback.incorporate.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming 