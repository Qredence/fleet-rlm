<!-- Chunk 2119: bytes 8045331-8046485, type=function -->
def test_get_trainset_filtering(temp_training_dir):
    """Test filtering logic."""
    manager = TrainingDataManager(temp_training_dir)

    # Mock metadata
    import hashlib

    def get_id(task):
        return hashlib.md5(task.encode()).hexdigest()

    id1 = get_id("Task 1")
    id2 = get_id("Task 2")

    manager._metadata = {
        id1: ExampleMetadata(
            example_id=id1,
            task_description="Task 1",
            category="technical",
            quality_score=0.9,
            success_rate=1.0,
        ),
        id2: ExampleMetadata(
            example_id=id2,
            task_description="Task 2",
            category="domain",
            quality_score=0.1,  # Low score
            success_rate=0.0,
        ),
    }

    # Test with default config
    examples = manager.get_trainset()
    # Should include Task 1 (high score) and Task 3 (neutral/new), but maybe exclude Task 2
    # Task 3 is new, so score 0.5. Task 2 score approx 0.06 < 0.7 default threshold

    tasks = [ex["task_description"] for ex in examples]
    assert "Task 1" in tasks
    assert "Task 3" in tasks
    assert "Task 2" not in tasks


