<!-- Chunk 1781: bytes 7434564-7438358, type=function -->
def optimize_with_gepa(
    program: LegacySkillCreationProgram,
    trainset_path: str | Path = "config/training/trainset.json",
    output_path: str | Path = "config/optimized/gepa/",
    model: str = DEFAULT_MODEL,
    reflection_model: str = REFLECTION_MODEL,
    auto: Literal["light", "medium", "heavy"] = "medium",
    track_stats: bool = True,
) -> LegacySkillCreationProgram:
    """
    Optimize skill creation workflow with GEPA.

    GEPA (Genetic-Pareto Reflective Prompt Optimizer) uses:
    - Reflective mutation based on LLM traces
    - Pareto frontier for multi-objective optimization
    - Textual feedback for improvement

    Args:
        program: LegacySkillCreationProgram to optimize
        trainset_path: Path to training data JSON
        output_path: Directory to save optimized program
        model: Approved model name for program execution
        reflection_model: Model for GEPA reflection (should be strong)
        auto: Optimization intensity
        track_stats: Whether to track detailed statistics

    Returns:
        Optimized LegacySkillCreationProgram

    """
    from .evaluation import load_trainset, skill_creation_metric, split_dataset

    # Configure with approved model and LM usage tracking
    lm = get_lm(model)
    dspy.configure(lm=lm, track_usage=True)
    logger.info(f"Configured DSPy with model: {model} (track_usage enabled)")

    # Get reflection LM (stronger model for analysis)
    reflection_lm = get_lm(reflection_model, temperature=1.0)
    logger.info(f"Using reflection model: {reflection_model}")

    # Use TrainingDataManager if available
    trainset_manager = TrainingDataManager(Path(trainset_path).parent)
    filtered_examples = trainset_manager.get_trainset()

    if filtered_examples:
        logger.info(f"Using {len(filtered_examples)} filtered examples from TrainingDataManager")
        examples = [dspy.Example(**ex).with_inputs("task_description") for ex in filtered_examples]
    else:
        logger.info(f"Loading full trainset from {trainset_path}")
        examples = load_trainset(trainset_path)

    train, val = split_dataset(examples, train_ratio=0.8)
    logger.info(f"Loaded {len(examples)} examples: {len(train)} train, {len(val)} val")

    # Configure GEPA optimizer
    # GEPA expects a GEPAFeedbackMetric-compatible callable. We provide a small
    # adapter instead of using a broad Any cast to keep type checking intact.
    def _gepa_metric_adapter(*args: Any, **kwargs: Any) -> Any:
        """
        Adapter to use `skill_creation_metric` with GEPA.

        This avoids disabling type checking via a broad Any cast.
        """
        return skill_creation_metric(*args, **kwargs)

    optimizer = dspy.GEPA(
        metric=_gepa_metric_adapter,
        reflection_lm=reflection_lm,
        auto=auto,
        track_stats=track_stats,
    )

    logger.info(f"Starting GEPA optimization (auto={auto})...")

    # Wrap program for optimization to handle missing context
    wrapped_program = OptimizationWrapper(program)

    # Run optimization
    optimized_wrapper = optimizer.compile(
        wrapped_program,
        trainset=train,
        valset=val,
    )

    # Extract optimized program
    optimized = optimized_wrapper.program

    # Save optimized program as JSON state (no cloudpickle) for safer loading
    output_path = Path(output_path)
    output_path.mkdir(parents=True, exist_ok=True)
    state_path = output_path / STATE_FILENAME
    optimized.save(str(state_path), save_program=False)

    logger.info(f"Optimized program state saved to {state_path}")
    return optimized


# =============================================================================
# Load/Save Utilities
# =============================================================================


