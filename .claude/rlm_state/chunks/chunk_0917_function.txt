<!-- Chunk 917: bytes 3315783-3344974, type=function -->
def _render_questions(questions: object) -> str:
    """Render questions to a displayable string."""
    if isinstance(questions, str):
        return questions
    if isinstance(questions, list):
        lines = []
        for idx, q in enumerate(questions, 1):
            if isinstance(q, dict):
                text = q.get("question") or q.get("text") or str(q)
            else:
                text = str(q)
            lines.append(f"{idx}. {text}")
        return "\n".join(lines)
    return str(questions or "")
```

## Usage Examples

### In Create Command

```python
from skill_fleet.cli.hitl.runner import run_hitl_job

async def _run():
    job_id = await client.create_skill(task, user_id)

    prompt_data = await run_hitl_job(
        console=console,
        client=client,
        job_id=job_id,
        auto_approve=False,
    )

    if prompt_data["status"] == "completed":
        console.print("Skill created successfully!")
```

### In Chat Command

```python
while True:
    result = await client.create_skill(task_description, user_id)
    job_id = result["job_id"]

    prompt_data = await run_hitl_job(
        console=console,
        client=client,
        job_id=job_id,
        auto_approve=auto_approve,
    )

    # Ask if user wants to create another
    again = Prompt.ask("Create another skill? (y/n)")
    if again != "y":
        break
```

### With Auto-Approve

```python
# For CI/CD or automation
prompt_data = await run_hitl_job(
    console=console,
    client=client,
    job_id=job_id,
    auto_approve=True,  # Skip all prompts
)
```

## Terminal States

The runner returns when the job reaches one of these states:

| State         | Meaning                    | Contains                      |
| ------------- | -------------------------- | ----------------------------- |
| **completed** | Skill created successfully | `skill_content`, `saved_path` |
| **failed**    | Job failed                 | `error` message               |
| **cancelled** | User cancelled             | Empty result                  |

## Error Handling

```python
try:
    prompt_data = await run_hitl_job(
        console=console,
        client=client,
        job_id=job_id,
    )
except httpx.HTTPStatusError as e:
    console.print(f"[red]HTTP Error: {e.response.status_code}[/red]")
except TimeoutError:
    console.print("[red]HITL interaction timed out[/red]")
except Exception as e:
    console.print(f"[red]Unexpected error: {type(e).__name__}: {e}[/red]")
```

## Rich Panel Styling

| Interaction         | Border Style | Icon | Color  |
| ------------------- | ------------ | ---- | ------ |
| **Clarify**         | `yellow`     | ðŸ¤”   | Yellow |
| **Confirm**         | `cyan`       | ðŸ“‹   | Cyan   |
| **Preview**         | `blue`       | ðŸ“   | Blue   |
| **Validate (pass)** | `green`      | âœ…   | Green  |
| **Validate (fail)** | `red`        | âš ï¸   | Red    |

## Performance Considerations

| Setting           | Effect                              | Recommendation        |
| ----------------- | ----------------------------------- | --------------------- |
| **Poll interval** | Lower = faster response, higher CPU | 2.0 seconds (default) |
| **Timeout**       | How long to wait for user           | 3600 seconds (1 hour) |
| **Auto-approve**  | Skips polling entirely              | Use for CI/CD only    |

## Testing

```python
import pytest
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_run_hitl_job_completed():
    """Test runner with completed job."""
    client = AsyncMock()
    client.get_hitl_prompt.return_value = {
        "status": "completed",
        "skill_content": "Generated content"
    }

    result = await run_hitl_job(
        console=console,
        client=client,
        job_id="test-job-id",
    )

    assert result["status"] == "completed"
    assert result["skill_content"] == "Generated content"

@pytest.mark.asyncio
async def test_run_hitl_job_with_clarify():
    """Test runner with clarify interaction."""
    client = AsyncMock()
    client.get_hitl_prompt.side_effect = [
        {"status": "pending_hitl", "type": "clarify", "questions": ["What?"]},
        {"status": "running"},
        {"status": "completed"}
    ]
    client.post_hitl_response.return_value = {"status": "accepted"}

    # Patch Rich Prompt to avoid interactive prompt
    with patch('skill_fleet.cli.hitl.runner.Prompt.ask', return_value="answer"):
        result = await run_hitl_job(
            console=console,
            client=client,
            job_id="test-job-id",
        )

    assert result["status"] == "completed"
```

## See Also

- **[HITL Overview](index.md)** - System overview
- **[Callbacks Documentation](callbacks.md)** - Callback interface
- **[Interactions Documentation](interactions.md)** - Interaction types
- **[CLI Interactive Chat](../cli/interactive-chat.md)** - Chat mode usage


============================================================
END FILE: docs/hitl/runner.md
============================================================

============================================================
FILE: docs/index.md
============================================================

# Skills Fleet Documentation

Welcome to the Skills Fleet documentation hub. This index provides quick access to all documentation for the agentic capability platform.

```markdown
# Skills Fleet Documentation

Version: Post-FastAPI-Centric Restructure
Last updated: 2026-01-27

This hub focuses on concise, role-oriented guides. The canonical, consolidated guides live under `docs/guides/` and deep technical references under `docs/reference/`.

## Quick start

- Getting started (installation & first skill): `docs/getting-started/index.md`
- API (production): `docs/guides/api.md`
- CLI quick reference: `docs/guides/cli.md`
- Workflows & HITL: `docs/guides/workflows.md`, `docs/guides/hitl.md`
- DSPy & optimization: `docs/guides/dspy.md` and `docs/dspy/`

## Navigate by role

### For users

- `docs/getting-started/index.md` â€” set up, create and promote skills
- `docs/guides/cli.md` â€” common commands and interactive chat
- `docs/guides/api.md` â€” programmatic workflows (v2 production API)

### For integrators / CI

- Use the v2 job endpoints (`/api/v2`) for reliable, async integrations
- Export XML: `uv run skill-fleet generate-xml -o available_skills.xml`

### For developers

- Architecture: `docs/architecture/`
- Contributor setup & guides: `docs/development/CONTRIBUTING.md`
- DSPy internals: `docs/dspy/`

## Legacy & detailed references

If you need detailed endpoint references or historical docs, see the legacy folder:

- `docs/archive/LEGACY_README.md` â€” pointers to archived docs
- Detailed API endpoints & schemas: `docs/api/` (kept for reference)

## Restructuring plan

Full restructuring rationale and implementation plan: `docs/DOCUMENTATION_RESTRUCTURING_PLAN.md`

If something you expect to find is missing, tell me which page and I will merge it into the appropriate consolidated guide.
```

- Detailed API endpoints & schemas: `docs/api/` (kept for reference)


============================================================
END FILE: docs/index.md
============================================================

============================================================
FILE: docs/internal/CODE_REVIEW_2026_01.md
============================================================

# Code Review Report - 2026-01-29

## Executive Summary

This review focused on the security and architecture of the `skill-fleet` codebase, specifically the `v0.5` restructure. The audit covered path sanitization, configuration management, and API boundaries.

**Overall Status**: âœ… **PASSED** (with minor optimizations)

The codebase demonstrates a strong security posture with robust defenses against common vulnerabilities like path traversal and secret leakage. The architecture follows a clean separation of concerns.

## 1. Security Audit

### 1.1 Path Traversal & File System Access

**Status**: Secure
**Findings**:

- **Sanitization**: `src/skill_fleet/common/security.py` implements a strict whitelist-based sanitization (`sanitize_taxonomy_path`), allowing only alphanumeric characters, underscores, and hyphens. This effectively neutralizes injection vectors.
- **Traversal Prevention**: The `resolve_path_within_root` function correctly utilizes `os.path.commonpath` to verify that resolved paths remain within the intended root directory. This protects against `../` attacks and symlink exploits.
- **TOCTOU Protection**: `resolve_skill_md_path` uses `resolve(strict=True)` to ensure atomic verification of file existence.

### 1.2 Configuration & Secrets

**Status**: Secure
**Findings**:

- **Secret Isolation**: Secrets are **not** stored in `config.yaml`. The configuration only references environment variable names (e.g., `env: GOOGLE_API_KEY`).
- **Runtime Injection**: The `ModelConfig` loader retrieves values from `os.environ` only at runtime. This follows 12-factor app best practices.

### 1.3 API Security

**Status**: Good
**Findings**:

- **CORS**: Strict CORS policies are enforced in `factory.py`.
- **Input Validation**: Pydantic models in `src/skill_fleet/api/schemas` provide strong typing and validation for request payloads.

## 2. Architecture Review

### 2.1 Domain Logic Separation

**Status**: Excellent
**Findings**:

- **Service Layer**: `SkillService` (`src/skill_fleet/api/services/skill_service.py`) correctly encapsulates business logic, isolating the API controllers (`src/skill_fleet/api/v1/`) from the domain model.
- **Taxonomy Management**: The `TaxonomyManager` abstracts disk I/O and logical organization, allowing the rest of the application to work with skill IDs rather than raw paths.

### 2.2 Improvements Implemented

During this review, the following optimization was applied:

- **Refactored `update_skill` endpoint**: Removed redundant instantiation of `TaxonomyManager` in `api/v1/skills.py`. The endpoint now reuses the initialized manager from `SkillService`.

## 3. Recommendations

1.  **Standardize Error Handling**: Some sanitization functions return `None` on failure. Ensure all callers explicitly handle this case to avoid `TypeError` or unexpected behavior. Consider raising specific `SecurityException`s instead of returning `None` for clearer audit trails.
2.  **Deprecate Legacy Support**: The "polyfill strategy" in `TaxonomyManager` adds complexity. Plan a migration to fully rely on the `TaxonomyIndex` and remove the filesystem fallback in a future 1.0 release.
3.  **Strict Path Types**: Consider using a custom Pydantic type for `TaxonomyPath` in API schemas to enforce sanitization at the edge (API boundary) rather than deep in the call stack.


============================================================
END FILE: docs/internal/CODE_REVIEW_2026_01.md
============================================================

============================================================
FILE: docs/internal/plans/README.md
============================================================

# Plans Directory

This directory contains planning documents for the Skills Fleet project.

**Note:** This directory is excluded from git (see .gitignore) to keep planning documentation local-only.

## Directory Structure

```
plans/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ archive/                            # Completed/legacy plans
â”œâ”€â”€ future/                             # Future exploration plans
â””â”€â”€ [active plans]                      # Current work-in-progress plans
```

## Active Plans

| File                                          | Description                                           | Status              |
|-----------------------------------------------|-------------------------------------------------------|---------------------|
| `plan-main-restructure-latest.md`             | Main restructure plan (task-based DSPy organization)  | Active âœ…           |
| `EXEC-0.2-optimizer-auto-selection.md`        | DSPy optimizer auto-selection strategy                 | Reference           |
| `technical-debt-audit.md`                     | Technical debt inventory and prioritization            | Reference           |
| `cleanup-and-optimization-plan.md`            | Code deduplication and optimization                    | Partially Complete  |

## Recent Progress (2026-01-23)

### Completed Tasks âœ…

**Phase 1: Restructure DSPy Signatures by Task**
- âœ… Renamed signature directories from phase-based to task-based
- âœ… Created task-based subdirectories:
  - `task_analysis_planning/` (Phase 1)
  - `content_generation/` (Phase 2)
  - `quality_assurance/` (Phase 3)
  - `signature_optimization/` (Signature tuning)
- âœ… Renamed signature files:
  - `chat.py` â†’ `conversational_interface.py`
  - `hitl.py` â†’ `human_in_the_loop.py`

**Phase 2: Create Workflows Layer**
- âœ… Created `src/skill_fleet/workflows/` package
- âœ… Built 6 workflow orchestrators:
  - `TaskAnalysisOrchestrator` - Phase 1 understanding & planning
  - `ContentGenerationOrchestrator` - Phase 2 skill content creation
  - `QualityAssuranceOrchestrator` - Phase 3 validation & refinement
  - `HITLCheckpointManager` - HITL checkpoint management
  - `ConversationalOrchestrator` - Multi-turn conversation workflow
  - `SignatureTuningOrchestrator` - Signature optimization workflow

**Cleanup: Remove Duplicate Facade Layer**
- âœ… Removed `src/skill_fleet/dspy/` facade directory
- âœ… Removed `src/skill_fleet/compat/` compatibility layer
- âœ… Updated test imports to use new paths
- âœ… Fixed `test_core_rework.py` and `test_signature_reasoning_types.py`

**MLflow Integration Verification**
- âœ… Fixed `log_parameter()` function to support both 2-arg and 3-arg forms
- âœ… Verified all 6 workflow orchestrators have proper MLflow integration
- âœ… Tested MLflow logging with dual-form parameter support

**Configuration Files Review**
- âœ… Reviewed `config/config.yaml` - clean with proper task-model mapping
- âœ… Reviewed training data - properly versioned v2, v3, v4
- âœ… Reviewed `SKILL_md_template.md` - comprehensive agentskills.io compliant template

**Documentation Revamp**
- âœ… Archived outdated docs (PHASE_0_FOUNDATION.md, UPDATE_SUMMARY.md)
- âœ… Moved PHASE_1_OPTIMIZATION.md to docs/dspy/
- âœ… Reorganized top-level docs into proper categories:
  - ADAPTIVE_METRIC_WEIGHTING.md â†’ docs/dspy/
  - BACKGROUND_JOBS.md â†’ docs/architecture/
  - CLI_SYNC_COMMANDS.md â†’ docs/cli/
  - DATABASE_SYNC.md â†’ docs/architecture/
  - JOB_PERSISTENCE.md â†’ docs/architecture/
  - OPTIMIZER_SELECTION.md â†’ docs/dspy/optimization.md
  - STREAMING_ARCHITECTURE.md â†’ docs/architecture/
  - STREAMING_QUICKSTART.md â†’ docs/getting-started/
  - MLFLOW_SETUP.md â†’ docs/getting-started/
- âœ… Created comprehensive `docs/workflows/` documentation for all 6 orchestrators
- âœ… Updated `docs/index.md` with new structure and recent changes

### In Progress ðŸ”„

*No tasks currently in progress - all immediate cleanup tasks completed*

### Pending â³

See task list for full pending items:
- Phase 3: Separate Domain Logic (depends on workflows)
- Phase 4: Implement DSPy 3.1.2 Best Practices
- Phase 5: Wire FastAPI to Workflows
- Phase 6: Restructure CLI
- Update tests for new structure
- MLflow integration for skill creation

## Archived Plans

Plans in `./archive/` represent completed phases or legacy documentation:

| Category                | Examples                                      |
|-------------------------|-----------------------------------------------|
| Implementation phases  | `implementation-phase-*.md` (completed)      |
| CLI reviews            | `cli-*.md` (merged to codebase)               |
| Feature plans           | `skills-taxonomy-*.md` (implemented)          |
| Old restructure plans   | `plan-main-restructure.md` (superseded)       |

## Plan Naming Convention

- **Date-prefixed**: `YYYY-MM-DD-description.md` for time-sensitive plans
- **Feature-based**: `feature-name-plan.md` for ongoing features
- **Versioned**: `plan-name-version.md` for evolving plans (e.g., `latest`)

---
*Last updated: 2026-01-23*


============================================================
END FILE: docs/internal/plans/README.md
============================================================

============================================================
FILE: docs/internal/plans/archive/2026-01-09-fastapi-baseline-tests.md
============================================================

# FastAPI Production Patterns - Baseline Test Scenarios (RED Phase)

## Testing Methodology

For technique/reference skills, we test with:
- **Application scenarios:** Can agents apply the techniques correctly?
- **Variation scenarios:** Do they handle edge cases?
- **Missing information tests:** Do instructions have gaps?

These scenarios will be run WITHOUT the skill to document baseline behavior and common mistakes.

---

## Scenario 1: Database Lifecycle (Application)

**Prompt:** "Help me create a FastAPI app with SQLAlchemy async database. I need a `/users` endpoint that returns all users from PostgreSQL."

**Expected baseline failures:**
- Creating engine at import time (not in lifespan)
- Missing `engine.dispose()` in shutdown
- Not setting pool parameters
- Using global `db` variable instead of dependency injection

**Success criteria (WITH skill):**
- Engine created in lifespan context manager
- Proper shutdown with `engine.dispose()`
- Using `Depends(get_db)` pattern
- Pool parameters configured

---

## Scenario 2: Partial Update Endpoint (Application)

**Prompt:** "I have a User model with name, email, and age fields. Create a PATCH endpoint to update users that only updates the fields provided in the request."

**Expected baseline failures:**
- Not using `exclude_unset=True`
- Overwriting unprovided fields with `None`
- Not using Pydantic `Optional` fields
- Missing validation for partial updates

**Success criteria (WITH skill):**
- Using `Optional` fields in Pydantic model
- Using `update.dict(exclude_unset=True)`
- Only updating provided fields
- Proper 404 handling

---

## Scenario 3: Converting Sync Utility to Async (Application)

**Prompt:** "I have this sync function that fetches user data from our database and calls an external API. Convert it to a FastAPI endpoint: [provide sync function using requests and SQLAlchemy sync]"

**Expected baseline failures:**
- Keeping `requests` library (blocking)
- Using `run_in_executor` as band-aid
- Not converting to `AsyncSession`
- Missing `await` keywords
- Not using async-compatible libraries

**Success criteria (WITH skill):**
- Replace `requests` with `httpx.AsyncClient`
- Convert to `AsyncSession` pattern
- Proper `async/await` usage
- No blocking operations

---

## Scenario 4: Testing Async Endpoints (Application)

**Prompt:** "Write tests for my FastAPI user endpoints. I need to test GET, POST, and PATCH operations."

**Expected baseline failures:**
- Using `TestClient` (sync) instead of `AsyncClient`
- Not using `@pytest.mark.asyncio`
- Sync fixtures with async tests
- Tests passing in isolation but failing when run together
- Missing database rollback between tests

**Success criteria (WITH skill):**
- Using `httpx.AsyncClient`
- Proper async fixtures
- `@pytest.mark.asyncio` decorator
- Database isolation between tests

---

## Scenario 5: File Upload Processing (Variation)

**Prompt:** "I have a utility function that processes Excel files using pandas. Convert it to a FastAPI endpoint that accepts file uploads. The files can be up to 50MB."

**Expected baseline failures:**
- Loading entire file into memory first
- Not streaming the file
- Not validating file type/size
- No error handling for malformed files

**Success criteria (WITH skill):**
- Streaming file handling with `UploadFile`
- Not loading entire file into memory
- File validation
- Proper error handling

---

## Scenario 6: Complex Dependency Graph (Variation)

**Prompt:** "I need dependencies that depend on other dependencies. I have `get_current_user` that depends on `get_db`, and `verify_admin` that depends on `get_current_user`. How do I set this up?"

**Expected baseline failures:**
- Trying to chain dependencies manually
- Passing dependencies as function parameters
- Not understanding that FastAPI handles this automatically
- Creating unnecessary complexity

**Success criteria (WITH skill):**
- Understanding that FastAPI auto-resolves dependency trees
- Clean dependency chain using `Depends()`
- Proper type hints
- No manual dependency passing

---

## Scenario 7: Pydantic Validation with Computed Fields (Edge Case)

**Prompt:** "Create a user model where `full_name` is computed from `first_name` and `last_name`, but only `first_name` and `last_name` are stored in the database."

**Expected baseline failures:**
- Not using Pydantic `computed_field`
- Computed field not appearing in response
- Validation running on computed field
- Confusion between input and output models

**Success criteria (WITH skill):**
- Using `@computed_field` decorator
- Separate input/output models if needed
- Computed field in API response
- No validation issues

---

## Scenario 8: Background Task Error Handling (Edge Case)

**Prompt:** "I have a background task that processes payments. How do I handle errors in the task and update the user about failures?"

**Expected baseline failures:**
- Exceptions in background tasks being silently swallowed
- No way to communicate task status back to user
- Not using task status tracking
- Missing retry logic

**Success criteria (WITH skill):**
- Proper exception handling in background tasks
- Task status tracking (database or cache)
- User-facing status endpoint
- Retry mechanism or dead letter queue

---

## Scenario 9: Multiple Database Connections (Edge Case)

**Prompt:** "My app needs to connect to two databases - a primary PostgreSQL for writes and a read replica for reads. How do I set this up?"

**Expected baseline failures:**
- Creating two separate engines incorrectly
- Not managing two separate lifecycles
- Confusion about which dependency to use where
- Connection pool issues with multiple engines

**Success criteria (WITH skill):**
- Separate engines for read/write
- Proper lifespan management for both
- Clear dependency naming (`get_db_read`, `get_db_write`)
- Pool parameters for each

---

## Scenario 10: Converting Legacy Class-Based API (Complex)

**Prompt:** "I have a Flask app with class-based views. Each class has methods for get, post, put, delete. How do I convert this to FastAPI?"

**Expected baseline failures:**
- Trying to maintain class structure in FastAPI
- Not understanding FastAPI's function-based approach
- Mixing patterns incorrectly
- Losing functionality in conversion

**Success criteria (WITH skill):**
- Converting to function-based endpoints
- Proper `APIRouter` organization
- Maintaining all functionality
- Cleaner FastAPI-idiomatic code

---

## Running the Baseline Tests

To run these scenarios and document failures:

```bash
# For each scenario, create a fresh subagent
# Prompt with the scenario WITHOUT access to the skill
# Document:
# 1. What choices did they make?
# 2. What rationalizations did they use (verbatim)?
# 3. Which pressures triggered violations?
# 4. What code patterns emerged (correct vs incorrect)?
```

## Baseline Test Results (Documented Failures)

### Scenario 1: Database Lifecycle - CONFIRMED FAILURES âœ…

**Files created:** `examples/fastapi_app/database.py`, `main.py`

**Baseline failures found:**
1. **Line 9-14 (database.py):** Engine created at import time (module-level global)
   ```python
   # âŒ Created at import - runs when module loads
   engine: AsyncEngine = create_async_engine(DATABASE_URL, ...)
   ```

2. **Line 19-23 (main.py):** Using deprecated `@app.on_event("startup")` instead of `lifespan`
   ```python
   # âŒ Deprecated pattern
   @app.on_event("startup")
   async def startup_event():
       async with engine.begin() as conn:
           await conn.run_sync(Base.metadata.create_all)
   ```

3. **NO shutdown handler:** No `@app.on_event("shutdown")` to dispose engine
   - **Impact:** Connections never close, workers leak connections forever
   - **Production symptom:** "Too many connections" DB errors under load

4. **Missing pool parameters:** No `pool_size`, `max_overflow`, `pool_recycle`
   - **Impact:** Pool exhaustion with multiple workers
   - **Production symptom:** Connection timeout errors under concurrent load

**Verdict:** Baseline agent creates code that works in dev but will fail in production.

---

### Scenario 2: Partial Updates - BASELINE PASSED âœ…

**Result:** Agent correctly used `model_dump(exclude_unset=True)` (Pydantic v2 syntax)

**Note:** This test used in-memory database. Real test would be with SQLAlchemy async to verify proper `exclude_unset` usage with ORM models.

---

## Expected Rationalizations

Based on common patterns, agents might rationalize:

| Rationalization                     | Reality                                         |
|-------------------------------------|-------------------------------------------------|
| "The tutorial did it this way"      | Tutorials skip production concerns              |
| "It works in development"           | Production has different load patterns          |
| "I'll add proper cleanup later"     | Later never comes, production leaks connections |
| "Requests is fine for simple cases" | Blocking kills async performance                |
| "I can fix tests after"             | Tests after don't catch async issues            |
| "This is a simple endpoint"         | Simple endpoints become complex                 |

These rationalizations will inform the "Common Mistakes" and anti-patterns section in the skill.


============================================================
END FILE: docs/internal/plans/archive/2026-01-09-fastapi-baseline-tests.md
============================================================

============================================================
FILE: docs/internal/plans/archive/2026-01-09-fastapi-production-patterns-design.md
============================================================

# FastAPI Production Patterns Skill Design

## Overview
Proven patterns for building production-ready FastAPI applications - covering async database lifecycle management, dependency injection tricks, Pydantic validation for partial updates, async testing, and converting existing Python code to FastAPI endpoints.

## Skill Metadata
- **Name:** `fastapi-production-patterns`
- **Type:** Technique + Reference
- **Target:** FastAPI developers facing production issues

## When to Use
```
Building FastAPI app with async DB operations?
Need to test async endpoints correctly?
Converting Python utilities to APIs?
Handling PATCH with partial updates?
Complex dependency injection scenarios?
â””â”€â”€ Use this skill
```

## Quick Reference

| Problem                                   | Solution                                                   | Location           |
|-------------------------------------------|------------------------------------------------------------|--------------------|
| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | Database Lifecycle |
| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | Database Lifecycle |
| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | Async Testing      |
| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | Partial Updates    |
| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | Conversion Pattern |
| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | Background Tasks   |

## Core Patterns

### 1. Database Lifecycle Management

**The Problem:** Most FastAPI tutorials show simple `engine.create_engine()` but don't explain:
- Connections not closed during graceful shutdown
- Pool exhaustion when multiple workers start
- "Event loop is closed" errors during tests
- Database state bleeding between tests

**Pattern:**

```python
# app/main.py
from contextlib import asynccontextmanager
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    engine = create_async_engine(
        DATABASE_URL,
        pool_size=10,
        max_overflow=20,
        pool_recycle=3600  # Recycle connections after 1 hour
    )
    app.state.db_engine = engine
    yield
    # Shutdown - CRITICAL: close connections
    await engine.dispose()

app = FastAPI(lifespan=lifespan)

async def get_db() -> AsyncSession:
    async with AsyncSession(app.state.db_engine) as session:
        yield session
```

**Key insight:** Database engine MUST be created in lifespan, not at import time. Connection pools MUST be disposed in shutdown, or workers will hold connections forever.

### 2. Dependency Injection Patterns

**Caching dependencies:**
```python
from functools import lru_cache

@lru_cache()
