<!-- Chunk 998: bytes 3486700-3490744, type=class -->
class SkillFleetClient:
    async def get_hitl_prompt(self, job_id: str) -> HITLPrompt:
        response = await self.client.get(f"/api/v2/hitl/{job_id}/prompt")
        response.raise_for_status()
        # Pydantic validates the response automatically
        return HITLPrompt.model_validate(response.json())
```

---

## Phase 3: Real-Time Communication (SSE)

**Duration:** 2 weeks  
**Priority:** Medium

### Objectives

1. Replace polling with Server-Sent Events for real-time updates
2. Reduce latency and network overhead
3. Enable streaming progress updates

### Tasks

| Task | File(s)                                | Description                                                         |
|------|----------------------------------------|---------------------------------------------------------------------|
| 3.1  | `pyproject.toml`                       | Add `sse-starlette>=2.0.0` dependency                               |
| 3.2  | `src/skill_fleet/api/routes/stream.py` | Create `GET /api/v2/jobs/{job_id}/stream` SSE endpoint              |
| 3.3  | `src/skill_fleet/api/jobs.py`          | Add event queue per job for SSE broadcasting                        |
| 3.4  | `src/skill_fleet/cli/hitl/runner.py`   | Replace `while True: sleep()` with `async for event in sse_client:` |
| 3.5  | `src/skill_fleet/cli/client.py`        | Add `stream_job_events()` method using `httpx-sse`                  |

### Success Criteria

- [ ] CLI receives HITL prompts via SSE within 100ms of server state change
- [ ] No polling loops in CLI code
- [ ] SSE endpoint documented in Swagger UI
- [ ] Graceful fallback to polling if SSE connection fails
- [ ] Load test: 50 concurrent jobs with SSE streams

### Code Example: SSE Endpoint

```python
# src/skill_fleet/api/routes/stream.py
from sse_starlette.sse import EventSourceResponse
from fastapi import APIRouter

router = APIRouter()

@router.get("/{job_id}/stream")
async def stream_job_events(job_id: str):
    async def event_generator():
        job = get_job(job_id)
        while job and job.status not in {"completed", "failed", "cancelled"}:
            if job.status == "pending_hitl":
                yield {"event": "hitl", "data": job.hitl_data}
            await asyncio.sleep(0.1)
            job = get_job(job_id)
        yield {"event": "complete", "data": {"status": job.status}}
    
    return EventSourceResponse(event_generator())
```

---

## Phase 4: Persistent Job State

**Duration:** 2-3 weeks  
**Priority:** Medium-High

### Objectives

1. Move job state from in-memory `JOBS` dict to persistent store
2. Enable horizontal scaling of API workers
3. Survive server restarts without losing active sessions

### Tasks

| Task | File(s)                               | Description                                            |
|------|---------------------------------------|--------------------------------------------------------|
| 4.1  | `pyproject.toml`                      | Add `redis>=5.0.0` or `sqlalchemy[asyncio]` dependency |
| 4.2  | `src/skill_fleet/api/store/`          | Create abstract `JobStore` interface                   |
| 4.3  | `src/skill_fleet/api/store/memory.py` | Refactor current `JOBS` dict into `MemoryJobStore`     |
| 4.4  | `src/skill_fleet/api/store/redis.py`  | Implement `RedisJobStore`                              |
| 4.5  | `src/skill_fleet/api/dependencies.py` | Add `get_job_store()` dependency                       |
| 4.6  | `config/config.yaml`                  | Add `job_store` configuration section                  |

### Success Criteria

- [ ] Server restart preserves active job state (with Redis/DB)
- [ ] Multiple API workers can handle HITL responses for any job
- [ ] `MemoryJobStore` remains default for local development
- [ ] Migration path documented for existing deployments
- [ ] Performance: <10ms job state read/write latency

### Code Example: Job Store Interface

```python
# src/skill_fleet/api/store/base.py
from abc import ABC, abstractmethod
from skill_fleet.api.schemas import JobState

