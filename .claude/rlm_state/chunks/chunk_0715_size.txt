<!-- Chunk 715: bytes 1722706-1872706, type=size -->
.6-0.8 is good, <0.6 needs improvement"
        },
        {
          "prefix": "Strengths:",
          "description": "What's good about this skill (3-5 points)"
        },
        {
          "prefix": "Weaknesses:",
          "description": "What could be improved (3-5 points)"
        },
        {
          "prefix": "Recommendations:",
          "description": "Specific recommendations for improvement"
        },
        {
          "prefix": "Audience Alignment:",
          "description": "How well content matches target level 0-1. >0.8 means well-aligned"
        }
      ]
    },
    "lm": null
  },
  "hitl_strategy.determine_strategy.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      }
    ],
    "signature": {
      "instructions": "Determine optimal HITL strategy for a given task.\n\nAnalyze the task and decide:\n- Which HITL checkpoints are needed\n- How many questions to ask\n- Whether auto-approve is appropriate",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description"
        },
        {
          "prefix": "Task Complexity:",
          "description": "Complexity assessment: 'simple', 'moderate', 'complex'"
        },
        {
          "prefix": "User Preferences:",
          "description": "JSON of user preferences (e.g., prefer_auto_approve, verbose_feedback)"
        },
        {
          "prefix": "Reasoning:",
          "description": "Reasoning for this strategy"
        },
        {
          "prefix": "Strategy:",
          "description": "Recommended strategy: 'minimal' (2 checkpoints), 'standard' (4 checkpoints), 'thorough' (6 checkpoints)"
        },
        {
          "prefix": "Checkpoints:",
          "description": "List of checkpoint names to enable (e.g., ['phase1_clarify', 'phase1_confirm', ...])"
        }
      ]
    },
    "lm": null
  },
  "readiness.assess": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      }
    ],
    "signature": {
      "instructions": "Assess if we're ready to proceed to next phase.\n\nEvaluate whether we have enough information to proceed,\nor if more HITL interaction is needed.",
      "fields": [
        {
          "prefix": "Phase:",
          "description": "Current phase: 'understanding', 'generation', 'validation'"
        },
        {
          "prefix": "Collected Info:",
          "description": "JSON of information collected so far"
        },
        {
          "prefix": "Min Requirements:",
          "description": "JSON of minimum requirements needed to proceed"
        },
        {
          "prefix": "Ready:",
          "description": "True if ready to proceed to next phase"
        },
        {
          "prefix": "Readiness Score:",
          "description": "Readiness score 0-1. >0.8 means ready"
        },
        {
          "prefix": "Missing Info:",
          "description": "List of missing information needed (empty if ready)"
        },
        {
          "prefix": "Next Questions:",
          "description": "Suggested next questions to ask user (if not ready)"
        }
      ]
    },
    "lm": null
  },
  "confirm_understanding.summarize": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Summarize understanding of user intent for confirmation.\n\nCreate a clear, concise summary of what we understood from the task\nand user's clarifying answers. This is shown to user for confirmation\nbefore proceeding to expensive generation phase.\n\nFormat as bullet points for easy scanning.",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "Original task description"
        },
        {
          "prefix": "User Clarifications:",
          "description": "JSON string of user's answers to clarifying questions"
        },
        {
          "prefix": "Intent Analysis:",
          "description": "Analyzed intent from Phase 1 parallel analysis"
        },
        {
          "prefix": "Taxonomy Path:",
          "description": "Determined taxonomy path (e.g., technical_skills/programming/python)"
        },
        {
          "prefix": "Dependencies:",
          "description": "List of skill dependencies"
        },
        {
          "prefix": "Summary:",
          "description": "Concise bullet-point summary of understanding (3-5 bullets)"
        },
        {
          "prefix": "Key Assumptions:",
          "description": "Key assumptions being made (user should verify these)"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence score 0-1. >0.8 means high confidence, proceed. <0.8 means may need more clarification"
        }
      ]
    },
    "lm": null
  },
  "preview_generator.generate_preview": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      }
    ],
    "signature": {
      "instructions": "Generate a preview of skill content for user review.\n\nCreate a concise preview showing:\n- Skill structure (sections/headings)\n- Key points covered in each section\n- Example count\n- Estimated length\n\nThis helps user verify scope and style before full generation.",
      "fields": [
        {
          "prefix": "Skill Content:",
          "description": "Full generated skill content (SKILL.md)"
        },
        {
          "prefix": "Metadata:",
          "description": "JSON skill metadata (name, description, capabilities)"
        },
        {
          "prefix": "Preview:",
          "description": "Concise preview with: 1) Table of contents, 2) Key points per section, 3) Stats (examples, length)"
        },
        {
          "prefix": "Highlights:",
          "description": "3-5 highlights of what makes this skill valuable"
        },
        {
          "prefix": "Potential Issues:",
          "description": "Potential issues user might want to address (e.g., 'No error handling examples')"
        }
      ]
    },
    "lm": null
  },
  "feedback_analyzer.analyze.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Analyze user feedback and determine what changes to make.\n\nParse user's free-form feedback and convert it into structured\nchange requests that can be used to refine the skill content.",
      "fields": [
        {
          "prefix": "User Feedback:",
          "description": "User's feedback on the preview (free-form text)"
        },
        {
          "prefix": "Current Content:",
          "description": "Current skill content"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Change Requests:",
          "description": "Structured change requests: [{type: 'add/remove/modify', section: '...', details: '...'}]"
        },
        {
          "prefix": "Scope Change:",
          "description": "True if feedback requires major scope change (may need to restart)"
        },
        {
          "prefix": "Estimated Effort:",
          "description": "Estimated effort: 'minor' (quick fix), 'moderate' (refinement), 'major' (regeneration)"
        }
      ]
    },
    "lm": null
  },
  "validation_formatter.format_results": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync → Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**✅ Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**❌ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**✅ Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | ✅ Yes       |\n| `fastapi run main.py`             | Production server  | ❌ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | ✅ Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | ❌ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management → 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Format validation results for human-readable display.\n\nConvert technical validation output into clear, actionable\nfeedback for the user. Group issues by severity and provide\nsuggested fixes.",
      "fields": [
        {
          "prefix": "Validation Report:",
          "description": "JSON validation report with checks, failures, warnings"
        },
        {
          "prefix": "Skill Content:",
          "description": "The skill content that was validated"
        },
        {
          "prefix": "Formatted Report:",
          "description": "Human-readable report with: 1) Summary (pass/fail), 2) Issues by severity, 3) Suggested fixes"
        },
        {
          "prefix": "Critical Issues:",
          "description": "Critical issues that MUST be fixed before acceptance"
        },
        {
          "prefix": "Warnings:",
          "description": "Warnings that SHOULD be addressed but not blocking"
        },
        {
          "prefix": "Auto Fixable:",
          "description": "True if all issues can be auto-fixed without user input"
        }
      ]
    },
    "lm": null
  },
  "refinement_planner.plan_refinement.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**❌ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**✅ Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**❌ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # ❌ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**✅ Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No valida