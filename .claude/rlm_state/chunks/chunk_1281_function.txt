<!-- Chunk 1281: bytes 4732773-4737956, type=function -->
def main():
    """Main optimization workflow."""
    print("=" * 60)
    print("Phase 2: DSPy Optimization with Expanded Training Data")
    print("=" * 60)

    # 1. Configure DSPy with Gemini
    logger.info("Configuring DSPy with Gemini 3 Flash...")
    lm = get_lm("gemini-3-flash-preview", temperature=1.0)  # Gemini 3 requires temp=1.0
    dspy.configure(lm=lm, track_usage=True)

    # 2. Load training data
    trainset = load_training_data("config/training/trainset_v4.json")

    # Split into train/test (80/20)
    split_idx = int(len(trainset) * 0.8)
    train_examples = trainset[:split_idx]
    test_examples = trainset[split_idx:]

    logger.info(f"Split: {len(train_examples)} train, {len(test_examples)} test")

    # 3. Create program
    logger.info("Creating skill program...")
    program = create_simple_program()

    # 4. Baseline evaluation
    logger.info("\n" + "=" * 60)
    logger.info("Baseline Evaluation (before optimization)")
    logger.info("=" * 60)
    baseline_results = evaluate_program(program, test_examples, simple_metric)

    # 5. Run optimization
    logger.info("\n" + "=" * 60)
    logger.info("Running Optimization")
    logger.info("=" * 60)

    # Quick BootstrapFewShot optimization first (faster for testing)
    optimized = run_optimization(
        trainset=train_examples,
        program=program,
        optimizer_type="bootstrap",  # Faster than MIPROv2 for initial test
    )

    # 6. Evaluate optimized
    logger.info("\n" + "=" * 60)
    logger.info("Post-Optimization Evaluation")
    logger.info("=" * 60)
    optimized_results = evaluate_program(optimized, test_examples, simple_metric)

    # 7. Summary
    print("\n" + "=" * 60)
    print("Optimization Results Summary")
    print("=" * 60)
    print(f"Training examples: {len(train_examples)}")
    print(f"Test examples: {len(test_examples)}")
    print(f"Baseline score: {baseline_results['score']:.3f}")
    print(f"Optimized score: {optimized_results['score']:.3f}")

    improvement = optimized_results["score"] - baseline_results["score"]
    print(
        f"Improvement: {improvement:+.3f} ({improvement / baseline_results['score'] * 100:+.1f}%)"
    )

    # 8. Save optimized program
    output_dir = Path("config/optimized")
    output_dir.mkdir(parents=True, exist_ok=True)

    output_path = output_dir / "skill_program_bootstrap_v1.pkl"

    logger.info(f"\nðŸ’¾ Saving optimized program to {output_path}")

    import pickle

    try:
        with open(output_path, "wb") as f:
            pickle.dump(optimized, f)
        logger.info("âœ… Optimization program saved successfully")
    except Exception as e:
        logger.warning(f"âš ï¸  Could not pickle optimized program: {e}")
        logger.warning("Results will still be saved, but program won't be pickled")

    # Save results
    results_path = output_dir / "optimization_results_bootstrap_v1.json"
    results = {
        "optimizer": "BootstrapFewShot",
        "trainset_size": len(train_examples),
        "testset_size": len(test_examples),
        "baseline_score": baseline_results["score"],
        "optimized_score": optimized_results["score"],
        "improvement": improvement,
        "improvement_percent": improvement / baseline_results["score"] * 100
        if baseline_results["score"] > 0
        else 0,
    }

    with open(results_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)

    logger.info(f"ðŸ’¾ Saved results to {results_path}")

    print("\n" + "=" * 60)
    print("âœ… Optimization Complete!")
    print("=" * 60)
    print("\nNext steps:")
    print("1. Review optimization results")
    print("2. Run full MIPROv2 optimization for maximum quality")
    print("3. Test optimized program on real skill creation tasks")
    print("=" * 60)


if __name__ == "__main__":
    main()


============================================================
END FILE: scripts/internal/opt/run_optimization.py
============================================================

============================================================
FILE: scripts/internal/opt/setup_dspy_tracking.py
============================================================

#!/usr/bin/env python3
"""
Setup DSPy tracking and MLflow integration for skills-fleet.

DSPy v3.1.0 provides comprehensive monitoring capabilities:
- Execution tracing (time, tokens, cost)
- Parameter tracking (demos, instructions, weights)
- LM call logging (requests, responses, errors)
- Experiment comparison

MLflow Integration:
- Track DSPy program versions
- Store optimization artifacts
- Compare optimizer performance
- Log metrics over time

Usage:
    uv run python scripts/setup_dspy_tracking.py
    uv run python -m skill_fleet.core.dspy.tracking.track_optimization
"""

from __future__ import annotations

import json
import logging
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import dspy

from skill_fleet.core.optimization.optimizer import get_lm

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


