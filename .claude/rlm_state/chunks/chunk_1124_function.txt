<!-- Chunk 1124: bytes 4217387-4220562, type=function -->
def gepa_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):
    """
    GEPA metric with optional feedback.
    
    Args:
        gold: Gold example
        pred: Prediction
        trace: Full execution trace
        pred_name: Name of predictor being optimized (GEPA-specific)
        pred_trace: Trace of specific predictor (GEPA-specific)
    
    Returns:
        dict: {"score": float, "feedback": str}
    """
    score = simple_metric(gold, pred, trace)
    
    # Optional: Add feedback for GEPA's reflection
    feedback = ""
    if not hasattr(pred, "field1") or not pred.field1:
        feedback += "Missing field1. "
    if score < 0.5:
        feedback += "Score below threshold. "
    
    return {
        "score": score,
        "feedback": feedback or "Good performance"
    }
```

## Training Data Requirements

### Minimum Size
- **BootstrapFewShot**: 10-50 examples (can work with less)
- **MIPROv2**: 50-500 examples (recommended 100+)
- **GEPA**: 20-100 examples

### Quality Guidelines
1. **Diversity**: Cover different scenarios and edge cases
2. **Correctness**: Examples should have correct expected outputs
3. **Balance**: Mix easy and hard examples
4. **Distribution**: Match your production distribution

### Current Training Data

Located at: `config/training/trainset_v4.json`

```
✅ 50 examples (meets DSPy 50-100 recommendation)
✅ 19 different categories
✅ 3 skill styles: comprehensive (38), navigation_hub (11), minimal (1)
✅ 3 sources: synthetic (26), golden (15), extracted (9)
```

## Running Optimization

### Command Line

```bash
# With default BootstrapFewShot
uv run python scripts/run_optimization.py

# Expected output:
# ============================================================
# Phase 2: DSPy Optimization with Expanded Training Data
# ============================================================
# 
# Baseline Evaluation (before optimization)
# Evaluating on 10 test examples...
# Evaluation score: 80.000
# 
# Running Optimization
# Running BootstrapFewShot optimization (fastest)...
# ✅ Optimization complete!
# 
# Post-Optimization Evaluation
# Evaluating on 10 test examples...
# Evaluation score: 80.000
# 
# ============================================================
# Optimization Results Summary
# ============================================================
# Training examples: 40
# Test examples: 10
# Baseline score: 80.000
# Optimized score: 80.000
# Improvement: +0.000 (+0.0%)
# 
# ✅ Results saved to: config/optimized/optimization_results_bootstrap_v1.json
```

### Programmatic Usage

```python
import dspy
from skill_fleet.core.dspy.metrics.skill_quality import skill_quality_metric
from skill_fleet.core.optimization.optimizer import get_lm

# 1. Configure LM
lm = get_lm("gemini-3-flash-preview", temperature=1.0)
dspy.configure(lm=lm)

# 2. Load training data
import json
with open("config/training/trainset_v4.json") as f:
    data = json.load(f)

examples = [
    dspy.Example(
        task_description=item["task_description"],
        expected_taxonomy_path=item.get("expected_taxonomy_path", ""),
    ).with_inputs("task_description")
    for item in data
]

# 3. Create program
