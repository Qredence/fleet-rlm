<!-- Chunk 1271: bytes 4712807-4716434, type=function -->
def run_gepa_optimization(
    trainset: list[dspy.Example],
    program: dspy.Module,
    reflection_model_name: str = "gemini-3-flash-preview",
    auto_level: str = "light",
    num_iterations: int = 3,
    metric_type: str = "composite",
) -> tuple[dspy.Module, dict]:
    """
    Run GEPA optimization.

    GEPA workflow:
    1. Run program on examples (bootstrapping)
    2. For each iteration:
        a. Evaluate using metric
        b. Use reflection_lm to analyze failures
        c. Generate improved instructions
        d. Update module with new instructions
    3. Return optimized program + detailed results

    Args:
        trainset: Training examples
        program: DSPy program to optimize
        reflection_model_name: LM for reflection (should be capable)
        auto_level: 'light', 'medium', or 'heavy'
        num_iterations: Number of reflection iterations (informational only)
        metric_type: 'quality' or 'composite'

    Returns:
        (optimized_program, results_dict)

    """
    logger.info("=" * 70)
    logger.info("GEPA OPTIMIZATION")
    logger.info("=" * 70)
    logger.info(f"Trainset size: {len(trainset)}")
    logger.info(f"Reflection model: {reflection_model_name}")
    logger.info(f"Auto level: {auto_level}")
    logger.info(f"Metric type: {metric_type}")

    # Get reflection LM (should be capable for good reflections)
    logger.info(f"\nConfiguring reflection LM: {reflection_model_name}")
    reflection_lm = get_lm(reflection_model_name, temperature=1.0)

    # Get metric function and wrap it to return float (GEPA needs float during optimization)
    metric_fn_orig = get_gepa_metric(metric_type)

    # Wrapper that extracts score from dict return value
    def metric_fn_for_gepa(example, pred, trace=None, pred_name=None, pred_trace=None):
        result = metric_fn_orig(example, pred, trace, pred_name, pred_trace)
        if isinstance(result, dict) and "score" in result:
            return result["score"]
        return result

    # Create optimizer
    # Note: GEPA auto level controls iterations automatically
    logger.info(f"Creating GEPA optimizer (auto={auto_level})...")
    optimizer = dspy.GEPA(
        metric=metric_fn_for_gepa,
        reflection_lm=reflection_lm,
        auto=auto_level,
        # GEPA automatically controls iterations based on auto level
        # auto="light" → ~2-3 iterations
        # auto="medium" → ~4-5 iterations
        # auto="heavy" → ~6+ iterations
    )

    # Run optimization
    logger.info(f"\n{'Starting GEPA optimization...':.<70}")
    try:
        optimized_program = optimizer.compile(program, trainset=trainset)
        logger.info("✅ GEPA optimization completed!")
    except Exception as e:
        logger.error(f"❌ GEPA optimization failed: {e}")
        logger.error("Note: GEPA is complex - falling back to basic optimization")
        # Fallback: just return the original program
        return program, {
            "optimizer": "GEPA (failed, returned baseline)",
            "reflection_model": reflection_model_name,
            "auto_level": auto_level,
            "metric_type": metric_type,
            "trainset_size": len(trainset),
            "error": str(e),
        }

    return optimized_program, {
        "optimizer": "GEPA",
        "reflection_model": reflection_model_name,
        "auto_level": auto_level,
        "metric_type": metric_type,
        "trainset_size": len(trainset),
    }


# ============================================================================
# EVALUATION
# ============================================================================


