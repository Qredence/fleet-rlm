<!-- Chunk 1006: bytes 3546886-3549621, type=class -->
class JobManager:
    async def create_job(self, job_id: str, job_type: str, metadata: dict):
        # Store in DB
        db.add(Job(id=job_id, type=job_type, status="queued", metadata=metadata))
        
    async def start_job(self, job_id: str):
        # Mark as running
        job.status = "running"
        job.started_at = datetime.utcnow()
        
    async def update_progress(self, job_id: str, step: str, progress_pct: float, message: str):
        # Record progress
        db.add(JobProgress(job_id=job_id, step=step, progress_pct=progress_pct, message=message))
        
    async def complete_job(self, job_id: str, result_path: str):
        # Mark as done
        job.status = "completed"
        job.completed_at = datetime.utcnow()
        job.result_path = result_path
        
    async def resume_jobs(self):
        # Called on API startup
        # Resume all jobs with status="running"
        pending = db.query(Job).filter_by(status="running").all()
        for job in pending:
            # Determine if resumable (not all jobs can resume)
            if job.type in ["optimization", "evaluation"]:
                await self.resume_job(job.id)
```

**Migration Strategy**:
```bash
# On startup
uv run skill-fleet init-db
# Creates schema, migrates in-memory jobs to SQLite
```

**Backward Compatibility**:
- If old in-memory jobs exist: Auto-migrate on first run
- Mark migrated jobs with `source: "memory_migration"`
- Track migration success/failure

**New CLI Command**:
```bash
uv run skill-fleet jobs list
# Shows all jobs with status, progress, result

uv run skill-fleet jobs resume <job_id>
# Resume interrupted optimization
```

**Files to Create**:
1. `src/skill_fleet/db/__init__.py`
2. `src/skill_fleet/db/jobs.py` (models)
3. `src/skill_fleet/db/migrations/` (alembic)
4. Update `src/skill_fleet/api/job_manager.py`
5. Update `src/skill_fleet/api/lifespan.py` with DB init
6. Update `src/skill_fleet/cli/commands/serve.py` with init-db logic

**Timeline**: 1-1.5 days (local-only, SQLite simplification) | **Impact**: Fault-tolerant job system, no data loss on restart

---

#### **2B: Streaming Result Aggregation** ðŸŒŠ

**Problem**: Streaming exists but may have buffering/latency issues during long optimization runs (hours). Users want real-time progress.

**Solution**: Optimized streaming with intelligent buffering. **Local-only: Simplified backpressure (single process).**

**Implementation**:
- New module: `src/skill_fleet/common/streaming/aggregator.py`
  - Class: `StreamingAggregator`
  - Buffers rapid events, emits at ~100ms intervals
  - Tracks: Progress %, current step, cost, ETA
  - Handles: Client disconnects, slow clients, backpressure

**Aggregator Logic**:
```python
