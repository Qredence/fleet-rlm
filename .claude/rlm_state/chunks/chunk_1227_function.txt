<!-- Chunk 1227: bytes 4615731-4616914, type=function -->
def generate_trainset_entry(skill_data: dict[str, Any]) -> dict[str, Any]:
    """Generate a trainset.json entry from skill data."""
    name = skill_data["name"]
    description = skill_data["description"]

    # Infer task description from skill
    task_description = f"Create a {name.replace('-', ' ')} skill: {description}"

    # Infer taxonomy path (simplified for v2)
    parts = name.split("-")
    if len(parts) >= 2:
        expected_taxonomy = f"{parts[0]}/{name}"
    else:
        expected_taxonomy = f"general/{name}"

    # Infer capabilities from name and description
    keywords = name.split("-")
    for word in ["and", "the", "for", "with"]:
        if word in keywords:
            keywords.remove(word)

    return {
        "task_description": task_description,
        "expected_taxonomy_path": expected_taxonomy,
        "expected_name": name,
        "expected_skill_style": skill_data["skill_style"],
        "expected_subdirectories": list(skill_data.get("subdirectory_files", {}).keys()),
        "expected_keywords": keywords,
        "expected_description": description[:200],  # Truncate long descriptions
        "source": "golden_example",
    }


