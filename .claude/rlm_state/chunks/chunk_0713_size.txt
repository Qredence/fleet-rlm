<!-- Chunk 713: bytes 1422706-1572706, type=size -->
class TestHITLWorkflows:
    """End-to-end HITL workflow tests."""
    
    async def test_multi_question_clarification(self):
        """Test Scenario A: Multi-question flow."""
        # Implementation
        
    async def test_skill_preview_approval(self):
        """Test Scenario B: Preview approval."""
        # Implementation
        
    async def test_skill_preview_revision(self):
        """Test Scenario C: Preview revision."""
        # Implementation
        
    async def test_validation_failure_recovery(self):
        """Test Scenario D: Validation recovery."""
        # Implementation
        
    async def test_promote_to_taxonomy(self):
        """Test Scenario E: Promotion flow."""
        # Implementation
```

**Tasks**:
- [ ] Create `tests/integration/test_hitl_workflows.py`
- [ ] Implement mock LLM responses for deterministic testing
- [ ] Create test fixtures for each scenario
- [ ] Add polling utilities for async workflow state changes
- [ ] Run full test suite and document results

### 5.4 Manual Testing Checklist

**Prerequisites**:
- Backend running with `GOOGLE_API_KEY` set
- Frontend dev server running (`npm run dev`)
- Fresh database or test isolation

**Test Execution**:
- [ ] Run Scenario A (20-30 minutes with real LLM calls)
- [ ] Run Scenario B (15-20 minutes)
- [ ] Run Scenario C (20-30 minutes with revision)
- [ ] Run Scenario D (20-30 minutes with validation failure)
- [ ] Run Scenario E (10-15 minutes)

**Validation Points**:
- [ ] No JavaScript errors in browser console
- [ ] No 500 errors from API
- [ ] Job status transitions match expected flow
- [ ] HITL prompts render correctly
- [ ] User responses processed correctly
- [ ] Data persistence works across phase transitions

### 5.5 Known Issues to Verify

**Issue 1**: HITL response race condition
- **Check**: `api/v1/hitl.py` lines 217-254
- **Verify**: Lock mechanism prevents race conditions on rapid double-clicks

**Issue 2**: Session persistence across HITL
- **Check**: `api/services/jobs.py` `save_job_session()`
- **Verify**: Job state preserved if backend restarts during HITL

**Issue 3**: Frontend polling on terminal states
- **Check**: `frontend/fleetui/lib/api.ts` lines 311-325
- **Verify**: Polling stops when job reaches `completed`, `failed`, `cancelled`, or `pending_review`

### 5.6 Success Criteria

- [ ] All 5 scenarios pass manual testing
- [ ] Integration test suite passes in CI
- [ ] No race conditions in HITL response handling
- [ ] Job state persists correctly across all transitions
- [ ] Frontend handles all HITL types without errors
- [ ] Documentation updated with HITL flow diagrams

### 5.7 Files to Test/Verify

| File | Verification |
|------|--------------|
| `api/v1/hitl.py` | Response handling, race conditions |
| `api/services/job_manager.py` | Job state transitions |
| `core/workflows/skill_creation/*.py` | HITL checkpoint integration |
| `core/hitl/manager.py` | HITL state management |
| `frontend/fleetui/app/create/[jobId]/create-skill-workflow.tsx` | UI rendering |
| `frontend/fleetui/lib/api.ts` | Polling logic |
| `tests/integration/test_hitl_workflows.py` | Automated coverage |

---

*Last updated: 2026-01-30*


============================================================
END FILE: PLANS.md
============================================================

============================================================
FILE: README.md
============================================================

# Skill Fleet

A modular AI capability platform that creates, manages, and deploys agent skills as reusable, standards-compliant components.

**Skill Fleet** transforms how AI agents learn by organizing capabilities in a hierarchical taxonomy. Instead of bloated monolithic prompts, skills are modular, versioned, and discoverableâ€”loaded on-demand when agents need them.

> **Perfect for**: AI teams building agent systems, platform engineers managing capability libraries, and organizations standardizing AI knowledge management.

---

## Why Skill Fleet?

### For Technical Teams

- **DSPy-Powered Workflows**: Built on DSPy with task-based orchestrators for reliable skill generation
- **FastAPI Architecture**: Clean API layer with background tasks, dependency injection, and async support
- **agentskills.io Compliant**: Standard YAML frontmatter ensures skills work across different agent frameworks
- **Hierarchical MLflow Tracking**: Parent runs for workflows, child runs for each phase

### For Decision Makers

- **Modular & Maintainable**: Skills are versioned, tracked, and independently testable
- **Standards-Based**: Open specification compliance prevents vendor lock-in
- **Scalable**: Hierarchical taxonomy supports hundreds of skills with organized growth

### For Everyone

- **Easy to Use**: Chat interface for creating skills without coding
- **Validated**: Automated compliance checking ensures quality
- **Observable**: Built-in analytics and usage tracking

---

## Quick Start

Create your first skill in under 2 minutes:

```bash
# 1. Install dependencies
uv sync --group dev
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY

# 2. Start the API server
uv run skill-fleet serve

# 3. Create a skill via chat (in a new terminal)
uv run skill-fleet chat "Create a Python decorators skill"
```

The skill is created as a draft. After reviewing it in `drafts/<job_id>/`, promote it:

```bash
uv run skill-fleet promote <job_id>
```

---

## Prerequisites

- **Python**: 3.12+
- **Package Manager**: [uv](https://github.com/astral-sh/uv)
- **API Keys**: `GOOGLE_API_KEY` (Gemini is the default model)

---

## Installation

```bash
# Clone the repository
git clone https://github.com/Qredence/skill-fleet.git
cd skill-fleet

# Install dependencies
uv sync

# Setup environment
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY
```

---

## Interactive Workflows

### ðŸ’¬ Real-Time Chat

Build skills with streaming updates and live reasoning display:

```bash
uv run skill-fleet chat "Create a Redis caching skill"
```

Features:
- Real-time progress updates (100ms polling)
- Live thinking/reasoning display
- Arrow key navigation for multi-choice questions
- HITL (Human-in-the-Loop) integration

### ðŸ“Š Validation & Quality

Validate skills against agentskills.io standards:

```bash
# Validate a skill
uv run skill-fleet validate skills/python/decorators

# Check compliance
uv run skill-fleet validate --strict skills/general/testing
```

### ðŸ§  DSPy Optimization

Tune prompts using MIPROv2 or GEPA optimizers:

```bash
uv run skill-fleet optimize --optimizer miprov2
```

---

## API Reference

### v1 API (Current)

The v1 API provides comprehensive skill management:

| Endpoint | Description |
|----------|-------------|
| `POST /api/v1/skills` | Create skill (starts background job) |
| `GET /api/v1/skills/{id}` | Get skill details |
| `PUT /api/v1/skills/{id}` | Update skill |
| `POST /api/v1/skills/{id}/validate` | Validate skill |
| `POST /api/v1/skills/{id}/refine` | Refine with feedback |
| `GET /api/v1/jobs/{id}` | Check job status |
| `GET /api/v1/hitl/{job_id}` | Poll for HITL prompts |
| `POST /api/v1/hitl/{job_id}` | Submit HITL response |

### CLI Commands

| Command | Description |
|---------|-------------|
| `skill-fleet serve` | Start FastAPI server |
| `skill-fleet chat` | Interactive skill creation |
| `skill-fleet list` | List all skills |
| `skill-fleet promote <id>` | Promote draft to taxonomy |
| `skill-fleet validate <path>` | Validate skill |
| `skill-fleet terminal` | Python-only CLI interface |

---

## Project Structure

```text
skill-fleet/
â”œâ”€â”€ src/skill_fleet/
â”‚   â”œâ”€â”€ api/                 # FastAPI application
â”‚   â”‚   â”œâ”€â”€ v1/             # API v1 routes
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic layer
â”‚   â”‚   â””â”€â”€ schemas/        # Pydantic models
â”‚   â”œâ”€â”€ cli/                # Typer-based CLI
â”‚   â”‚   â””â”€â”€ commands/
â”‚   â”‚       â”œâ”€â”€ chat.py     # Interactive chat
â”‚   â”‚       â””â”€â”€ terminal.py # Python-only interface
â”‚   â”œâ”€â”€ core/               # Domain logic
â”‚   â”‚   â”œâ”€â”€ workflows/      # Task-based orchestrators
â”‚   â”‚   â”œâ”€â”€ modules/        # DSPy modules
â”‚   â”‚   â””â”€â”€ signatures/     # DSPy signatures
â”‚   â”œâ”€â”€ dspy/               # Centralized DSPy config
â”‚   â”œâ”€â”€ infrastructure/     # Technical infrastructure
â”‚   â”‚   â”œâ”€â”€ db/            # Database layer
â”‚   â”‚   â””â”€â”€ tracing/       # MLflow integration
â”‚   â”œâ”€â”€ taxonomy/          # Skill taxonomy management
â”‚   â””â”€â”€ validators/        # Skill validation
â”œâ”€â”€ skills/                # Skill taxonomy
â”‚   â”œâ”€â”€ _core/            # Always-loaded skills
â”‚   â”œâ”€â”€ python/           # Python skills
â”‚   â”œâ”€â”€ devops/           # DevOps skills
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ api/              # API tests
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â””â”€â”€ integration/      # Integration tests
â”œâ”€â”€ config/               # Configuration
â””â”€â”€ docs/                 # Documentation
```

---

## Architecture

### FastAPI-Centric Design

The v0.3.5 restructure introduces a clean, FastAPI-centric architecture:

1. **API Layer** (`api/`): Routes, schemas, and dependency injection
2. **Service Layer** (`api/services/`): Business logic bridging API to workflows
3. **Workflow Layer** (`core/workflows/`): Task-based DSPy orchestrators
4. **Infrastructure** (`infrastructure/`): Database, tracing, monitoring

### Workflow Orchestrators

Three-phase skill creation with HITL support:

1. **Understanding Workflow**: Analyzes requirements, generates plan
2. **Generation Workflow**: Creates skill content
3. **Validation Workflow**: Checks compliance, refines content

Each phase runs in a child MLflow run under a parent workflow run.

---

## Configuration

### Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GOOGLE_API_KEY` | Yes | Gemini API key |
| `SKILL_FLEET_ENV` | No | `production` or `development` |
| `SKILL_FLEET_CORS_ORIGINS` | Prod | Allowed origins (comma-separated) |
| `DSPY_CACHEDIR` | No | DSPy cache directory |
| `DSPY_TEMPERATURE` | No | Override LLM temperature |

### Config File

Edit `config/config.yaml` for:
- Model settings (default: `gemini/gemini-2-flash`)
- Optimizer configurations (MIPROv2, GEPA)
- Task-specific model assignments

---

## Development

### Running Tests

```bash
# Run all tests
uv run pytest

# Run unit tests only
uv run pytest tests/unit/

# Run with coverage
uv run pytest --cov=skill_fleet
```

### Linting & Formatting

```bash
# Check and fix
uv run ruff check --fix .

# Format code
uv run ruff format .
```

### Project Standards

- **Python**: 3.12+ with modern type hints (`str | None`)
- **Line Length**: 100 characters
- **Quotes**: Double quotes
- **Docstrings**: Google style
- **Imports**: Absolute only, no relative imports

---

## Documentation

### Getting Started

- [Getting Started Guide](docs/getting-started/index.md) - Installation and first steps
- [Quick Start](docs/getting-started/STREAMING_QUICKSTART.md) - Streaming chat guide

### Core Concepts

- [System Overview](docs/index.md) - Architecture and concepts
- [AGENTS.md](AGENTS.md) - Comprehensive working guide
- [Developer Reference](docs/concepts/developer-reference.md)

### API & Technical

- [API v1 Documentation](docs/api/index.md) - REST API reference
- [API Migration](docs/api/MIGRATION_V1_TO_V2.md) - v1 to v2 migration guide
- [DSPy Framework](docs/dspy/index.md) - Workflow documentation
- [Import Path Guide](docs/development/IMPORT_PATH_GUIDE.md) - Import conventions
- [Service Extension](docs/development/SERVICE_EXTENSION_GUIDE.md) - Adding services

### Advanced

- [HITL System](docs/architecture/CONVERSATIONAL_INTERFACE.md) - Human-in-the-Loop
- [agentskills.io Compliance](docs/concepts/agentskills-compliance.md) - Standards
- [Background Jobs](docs/architecture/BACKGROUND_JOBS.md) - Async job processing

---

## Migration from v0.2.x

See [docs/api/MIGRATION_V1_TO_V2.md](docs/api/MIGRATION_V1_TO_V2.md) for:
- Import path changes
- API endpoint updates
- Architecture changes
- Breaking changes and deprecations

---

## License

Apache License 2.0. See [LICENSE](LICENSE).

## Contributing

See [CONTRIBUTING.md](docs/development/CONTRIBUTING.md) for development workflow.

---

**Version**: 0.3.5  
**Status**: Production Ready  
**Last Updated**: January 2026


============================================================
END FILE: README.md
============================================================

============================================================
FILE: SECURITY.md
============================================================

# Security Policy

## Supported Versions

Use this section to tell people about which versions of your project are
currently being supported with security updates.

| Version | Supported          |
| ------- | ------------------ |
| 5.1.x   | :white_check_mark: |
| 5.0.x   | :x:                |
| 4.0.x   | :white_check_mark: |
| < 4.0   | :x:                |

## Reporting a Vulnerability

Use this section to tell people how to report a vulnerability.

Tell them where to go, how often they can expect to get an update on a
reported vulnerability, what to expect if the vulnerability is accepted or
declined, etc.


============================================================
END FILE: SECURITY.md
============================================================

============================================================
FILE: cli/tui/package-lock.json
============================================================

{
  "name": "skills-fleet-tui",
  "version": "0.1.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "skills-fleet-tui",
      "version": "0.1.0",
      "dependencies": {
        "eventsource-parser": "^3.0.0",
        "ink": "^6.6.0",
        "ink-select-input": "^6.2.0",
        "ink-spinner": "^5.0.0",
        "ink-text-input": "^6.0.0",
        "react": "^19.0.0",
        "react-devtools-core": "^6.1.2"
      },
      "devDependencies": {
        "@types/node": "^25.0.0",
        "@types/react": "^19.2.0",
        "tsx": "^4.0.0",
        "typescript": "^5.9.0"
      },
      "engines": {
        "node": ">=18.0.0"
      }
    },
    "node_modules/@alcalzone/ansi-tokenize": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@alcalzone/ansi-tokenize/-/ansi-tokenize-0.2.3.tgz",
      "integrity": "sha512-jsElTJ0sQ4wHRz+C45tfect76BwbTbgkgKByOzpCN9xG61N5V6u/glvg1CsNJhq2xJIFpKHSwG3D2wPPuEYOrQ==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.2.1",
        "is-fullwidth-code-point": "^5.0.0"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/aix-ppc64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/aix-ppc64/-/aix-ppc64-0.27.2.tgz",
      "integrity": "sha512-GZMB+a0mOMZs4MpDbj8RJp4cw+w1WV5NYD6xzgvzUJ5Ek2jerwfO2eADyI6ExDSUED+1X8aMbegahsJi+8mgpw==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "aix"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm/-/android-arm-0.27.2.tgz",
      "integrity": "sha512-DVNI8jlPa7Ujbr1yjU2PfUSRtAUZPG9I1RwW4F4xFB1Imiu2on0ADiI/c3td+KmDtVKNbi+nffGDQMfcIMkwIA==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/android-arm64/-/android-arm64-0.27.2.tgz",
      "integrity": "sha512-pvz8ZZ7ot/RBphf8fv60ljmaoydPU12VuXHImtAs0XhLLw+EXBi2BLe3OYSBslR4rryHvweW5gmkKFwTiFy6KA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/android-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/android-x64/-/android-x64-0.27.2.tgz",
      "integrity": "sha512-z8Ank4Byh4TJJOh4wpz8g2vDy75zFL0TlZlkUkEwYXuPSgX8yzep596n6mT7905kA9uHZsf/o2OJZubl2l3M7A==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-arm64/-/darwin-arm64-0.27.2.tgz",
      "integrity": "sha512-davCD2Zc80nzDVRwXTcQP/28fiJbcOwvdolL0sOiOsbwBa72kegmVU0Wrh1MYrbuCL98Omp5dVhQFWRKR2ZAlg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/darwin-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/darwin-x64/-/darwin-x64-0.27.2.tgz",
      "integrity": "sha512-ZxtijOmlQCBWGwbVmwOF/UCzuGIbUkqB1faQRf5akQmxRJ1ujusWsb3CVfk/9iZKr2L5SMU5wPBi1UWbvL+VQA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-arm64/-/freebsd-arm64-0.27.2.tgz",
      "integrity": "sha512-lS/9CN+rgqQ9czogxlMcBMGd+l8Q3Nj1MFQwBZJyoEKI50XGxwuzznYdwcav6lpOGv5BqaZXqvBSiB/kJ5op+g==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/freebsd-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/freebsd-x64/-/freebsd-x64-0.27.2.tgz",
      "integrity": "sha512-tAfqtNYb4YgPnJlEFu4c212HYjQWSO/w/h/lQaBK7RbwGIkBOuNKQI9tqWzx7Wtp7bTPaGC6MJvWI608P3wXYA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "freebsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm/-/linux-arm-0.27.2.tgz",
      "integrity": "sha512-vWfq4GaIMP9AIe4yj1ZUW18RDhx6EPQKjwe7n8BbIecFtCQG4CfHGaHuh7fdfq+y3LIA2vGS/o9ZBGVxIDi9hw==",
      "cpu": [
        "arm"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-arm64/-/linux-arm64-0.27.2.tgz",
      "integrity": "sha512-hYxN8pr66NsCCiRFkHUAsxylNOcAQaxSSkHMMjcpx0si13t1LHFphxJZUiGwojB1a/Hd5OiPIqDdXONia6bhTw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ia32": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ia32/-/linux-ia32-0.27.2.tgz",
      "integrity": "sha512-MJt5BRRSScPDwG2hLelYhAAKh9imjHK5+NE/tvnRLbIqUWa+0E9N4WNMjmp/kXXPHZGqPLxggwVhz7QP8CTR8w==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-loong64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-loong64/-/linux-loong64-0.27.2.tgz",
      "integrity": "sha512-lugyF1atnAT463aO6KPshVCJK5NgRnU4yb3FUumyVz+cGvZbontBgzeGFO1nF+dPueHD367a2ZXe1NtUkAjOtg==",
      "cpu": [
        "loong64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-mips64el": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-mips64el/-/linux-mips64el-0.27.2.tgz",
      "integrity": "sha512-nlP2I6ArEBewvJ2gjrrkESEZkB5mIoaTswuqNFRv/WYd+ATtUpe9Y09RnJvgvdag7he0OWgEZWhviS1OTOKixw==",
      "cpu": [
        "mips64el"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-ppc64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-ppc64/-/linux-ppc64-0.27.2.tgz",
      "integrity": "sha512-C92gnpey7tUQONqg1n6dKVbx3vphKtTHJaNG2Ok9lGwbZil6DrfyecMsp9CrmXGQJmZ7iiVXvvZH6Ml5hL6XdQ==",
      "cpu": [
        "ppc64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-riscv64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-riscv64/-/linux-riscv64-0.27.2.tgz",
      "integrity": "sha512-B5BOmojNtUyN8AXlK0QJyvjEZkWwy/FKvakkTDCziX95AowLZKR6aCDhG7LeF7uMCXEJqwa8Bejz5LTPYm8AvA==",
      "cpu": [
        "riscv64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-s390x": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-s390x/-/linux-s390x-0.27.2.tgz",
      "integrity": "sha512-p4bm9+wsPwup5Z8f4EpfN63qNagQ47Ua2znaqGH6bqLlmJ4bx97Y9JdqxgGZ6Y8xVTixUnEkoKSHcpRlDnNr5w==",
      "cpu": [
        "s390x"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/linux-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/linux-x64/-/linux-x64-0.27.2.tgz",
      "integrity": "sha512-uwp2Tip5aPmH+NRUwTcfLb+W32WXjpFejTIOWZFw/v7/KnpCDKG66u4DLcurQpiYTiYwQ9B7KOeMJvLCu/OvbA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-arm64/-/netbsd-arm64-0.27.2.tgz",
      "integrity": "sha512-Kj6DiBlwXrPsCRDeRvGAUb/LNrBASrfqAIok+xB0LxK8CHqxZ037viF13ugfsIpePH93mX7xfJp97cyDuTZ3cw==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/netbsd-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/netbsd-x64/-/netbsd-x64-0.27.2.tgz",
      "integrity": "sha512-HwGDZ0VLVBY3Y+Nw0JexZy9o/nUAWq9MlV7cahpaXKW6TOzfVno3y3/M8Ga8u8Yr7GldLOov27xiCnqRZf0tCA==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "netbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-arm64/-/openbsd-arm64-0.27.2.tgz",
      "integrity": "sha512-DNIHH2BPQ5551A7oSHD0CKbwIA/Ox7+78/AWkbS5QoRzaqlev2uFayfSxq68EkonB+IKjiuxBFoV8ESJy8bOHA==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openbsd-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/openbsd-x64/-/openbsd-x64-0.27.2.tgz",
      "integrity": "sha512-/it7w9Nb7+0KFIzjalNJVR5bOzA9Vay+yIPLVHfIQYG/j+j9VTH84aNB8ExGKPU4AzfaEvN9/V4HV+F+vo8OEg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openbsd"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/openharmony-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/openharmony-arm64/-/openharmony-arm64-0.27.2.tgz",
      "integrity": "sha512-LRBbCmiU51IXfeXk59csuX/aSaToeG7w48nMwA6049Y4J4+VbWALAuXcs+qcD04rHDuSCSRKdmY63sruDS5qag==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "openharmony"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/sunos-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/sunos-x64/-/sunos-x64-0.27.2.tgz",
      "integrity": "sha512-kMtx1yqJHTmqaqHPAzKCAkDaKsffmXkPHThSfRwZGyuqyIeBvf08KSsYXl+abf5HDAPMJIPnbBfXvP2ZC2TfHg==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "sunos"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-arm64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-arm64/-/win32-arm64-0.27.2.tgz",
      "integrity": "sha512-Yaf78O/B3Kkh+nKABUF++bvJv5Ijoy9AN1ww904rOXZFLWVc5OLOfL56W+C8F9xn5JQZa3UX6m+IktJnIb1Jjg==",
      "cpu": [
        "arm64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-ia32": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-ia32/-/win32-ia32-0.27.2.tgz",
      "integrity": "sha512-Iuws0kxo4yusk7sw70Xa2E2imZU5HoixzxfGCdxwBdhiDgt9vX9VUCBhqcwY7/uh//78A1hMkkROMJq9l27oLQ==",
      "cpu": [
        "ia32"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@esbuild/win32-x64": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/@esbuild/win32-x64/-/win32-x64-0.27.2.tgz",
      "integrity": "sha512-sRdU18mcKf7F+YgheI/zGf5alZatMUTKj/jNS6l744f9u3WFu4v7twcUI9vu4mknF4Y9aDlblIie0IM+5xxaqQ==",
      "cpu": [
        "x64"
      ],
      "dev": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@types/node": {
      "version": "25.0.9",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-25.0.9.tgz",
      "integrity": "sha512-/rpCXHlCWeqClNBwUhDcusJxXYDjZTyE8v5oTO7WbL8eij2nKhUeU89/6xgjU7N4/Vh3He0BtyhJdQbDyhiXAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "undici-types": "~7.16.0"
      }
    },
    "node_modules/@types/react": {
      "version": "19.2.8",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-19.2.8.tgz",
      "integrity": "sha512-3MbSL37jEchWZz2p2mjntRZtPt837ij10ApxKfgmXCTuHWagYg7iA5bqPw6C8BMPfwidlvfPI/fxOc42HLhcyg==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "csstype": "^3.2.2"
      }
    },
    "node_modules/ansi-escapes": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-7.2.0.tgz",
      "integrity": "sha512-g6LhBsl+GBPRWGWsBtutpzBYuIIdBkLEvad5C/va/74Db018+5TZiyA26cZJAr3Rft5lprVqOIPxf5Vid6tqAw==",
      "license": "MIT",
      "dependencies": {
        "environment": "^1.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ansi-regex": {
      "version": "6.2.2",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.2.2.tgz",
      "integrity": "sha512-Bq3SmSpyFHaWjPk8If9yc6svM8c56dB5BAtW4Qbw5jHTwwXXcTLoRMkpDJp6VL0XzlWaCHTXrkFURMYmD0sLqg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/ansi-styles": {
      "version": "6.2.3",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.3.tgz",
      "integrity": "sha512-4Dj6M28JB+oAH8kFkTLUo+a2jwOFkuqb3yucU0CANcRRUbxS0cP0nZYCGjcc3BNXwRIsUVmDGgzawme7zvJHvg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/auto-bind": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/auto-bind/-/auto-bind-5.0.1.tgz",
      "integrity": "sha512-ooviqdwwgfIfNmDwo94wlshcdzfO64XV0Cg6oDsDYBJfITDz1EngD2z7DkbvCWn+XIMsIqW27sEVF6qcpJrRcg==",
      "license": "MIT",
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/chalk": {
      "version": "5.6.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-5.6.2.tgz",
      "integrity": "sha512-7NzBL0rN6fMUW+f7A6Io4h40qQlG+xGmtMxfbnH/K7TAtt8JQWVQK+6g0UXKMeVJoyV5EkkNsErQ8pVD3bLHbA==",
      "license": "MIT",
      "engines": {
        "node": "^12.17.0 || ^14.13 || >=16.0.0"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/cli-boxes": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cli-boxes/-/cli-boxes-3.0.0.tgz",
      "integrity": "sha512-/lzGpEWL/8PfI0BmBOPRwp0c/wFNX1RdUML3jK/RcSBA9T8mZDdQpqYBKtCFTOfQbwPqWEOpjqW+Fnayc0969g==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/cli-cursor": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/cli-cursor/-/cli-cursor-4.0.0.tgz",
      "integrity": "sha512-VGtlMu3x/4DOtIUwEkRezxUZ2lBacNJCHash0N0WeZDBS+7Ux1dm3XWAgWYxLJFMMdOeXMHXorshEFhbMSGelg==",
      "license": "MIT",
      "dependencies": {
        "restore-cursor": "^4.0.0"
      },
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/cli-spinners": {
      "version": "2.9.2",
      "resolved": "https://registry.npmjs.org/cli-spinners/-/cli-spinners-2.9.2.tgz",
      "integrity": "sha512-ywqV+5MmyL4E7ybXgKys4DugZbX0FC6LnwrhjuykIjnK9k8OQacQ7axGKnjDXWNhns0xot3bZI5h55H8yo9cJg==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/cli-truncate": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/cli-truncate/-/cli-truncate-5.1.1.tgz",
      "integrity": "sha512-SroPvNHxUnk+vIW/dOSfNqdy1sPEFkrTk6TUtqLCnBlo3N7TNYYkzzN7uSD6+jVjrdO4+p8nH7JzH6cIvUem6A==",
      "license": "MIT",
      "dependencies": {
        "slice-ansi": "^7.1.0",
        "string-width": "^8.0.0"
      },
      "engines": {
        "node": ">=20"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/code-excerpt": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/code-excerpt/-/code-excerpt-4.0.0.tgz",
      "integrity": "sha512-xxodCmBen3iy2i0WtAK8FlFNrRzjUqjRsMfho58xT/wvZU1YTM3fCnRjcy1gJPMepaRlgm/0e6w8SpWHpn3/cA==",
      "license": "MIT",
      "dependencies": {
        "convert-to-spaces": "^2.0.1"
      },
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      }
    },
    "node_modules/convert-to-spaces": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/convert-to-spaces/-/convert-to-spaces-2.0.1.tgz",
      "integrity": "sha512-rcQ1bsQO9799wq24uE5AM2tAILy4gXGIK/njFWcVQkGNZ96edlpY+A7bjwvzjYvLDyzmG1MmMLZhpcsb+klNMQ==",
      "license": "MIT",
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      }
    },
    "node_modules/csstype": {
      "version": "3.2.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.2.3.tgz",
      "integrity": "sha512-z1HGKcYy2xA8AGQfwrn0PAy+PB7X/GSj3UVJW9qKyn43xWa+gl5nXmU4qqLMRzWVLFC8KusUX8T/0kCiOYpAIQ==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/emoji-regex": {
      "version": "10.6.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-10.6.0.tgz",
      "integrity": "sha512-toUI84YS5YmxW219erniWD0CIVOo46xGKColeNQRgOzDorgBi1v4D71/OFzgD9GO2UGKIv1C3Sp8DAn0+j5w7A==",
      "license": "MIT"
    },
    "node_modules/environment": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/environment/-/environment-1.1.0.tgz",
      "integrity": "sha512-xUtoPkMggbz0MPyPiIWr1Kp4aeWJjDZ6SMvURhimjdZgsRuDplF5/s9hcgGhyXMhs+6vpnuoiZ2kFiu3FMnS8Q==",
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/es-toolkit": {
      "version": "1.44.0",
      "resolved": "https://registry.npmjs.org/es-toolkit/-/es-toolkit-1.44.0.tgz",
      "integrity": "sha512-6penXeZalaV88MM3cGkFZZfOoLGWshWWfdy0tWw/RlVVyhvMaWSBTOvXNeiW3e5FwdS5ePW0LGEu17zT139ktg==",
      "license": "MIT",
      "workspaces": [
        "docs",
        "benchmarks"
      ]
    },
    "node_modules/esbuild": {
      "version": "0.27.2",
      "resolved": "https://registry.npmjs.org/esbuild/-/esbuild-0.27.2.tgz",
      "integrity": "sha512-HyNQImnsOC7X9PMNaCIeAm4ISCQXs5a5YasTXVliKv4uuBo1dKrG0A+uQS8M5eXjVMnLg3WgXaKvprHlFJQffw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "bin": {
        "esbuild": "bin/esbuild"
      },
      "engines": {
        "node": ">=18"
      },
      "optionalDependencies": {
        "@esbuild/aix-ppc64": "0.27.2",
        "@esbuild/android-arm": "0.27.2",
        "@esbuild/android-arm64": "0.27.2",
        "@esbuild/android-x64": "0.27.2",
        "@esbuild/darwin-arm64": "0.27.2",
        "@esbuild/darwin-x64": "0.27.2",
        "@esbuild/freebsd-arm64": "0.27.2",
        "@esbuild/freebsd-x64": "0.27.2",
        "@esbuild/linux-arm": "0.27.2",
        "@esbuild/linux-arm64": "0.27.2",
        "@esbuild/linux-ia32": "0.27.2",
        "@esbuild/linux-loong64": "0.27.2",
        "@esbuild/linux-mips64el": "0.27.2",
        "@esbuild/linux-ppc64": "0.27.2",
        "@esbuild/linux-riscv64": "0.27.2",
        "@esbuild/linux-s390x": "0.27.2",
        "@esbuild/linux-x64": "0.27.2",
        "@esbuild/netbsd-arm64": "0.27.2",
        "@esbuild/netbsd-x64": "0.27.2",
        "@esbuild/openbsd-arm64": "0.27.2",
        "@esbuild/openbsd-x64": "0.27.2",
        "@esbuild/openharmony-arm64": "0.27.2",
        "@esbuild/sunos-x64": "0.27.2",
        "@esbuild/win32-arm64": "0.27.2",
        "@esbuild/win32-ia32": "0.27.2",
        "@esbuild/win32-x64": "0.27.2"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-2.0.0.tgz",
      "integrity": "sha512-UpzcLCXolUWcNu5HtVMHYdXJjArjsF9C0aNnquZYY4uW/Vu0miy5YoWvbV345HauVvcAUnpRuhMMcqTcGOY2+w==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/eventsource-parser": {
      "version": "3.0.6",
      "resolved": "https://registry.npmjs.org/eventsource-parser/-/eventsource-parser-3.0.6.tgz",
      "integrity": "sha512-Vo1ab+QXPzZ4tCa8SwIHJFaSzy4R6SHf7BY79rFBDf0idraZWAkYrDjDj8uWaSm3S2TK+hJ7/t1CEmZ7jXw+pg==",
      "license": "MIT",
      "engines": {
        "node": ">=18.0.0"
      }
    },
    "node_modules/figures": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/figures/-/figures-6.1.0.tgz",
      "integrity": "sha512-d+l3qxjSesT4V7v2fh+QnmFnUWv9lSpjarhShNTgBOfA0ttejbQUAlHLitbjkoRiDulW0OPoQPYIGhIC8ohejg==",
      "license": "MIT",
      "dependencies": {
        "is-unicode-supported": "^2.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "dev": true,
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/get-east-asian-width": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/get-east-asian-width/-/get-east-asian-width-1.4.0.tgz",
      "integrity": "sha512-QZjmEOC+IT1uk6Rx0sX22V6uHWVwbdbxf1faPqJ1QhLdGgsRGCZoyaQBm/piRdJy/D2um6hM1UP7ZEeQ4EkP+Q==",
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.13.0",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.13.0.tgz",
      "integrity": "sha512-1VKTZJCwBrvbd+Wn3AOgQP/2Av+TfTCOlE4AcRJE72W1ksZXbAx8PPBR9RzgTeSPzlPMHrbANMH3LbltH73wxQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/indent-string": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/indent-string/-/indent-string-5.0.0.tgz",
      "integrity": "sha512-m6FAo/spmsW2Ab2fU35JTYwtOKa2yAwXSwgjSv1TJzh4Mh7mC3lzAOVLBprb72XsTrgkEIsl7YrFNAiDiRhIGg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ink": {
      "version": "6.6.0",
      "resolved": "https://registry.npmjs.org/ink/-/ink-6.6.0.tgz",
      "integrity": "sha512-QDt6FgJxgmSxAelcOvOHUvFxbIUjVpCH5bx+Slvc5m7IEcpGt3dYwbz/L+oRnqEGeRvwy1tineKK4ect3nW1vQ==",
      "license": "MIT",
      "dependencies": {
        "@alcalzone/ansi-tokenize": "^0.2.1",
        "ansi-escapes": "^7.2.0",
        "ansi-styles": "^6.2.1",
        "auto-bind": "^5.0.1",
        "chalk": "^5.6.0",
        "cli-boxes": "^3.0.0",
        "cli-cursor": "^4.0.0",
        "cli-truncate": "^5.1.1",
        "code-excerpt": "^4.0.0",
        "es-toolkit": "^1.39.10",
        "indent-string": "^5.0.0",
        "is-in-ci": "^2.0.0",
        "patch-console": "^2.0.0",
        "react-reconciler": "^0.33.0",
        "signal-exit": "^3.0.7",
        "slice-ansi": "^7.1.0",
        "stack-utils": "^2.0.6",
        "string-width": "^8.1.0",
        "type-fest": "^4.27.0",
        "widest-line": "^5.0.0",
        "wrap-ansi": "^9.0.0",
        "ws": "^8.18.0",
        "yoga-layout": "~3.2.1"
      },
      "engines": {
        "node": ">=20"
      },
      "peerDependencies": {
        "@types/react": ">=19.0.0",
        "react": ">=19.0.0",
        "react-devtools-core": "^6.1.2"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "react-devtools-core": {
          "optional": true
        }
      }
    },
    "node_modules/ink-select-input": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/ink-select-input/-/ink-select-input-6.2.0.tgz",
      "integrity": "sha512-304fZXxkpYxJ9si5lxRCaX01GNlmPBgOZumXXRnPYbHW/iI31cgQynqk2tRypGLOF1cMIwPUzL2LSm6q4I5rQQ==",
      "license": "MIT",
      "dependencies": {
        "figures": "^6.1.0",
        "to-rotated": "^1.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "ink": ">=5.0.0",
        "react": ">=18.0.0"
      }
    },
    "node_modules/ink-spinner": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/ink-spinner/-/ink-spinner-5.0.0.tgz",
      "integrity": "sha512-EYEasbEjkqLGyPOUc8hBJZNuC5GvXGMLu0w5gdTNskPc7Izc5vO3tdQEYnzvshucyGCBXc86ig0ujXPMWaQCdA==",
      "license": "MIT",
      "dependencies": {
        "cli-spinners": "^2.7.0"
      },
      "engines": {
        "node": ">=14.16"
      },
      "peerDependencies": {
        "ink": ">=4.0.0",
        "react": ">=18.0.0"
      }
    },
    "node_modules/ink-text-input": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/ink-text-input/-/ink-text-input-6.0.0.tgz",
      "integrity": "sha512-Fw64n7Yha5deb1rHY137zHTAbSTNelUKuB5Kkk2HACXEtwIHBCf9OH2tP/LQ9fRYTl1F0dZgbW0zPnZk6FA9Lw==",
      "license": "MIT",
      "dependencies": {
        "chalk": "^5.3.0",
        "type-fest": "^4.18.2"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "ink": ">=5",
        "react": ">=18"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "5.1.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-5.1.0.tgz",
      "integrity": "sha512-5XHYaSyiqADb4RnZ1Bdad6cPp8Toise4TzEjcOYDHZkTCbKgiUl7WTUCpNWHuxmDt91wnsZBc9xinNzopv3JMQ==",
      "license": "MIT",
      "dependencies": {
        "get-east-asian-width": "^1.3.1"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-in-ci": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/is-in-ci/-/is-in-ci-2.0.0.tgz",
      "integrity": "sha512-cFeerHriAnhrQSbpAxL37W1wcJKUUX07HyLWZCW1URJT/ra3GyUTzBgUnh24TMVfNTV2Hij2HLxkPHFZfOZy5w==",
      "license": "MIT",
      "bin": {
        "is-in-ci": "cli.js"
      },
      "engines": {
        "node": ">=20"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-unicode-supported": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-unicode-supported/-/is-unicode-supported-2.1.0.tgz",
      "integrity": "sha512-mE00Gnza5EEB3Ds0HfMyllZzbBrmLOX3vfWoj9A9PEnTfratQ/BcaJOuMhnkhjXvb2+FkY3VuHqtAGpTPmglFQ==",
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/mimic-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
      "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/onetime": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/onetime/-/onetime-5.1.2.tgz",
      "integrity": "sha512-kbpaSSGJTWdAY5KPVeMOKXSrPtr8C8C7wodJbcsd51jRnmD+GZu8Y0VoU6Dm5Z4vWr0Ig/1NKuWRKf7j5aaYSg==",
      "license": "MIT",
      "dependencies": {
        "mimic-fn": "^2.1.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/patch-console": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/patch-console/-/patch-console-2.0.0.tgz",
      "integrity": "sha512-0YNdUceMdaQwoKce1gatDScmMo5pu/tfABfnzEqeG0gtTmd7mh/WcwgUjtAeOU7N8nFFlbQBnFK2gXW5fGvmMA==",
      "license": "MIT",
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      }
    },
    "node_modules/react": {
      "version": "19.2.3",
      "resolved": "https://registry.npmjs.org/react/-/react-19.2.3.tgz",
      "integrity": "sha512-Ku/hhYbVjOQnXDZFv2+RibmLFGwFdeeKHFcOTlrt7xplBnya5OGn/hIRDsqDiSUcfORsDC7MPxwork8jBwsIWA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-devtools-core": {
      "version": "6.1.5",
      "resolved": "https://registry.npmjs.org/react-devtools-core/-/react-devtools-core-6.1.5.tgz",
      "integrity": "sha512-ePrwPfxAnB+7hgnEr8vpKxL9cmnp7F322t8oqcPshbIQQhDKgFDW4tjhF2wjVbdXF9O/nyuy3sQWd9JGpiLPvA==",
      "license": "MIT",
      "dependencies": {
        "shell-quote": "^1.6.1",
        "ws": "^7"
      }
    },
    "node_modules/react-devtools-core/node_modules/ws": {
      "version": "7.5.10",
      "resolved": "https://registry.npmjs.org/ws/-/ws-7.5.10.tgz",
      "integrity": "sha512-+dbF1tHwZpXcbOJdVOkzLDxZP1ailvSxM6ZweXTegylPny803bFhA+vqBYw4s31NSAk4S2Qz+AKXK9a4wkdjcQ==",
      "license": "MIT",
      "engines": {
        "node": ">=8.3.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": "^5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/react-reconciler": {
      "version": "0.33.0",
      "resolved": "https://registry.npmjs.org/react-reconciler/-/react-reconciler-0.33.0.tgz",
      "integrity": "sha512-KetWRytFv1epdpJc3J4G75I4WrplZE5jOL7Yq0p34+OVOKF4Se7WrdIdVC45XsSSmUTlht2FM/fM1FZb1mfQeA==",
      "license": "MIT",
      "dependencies": {
        "scheduler": "^0.27.0"
      },
      "engines": {
        "node": ">=0.10.0"
      },
      "peerDependencies": {
        "react": "^19.2.0"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/restore-cursor": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/restore-cursor/-/restore-cursor-4.0.0.tgz",
      "integrity": "sha512-I9fPXU9geO9bHOt9pHHOhOkYerIMsmVaWB0rA2AI9ERh/+x/i7MV5HKBNrg+ljO5eoPVgCcnFuRjJ9uH6I/3eg==",
      "license": "MIT",
      "dependencies": {
        "onetime": "^5.1.0",
        "signal-exit": "^3.0.2"
      },
      "engines": {
        "node": "^12.20.0 || ^14.13.1 || >=16.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/scheduler": {
      "version": "0.27.0",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.27.0.tgz",
      "integrity": "sha512-eNv+WrVbKu1f3vbYJT/xtiF5syA5HPIMtf9IgY/nKg0sWqzAUEvqY/xm7OcZc/qafLx/iO9FgOmeSAp4v5ti/Q==",
      "license": "MIT"
    },
    "node_modules/shell-quote": {
      "version": "1.8.3",
      "resolved": "https://registry.npmjs.org/shell-quote/-/shell-quote-1.8.3.tgz",
      "integrity": "sha512-ObmnIF4hXNg1BqhnHmgbDETF8dLPCggZWBjkQfhZpbszZnYur5DUljTcCHii5LC3J5E0yeO/1LIMyH+UvHQgyw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==",
      "license": "ISC"
    },
    "node_modules/slice-ansi": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/slice-ansi/-/slice-ansi-7.1.2.tgz",
      "integrity": "sha512-iOBWFgUX7caIZiuutICxVgX1SdxwAVFFKwt1EvMYYec/NWO5meOJ6K5uQxhrYBdQJne4KxiqZc+KptFOWFSI9w==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.2.1",
        "is-fullwidth-code-point": "^5.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/chalk/slice-ansi?sponsor=1"
      }
    },
    "node_modules/stack-utils": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-2.0.6.tgz",
      "integrity": "sha512-XlkWvfIm6RmsWtNJx+uqtKLS8eqFbxUg0ZzLXqY0caEy9l7hruX8IpiDnjsLavoBgqCCR71TqWO8MaXYheJ3RQ==",
      "license": "MIT",
      "dependencies": {
        "escape-string-regexp": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/string-width": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-8.1.0.tgz",
      "integrity": "sha512-Kxl3KJGb/gxkaUMOjRsQ8IrXiGW75O4E3RPjFIINOVH8AMl2SQ/yWdTzWwF3FevIX9LcMAjJW+GRwAlAbTSXdg==",
      "license": "MIT",
      "dependencies": {
        "get-east-asian-width": "^1.3.0",
        "strip-ansi": "^7.1.0"
      },
      "engines": {
        "node": ">=20"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/strip-ansi": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.2.tgz",
      "integrity": "sha512-gmBGslpoQJtgnMAvOVqGZpEz9dyoKTCzy2nfz/n8aIFhN/jCE/rCmcxabB6jOOHV+0WNnylOxaxBQPSvcWklhA==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/to-rotated": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/to-rotated/-/to-rotated-1.0.0.tgz",
      "integrity": "sha512-KsEID8AfgUy+pxVRLsWp0VzCa69wxzUDZnzGbyIST/bcgcrMvTYoFBX/QORH4YApoD89EDuUovx4BTdpOn319Q==",
      "license": "MIT",
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/tsx": {
      "version": "4.21.0",
      "resolved": "https://registry.npmjs.org/tsx/-/tsx-4.21.0.tgz",
      "integrity": "sha512-5C1sg4USs1lfG0GFb2RLXsdpXqBSEhAaA/0kPL01wxzpMqLILNxIxIOKiILz+cdg/pLnOUxFYOR5yhHU666wbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "esbuild": "~0.27.0",
        "get-tsconfig": "^4.7.5"
      },
      "bin": {
        "tsx": "dist/cli.mjs"
      },
      "engines": {
        "node": ">=18.0.0"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.3"
      }
    },
    "node_modules/type-fest": {
      "version": "4.41.0",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-4.41.0.tgz",
      "integrity": "sha512-TeTSQ6H5YHvpqVwBRcnLDCBnDOHWYu7IvGbHT6N8AOymcr9PJGjc1GTtiWZTYg0NCgYwvnYWEkVChQAr9bjfwA==",
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=16"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typescript": {
      "version": "5.9.3",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.9.3.tgz",
      "integrity": "sha512-jl1vZzPDinLr9eUt3J/t7V6FgNEw9QjvBPdysz9KfQDD41fQrC2Y4vKQdiaUpFT4bXlb1RHhLpp8wtm6M5TgSw==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/undici-types": {
      "version": "7.16.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-7.16.0.tgz",
      "integrity": "sha512-Zz+aZWSj8LE6zoxD+xrjh4VfkIG8Ya6LvYkZqtUQGJPZjYl53ypCaUwWqo7eI0x66KBGeRo+mlBEkMSeSZ38Nw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/widest-line": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/widest-line/-/widest-line-5.0.0.tgz",
      "integrity": "sha512-c9bZp7b5YtRj2wOe6dlj32MK+Bx/M/d+9VB2SHM1OtsUHR0aV0tdP6DWh/iMt0kWi1t5g1Iudu6hQRNd1A4PVA==",
      "license": "MIT",
      "dependencies": {
        "string-width": "^7.0.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/widest-line/node_modules/string-width": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-7.2.0.tgz",
      "integrity": "sha512-tsaTIkKW9b4N+AEj+SVA+WhJzV7/zMhcSu78mLKWSk7cXMOSHsBKFWUs0fWwq8QyK3MgJBQRX6Gbi4kYbdvGkQ==",
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^10.3.0",
        "get-east-asian-width": "^1.0.0",
        "strip-ansi": "^7.1.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "9.0.2",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-9.0.2.tgz",
      "integrity": "sha512-42AtmgqjV+X1VpdOfyTGOYRi0/zsoLqtXQckTmqTeybT+BDIbM/Guxo7x3pE2vtpr1ok6xRqM9OpBe+Jyoqyww==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.2.1",
        "string-width": "^7.0.0",
        "strip-ansi": "^7.1.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/string-width": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-7.2.0.tgz",
      "integrity": "sha512-tsaTIkKW9b4N+AEj+SVA+WhJzV7/zMhcSu78mLKWSk7cXMOSHsBKFWUs0fWwq8QyK3MgJBQRX6Gbi4kYbdvGkQ==",
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^10.3.0",
        "get-east-asian-width": "^1.0.0",
        "strip-ansi": "^7.1.0"
      },
      "engines": {
        "node": ">=18"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ws": {
      "version": "8.19.0",
      "resolved": "https://registry.npmjs.org/ws/-/ws-8.19.0.tgz",
      "integrity": "sha512-blAT2mjOEIi0ZzruJfIhb3nps74PRWTCz1IjglWEEpQl5XS/UNama6u2/rjFkDDouqr4L67ry+1aGIALViWjDg==",
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": ">=5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/yoga-layout": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/yoga-layout/-/yoga-layout-3.2.1.tgz",
      "integrity": "sha512-0LPOt3AxKqMdFBZA3HBAt/t/8vIKq7VaQYbuA8WxCgung+p9TVyKRYdpvCb80HcdTN2NkbIKbhNwKUfm3tQywQ==",
      "license": "MIT"
    }
  }
}


============================================================
END FILE: cli/tui/package-lock.json
============================================================

============================================================
FILE: cli/tui/package.json
============================================================

{
  "name": "skills-fleet-tui",
  "version": "0.1.0",
  "description": "Interactive Terminal UI for Skills Fleet with streaming responses",
  "type": "module",
  "main": "dist/index.js",
  "scripts": {
    "start": "node dist/index.js",
    "build": "tsc",
    "dev": "tsx src/index.ts",
    "type-check": "tsc --noEmit"
  },
  "dependencies": {
    "eventsource-parser": "^3.0.0",
    "ink": "^6.6.0",
    "ink-text-input": "^6.0.0",
    "ink-select-input": "^6.2.0",
    "ink-spinner": "^5.0.0",
    "react": "^19.0.0",
    "react-devtools-core": "^6.1.2"
  },
  "devDependencies": {
    "@types/node": "^25.0.0",
    "@types/react": "^19.2.0",
    "typescript": "^5.9.0",
    "tsx": "^4.0.0"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}


============================================================
END FILE: cli/tui/package.json
============================================================

============================================================
FILE: cli/tui/tsconfig.json
============================================================

{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "lib": ["ES2022"],
    "moduleResolution": "bundler",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": false,
    "declaration": true,
    "sourceMap": true,
    "noImplicitAny": false,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true,
    "jsx": "react",
    "types": ["node"]
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}


============================================================
END FILE: cli/tui/tsconfig.json
============================================================

============================================================
FILE: config/config.yaml
============================================================

# config.yaml - Single source of truth for `skills-fleet` LLM configuration
#
# Default model: gemini/gemini-3-flash-preview (LiteLLM format for Gemini 3 Flash)
#
# Required env:
#   - GOOGLE_API_KEY
#   - LITELLM_API_KEY
#
# Optional env:
#   - DSPY_TEMPERATURE (override temperature globally)
#
# LiteLLM v1.80.8-stable.1+ required for Gemini 3 Flash features

dspy:
  adapter: chat

models:
  default: gemini/gemini-3-flash-preview

  registry:
    gemini/gemini-3-flash-preview:
      model: gemini-3-flash-preview
      model_type: chat
      env: GOOGLE_API_KEY
      env_fallback: LITELLM_API_KEY
      timeout: 60
      parameters:
        temperature: 1.0
        max_tokens: 8192

    gemini/gemini-3-pro-preview:
      model: gemini-3-pro-preview
      model_type: chat
      env: GOOGLE_API_KEY
      env_fallback: LITELLM_API_KEY
      timeout: 120
      parameters:
        temperature: 1.0  # Gemini 3 models require temperature=1.0 per documentation
        max_tokens: 16384

roles:
  router:
    model: gemini/gemini-3-flash-preview
    description: "Routes requests and selects workflow patterns"
    capabilities: [pattern_detection, team_selection, complexity_assessment]
    parameter_overrides:
      reasoning_effort: high

  planner:
    model: gemini/gemini-3-flash-preview
    description: "Creates detailed plans and orchestrates skill selection"
    capabilities: [task_decomposition, skill_orchestration, dependency_analysis]
    parameter_overrides: {}

  worker:
    model: gemini/gemini-3-flash-preview
    description: "Executes work steps"
    capabilities: [file_operations, skill_execution, content_generation]
    parameter_overrides: {}

  judge:
    model: gemini/gemini-3-flash-preview
    description: "Evaluates results and validates completion quality"
    capabilities: [quality_assessment, validation, critique_generation]
    parameter_overrides: {}

tasks:
  # Skill Creation Workflow (6-step process)
  skill_understand:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: medium

  skill_plan:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: high

  skill_initialize:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: high

  skill_edit:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: high

  skill_package:
    model: gemini/gemini-3-flash-preview
    role: worker
    parameters:
      reasoning_effort: medium

  skill_validate:
    model: gemini/gemini-3-flash-preview
    role: judge
    parameters:
      reasoning_effort: high

  # Conversational Agent (Interactive CLI)
  conversational_agent:
    model: gemini/gemini-3-flash-preview
    role: planner
    parameters:
      reasoning_effort: high  # High thinking for complex reasoning in conversation

  # Evaluation & Optimization Tasks
  skill_evaluate:
    model: gemini/gemini-3-flash-preview
    role: judge
    parameters:
      temperature: 1.0  # Keep 1.0 for Gemini 3 models
      # Note: reasoning_effort removed - not supported by Gemini via LiteLLM

  skill_optimize:
    model: gemini/gemini-3-flash-preview  # Using flash for reliability
    role: judge
    parameters:
      temperature: 1.0  # Gemini 3 models require temperature=1.0
      # Note: reasoning_effort removed - not supported by Gemini via LiteLLM

# Optimization Configuration
optimization:
  # Default optimizer to use
  default_optimizer: miprov2

  # MIPROv2 optimizer settings
  miprov2:
    auto: "medium"  # Balance between optimization depth and cost (light/medium/heavy)
    num_threads: 4
    max_bootstrapped_demos: 4
    max_labeled_demos: 4
    verbose: true

  # BootstrapFewShot optimizer settings
  bootstrap_fewshot:
    max_bootstrapped_demos: 4
    max_labeled_demos: 4
    max_rounds: 1
    max_errors: 5

  # Training data paths
  training:
    gold_skills_path: "config/training/gold_skills.json"
    quality_criteria_path: "config/training/quality_criteria.yaml"
    optimized_programs_dir: "config/optimized"

# Evaluation Configuration
evaluation:
  # Number of threads for parallel evaluation
  num_threads: 8
  display_progress: true
  display_table: true

  # Quality thresholds
  thresholds:
    minimum_quality: 0.6
    target_quality: 0.8
    excellent_quality: 0.9

  # Metrics weights for overall score
  metric_weights:
    pattern_count: 0.15
    has_anti_patterns: 0.10
    has_key_insights: 0.10
    has_real_world_impact: 0.10
    has_quick_reference: 0.10
    has_common_mistakes: 0.10
    has_red_flags: 0.05
    frontmatter_completeness: 0.15
    code_examples_quality: 0.15


============================================================
END FILE: config/config.yaml
============================================================

============================================================
FILE: config/optimized/benchmark_results.json
============================================================

[
  {
    "optimizer": "BootstrapFewShot",
    "baseline": 80.0,
    "optimized": 80.0,
    "improvement": 0.0,
    "improvement_pct": 0.0,
    "time_seconds": 0.38899993896484375,
    "cost_estimate": "$0.00 (free - uses existing traces)"
  },
  {
    "optimizer": "BootstrapFewShot (Reflection Metrics)",
    "baseline": 46.7,
    "optimized": 47.4,
    "improvement": 0.6999999999999957,
    "improvement_pct": 1.4989293361884277,
    "time_seconds": 0.06296706199645996,
    "cost_estimate": "$0.01-0.05 (metrics evaluation only)"
  },
  {
    "optimizer": "MIPROv2 (Light)",
    "baseline": 80.0,
    "optimized": 80.0,
    "improvement": 0.0,
    "improvement_pct": 0.0,
    "time_seconds": 264.94513392448425,
    "cost_estimate": "$5-10 (LLM calls for optimization)"
  }
]

============================================================
END FILE: config/optimized/benchmark_results.json
============================================================

============================================================
FILE: config/optimized/miprov2/metadata.json
============================================================

{
  "dependency_versions": {
    "python": "3.13",
    "dspy": "3.1.0",
    "cloudpickle": "3.1"
  }
}


============================================================
END FILE: config/optimized/miprov2/metadata.json
============================================================

============================================================
FILE: config/optimized/optimization_results_bootstrap_v1.json
============================================================

{
  "optimizer": "BootstrapFewShot",
  "trainset_size": 40,
  "testset_size": 10,
  "baseline_score": 80.0,
  "optimized_score": 80.0,
  "improvement": 0.0,
  "improvement_percent": 0.0
}

============================================================
END FILE: config/optimized/optimization_results_bootstrap_v1.json
============================================================

============================================================
FILE: config/optimized/optimization_results_reflection_metrics_v1.json
============================================================

{
  "optimizer": "BootstrapFewShot (with reflection metrics)",
  "metric_type": "composite",
  "reflection_model": "gemini-3-flash-preview",
  "trainset_size": 40,
  "testset_size": 10,
  "baseline_score": 46.7,
  "optimized_score": 47.4,
  "improvement": 0.6999999999999957,
  "improvement_percent": 1.4989293361884277
}

============================================================
END FILE: config/optimized/optimization_results_reflection_metrics_v1.json
============================================================

============================================================
FILE: config/optimized/skill_creator_bootstrap_v1.json
============================================================

{
  "phase1.gather_requirements.gather.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**âŒ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**âœ… Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**âŒ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # âŒ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**âœ… Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync â†’ Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**âœ… Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**âŒ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**âœ… Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | âœ… Yes       |\n| `fastapi run main.py`             | Production server  | âŒ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | âœ… Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | âŒ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management â†’ 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      }
    ],
    "signature": {
      "instructions": "Initial requirements gathering from task description.\n\nExtract basic requirements before detailed analysis:\n- What domain/category?\n- What level (beginner/intermediate/advanced)?\n- What specific topics to cover?\n- Any constraints or preferences?",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description (may include clarifications)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Domain:",
          "description": "Primary domain: 'technical', 'cognitive', 'domain_knowledge', etc."
        },
        {
          "prefix": "Category:",
          "description": "Category within domain: 'programming', 'devops', 'data_science', etc."
        },
        {
          "prefix": "Target Level:",
          "description": "Target level: 'beginner', 'intermediate', 'advanced', 'expert'"
        },
        {
          "prefix": "Topics:",
          "description": "List of specific topics to cover (3-7 items)"
        },
        {
          "prefix": "Constraints:",
          "description": "Any constraints or preferences (e.g., 'focus on Python 3.12+', 'no deprecated patterns')"
        },
        {
          "prefix": "Ambiguities:",
          "description": "Detected ambiguities that need clarification via HITL"
        }
      ]
    },
    "lm": null
  },
  "phase1.analyze_intent.analyze.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**âŒ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**âœ… Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**âŒ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # âŒ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**âœ… Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync â†’ Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**âœ… Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**âŒ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**âœ… Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | âœ… Yes       |\n| `fastapi run main.py`             | Production server  | âŒ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | âœ… Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | âŒ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management â†’ 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      }
    ],
    "signature": {
      "instructions": "Deeply analyze user intent to understand what skill is needed.\n\nThis is one of three parallel analyses in Phase 1. Focus on:\n- WHY is this skill needed?\n- WHAT problem does it solve?\n- WHO is the target user?\n- WHAT value does it provide?\n\nUse chain-of-thought reasoning for thorough analysis.",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description with any clarifications"
        },
        {
          "prefix": "User Context:",
          "description": "JSON user context (user_id, existing skills, preferences)"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Task Intent:",
          "description": "Structured intent with: purpose, problem_statement, target_audience, value_proposition"
        },
        {
          "prefix": "Skill Type:",
          "description": "Type of skill: 'how_to', 'reference', 'concept', 'workflow', 'checklist'"
        },
        {
          "prefix": "Scope:",
          "description": "Scope description: what's included and excluded"
        },
        {
          "prefix": "Success Criteria:",
          "description": "How will we know this skill is successful? (3-5 criteria)"
        }
      ]
    },
    "lm": null
  },
  "phase1.find_taxonomy.find_path.predict": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**âŒ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**âœ… Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**âŒ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # âŒ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**âœ… Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync â†’ Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**âœ… Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-csv\")\nasync def upload_csv(file: UploadFile):\n    # Stream the file - don't load entirely into memory\n    df = pd.read_csv(file.file)\n    results = process_data_frame(df)\n    return {\"uploaded\": len(results), \"data\": results}\n```\n\n### 8. Background Tasks\n\n**For operations longer than HTTP timeout:**\n```python\nfrom fastapi import BackgroundTasks\n\ndef long_running_task(task_id: str):\n    result = process_heavy_computation()\n    mark_task_complete(task_id, result)\n\n@app.post(\"/process\")\nasync def start_process(background_tasks: BackgroundTasks):\n    task_id = generate_task_id()\n    background_tasks.add_task(long_running_task, task_id)\n    return {\"task_id\": task_id, \"status\": \"processing\"}\n\n# For production: Use Celery for retries and distributed execution\n```\n\n### 9. FastAPI CLI (New in 0.128.0)\n\n**The problem:** Running FastAPI apps required manual uvicorn commands. Developers had to remember different commands for development vs production.\n\n**âŒ Old approach (still works but not recommended):**\n```bash\n# Development with auto-reload\nuvicorn main:app --reload\n\n# Production\nuvicorn main:app --host 0.0.0.0 --port 8000\n```\n\n**âœ… Modern approach with FastAPI CLI:**\n```bash\n# Installation (includes CLI + all standard dependencies)\npip install \"fastapi[standard]\"\n\n# Development with auto-reload\nfastapi dev main.py\n\n# Production\nfastapi run main.py --workers 4\n```\n\n**CLI Command Reference:**\n\n| Command                           | Purpose            | Auto-reload |\n|-----------------------------------|--------------------|-------------|\n| `fastapi dev main.py`             | Development server | âœ… Yes       |\n| `fastapi run main.py`             | Production server  | âŒ No        |\n| `fastapi dev main.py --port 8080` | Custom port        | âœ… Yes       |\n| `fastapi run main.py --workers 4` | Multiple workers   | âŒ No        |\n\n**Key benefits:**\n- Unified CLI for development and production\n- Auto-reload by default in dev mode\n- Includes all standard dependencies (uvicorn, httpx, jinja2, python-multipart)\n- Better error messages and output formatting\n\n> **For comprehensive CLI documentation**, see the [FastAPI CLI capability](capabilities/fastapi-cli.md)\n\n**Installation with all standard dependencies:**\n```bash\npip install \"fastapi[standard]\"\n```\n\nThis installs:\n- `fastapi` - Core framework\n- `uvicorn[standard]` - ASGI server with high-performance dependencies\n- `fastapi-cli[standard]` - CLI tool (includes deployment tools)\n- `httpx` - For testing\n- `jinja2` - For templates\n- `python-multipart` - For form data\n\n**Optional: FastAPI Cloud deployment:**\n```bash\nfastapi login\nfastapi deploy\n```\n\n> **Note:** FastAPI Cloud is optional. You can deploy to any cloud provider (AWS, GCP, Azure, Railway, etc.) using traditional deployment methods.\n\n## Common Mistakes\n\n| Mistake                             | Why It's Wrong                                    | Fix                                            |\n|-------------------------------------|---------------------------------------------------|------------------------------------------------|\n| Creating DB engine at import time   | Connections never close, workers leak connections | Create in `lifespan`, dispose in shutdown      |\n| Using `requests` in async endpoints | Blocks entire event loop                          | Use `httpx.AsyncClient`                        |\n| Forgetting `exclude_unset=True`     | Optional fields become `None` and overwrite data  | Use `exclude_unset=True` for PATCH             |\n| Sync fixtures with async tests      | Tests hang or fail mysteriously                   | Use `@pytest.mark.asyncio` with async fixtures |\n| Global state for dependencies       | Can't test, hard to manage lifecycle              | Use `Depends()` with yield                     |\n| Not setting `pool_recycle`          | Database closes idle connections, causing errors  | Set `pool_recycle=3600` or similar             |\n| Using `run_in_executor` as band-aid | Still blocks threads, doesn't scale               | Proper async conversion                        |\n| Missing `max_overflow` parameter    | Pool can't burst under load, requests queue       | Set `max_overflow=20` or similar               |\n\n## Real-World Impact\n\n- **Connection pool exhaustion** fixed with proper lifecycle management â†’ 50 concurrent requests without errors\n- **Test execution time** reduced 80% with proper async fixtures\n- **API response validation** caught 15% of frontend bugs before deployment\n- **Memory usage** reduced 60% by streaming file uploads instead of loading into memory\n- **\"Too many connections\" DB errors** eliminated with proper shutdown handling\n\n## Red Flags - STOP and Reconsider\n\n- Code that \"works locally\" but you haven't load tested\n- Creating database connections at module level\n- Using `@app.on_event(\"startup\")` (deprecated)\n- Missing shutdown handlers\n- No pool parameters on engine creation\n- Using `requests` library in async functions\n- Tests that only pass when run individually\n- `run_in_executor` as primary async strategy\n\n**All of these mean: Revisit your architecture. Production will break.**\n"
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/decorators",
        "skill_content": "---\nname: python-decorators\ndescription: Ability to design, implement, and apply higher-order functions to extend\n  or modify the behavior of functions and classes in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/decorators\n  version: 1.0.0\n---\n\n# Python Decorators: Functional and Metaprogramming Patterns\n\n## Overview\nPython decorators are a powerful form of metaprogramming used to modify or enhance the behavior of functions or classes without permanently modifying their source code. They rely on Python's first-class function support and closure mechanics.\n\n## Core Concepts\n- **Closures**: Functions that \"remember\" the environment in which they were created.\n- **First-Class Citizens**: The ability to pass functions as arguments, return them from other functions, and assign them to variables.\n- **Syntactic Sugar**: The `@decorator` syntax is equivalent to `func = decorator(func)`.\n\n## Modules\n\n### 1. Basic Function Decorators\nFocuses on the standard wrapper pattern.\n- **Simple Logger**: Intercepting calls to log arguments and return values.\n- **Metadata Preservation**: Critical use of `functools.wraps` to prevent losing the original function's identity (`__name__`, `__doc__`).\n\n### 2. Parameterized Decorators (Decorator Factories)\nMoving beyond simple wrappers to \"factories\" that return decorators.\n- Implementation of the triple-nested function structure: `outer_params(actual_decorator(wrapped_func))`.\n- Use cases: `@retry(times=3)`, `@access_level(\"admin\")`.\n\n### 3. Class-Based Decorators\nUtilizing the `__call__` dunder method to treat an object instance as a decorator.\n- Maintaining state within instance attributes rather than closures.\n\n### 4. Stateful & Memoization\nAdvanced patterns for performance and tracking.\n- **Call Counting**: Monitoring execution frequency.\n- **Memoization**: Caching expensive computation results based on input arguments (e.g., implementing a custom LRU cache).\n\n### 5. Composition and Order\nUnderstanding the \"Onion\" model of execution.\n- Order of application: Bottom-to-top.\n- Order of execution: Top-to-bottom."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      }
    ],
    "signature": {
      "instructions": "Determine optimal taxonomy placement for this skill.\n\nThis is one of three parallel analyses in Phase 1. Analyze the\ntaxonomy structure and find the best location for this skill.\n\nRules:\n- Prefer deeper paths (more specific is better)\n- Consider existing skills in similar categories\n- Follow taxonomy naming conventions\n- Avoid creating new top-level categories",
      "fields": [
        {
          "prefix": "Task Description:",
          "description": "User's task description"
        },
        {
          "prefix": "Taxonomy Structure:",
          "description": "JSON representation of full taxonomy structure"
        },
        {
          "prefix": "Existing Skills:",
          "description": "List of existing skill paths for reference"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Recommended Path:",
          "description": "Recommended taxonomy path (e.g., 'technical_skills/programming/python/async')"
        },
        {
          "prefix": "Alternative Paths:",
          "description": "2-3 alternative paths if primary has issues"
        },
        {
          "prefix": "Path Rationale:",
          "description": "Why this path is optimal (mention similar skills, category fit, etc.)"
        },
        {
          "prefix": "New Directories:",
          "description": "Any new directories that need to be created (empty if using existing path)"
        },
        {
          "prefix": "Confidence:",
          "description": "Confidence in path selection 0-1. <0.7 means may need user confirmation"
        }
      ]
    },
    "lm": null
  },
  "phase1.analyze_dependencies.analyze": {
    "traces": [],
    "train": [],
    "demos": [
      {
        "task_description": "Create a skill based on: technical_skills/programming/languages/python/asynchronous_programming",
        "skill_content": "---\nname: python-asynchronous-programming\ndescription: Implementation and management of non-blocking code using asyncio, event\n  loops, and concurrent execution patterns in Python.\nmetadata:\n  skill_id: technical_skills/programming/languages/python/asynchronous_programming\n  version: 1.0.0\n---\n\n# Python Asynchronous Programming (asyncio)\n\n## Overview\nAsynchronous programming in Python, powered by the `asyncio` library, enables high-performance concurrent execution using a single-threaded event loop. This skill covers the transition from traditional blocking code to non-blocking, cooperative multitasking, allowing for thousands of simultaneous connections without the overhead of heavy threading.\n\n## Core Concepts\n- **Coroutines**: Functions defined with `async def` that can be paused and resumed.\n- **Event Loop**: The central scheduler that manages and executes asynchronous tasks.\n- **Awaitables**: Objects that can be used in an `await` expression (Coroutines, Tasks, Futures).\n- **Non-blocking I/O**: Performing input/output operations without stalling the execution of other tasks.\n\n## Key Components\n- **Task Management**: Using `asyncio.create_task` for concurrent execution and `asyncio.gather` for aggregating results.\n- **Error Handling**: Managing `asyncio.CancelledError` and timeouts to ensure system resilience.\n- **Synchronization**: Using async-aware `Locks`, `Semaphores`, and `Queues` to coordinate state between coroutines.\n- **Blocking Interop**: Offloading CPU-bound or legacy blocking I/O to threads or processes via `run_in_executor`."
      },
      {
        "task_description": "Create a skill based on: technical_skills/programming/web_frameworks/python/fastapi",
        "skill_content": "---\nname: fastapi-production-patterns\ndescription: Use when building FastAPI apps with async database operations, complex dependency injection, partial update endpoints, async testing, or converting Python utilities to API endpoints\nlicense: MIT\ncompatibility: Requires Python 3.8+, FastAPI 0.128.0+, SQLAlchemy 2.0+\nmetadata:\n  skill_id: technical/programming/web-frameworks/python/fastapi\n  version: 1.0.0\n  type: technical\n  weight: medium\n  load_priority: task_specific\n---\n\n# FastAPI Production Patterns\n\n## Overview\nProven patterns for building production-ready FastAPI applications that avoid common silent failures: connection pool exhaustion, blocking async operations, partial update bugs, and test isolation issues.\n\n**Core principle:** Code that works in development but fails under load is NOT production-ready. Database engines MUST be created in lifespan, connections MUST be disposed on shutdown, and async operations MUST NOT block.\n\n## When to Use\n**When to use:**\n\n```dot\ndigraph when_to_use {\n    \"Building FastAPI app?\" [shape=diamond];\n    \"Async DB operations?\" [shape=diamond];\n    \"Need to test async endpoints?\" [shape=diamond];\n    \"Converting Python utilities to APIs?\" [shape=diamond];\n    \"PATCH with partial updates?\" [shape=diamond];\n    \"Use this skill\" [shape=box];\n\n    \"Building FastAPI app?\" -> \"Async DB operations?\" [label=\"yes\"];\n    \"Async DB operations?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Need to test async endpoints?\" [label=\"yes\"];\n    \"Need to test async endpoints?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"Converting Python utilities to APIs?\" [label=\"yes\"];\n    \"Converting Python utilities to APIs?\" -> \"Use this skill\" [label=\"yes\"];\n    \"Building FastAPI app?\" -> \"PATCH with partial updates?\" [label=\"yes\"];\n    \"PATCH with partial updates?\" -> \"Use this skill\" [label=\"yes\"];\n}\n```\n\n**When NOT to use:**\n- Simple synchronous APIs without database operations\n- Learning basic FastAPI routing (use official docs instead)\n- Trivial CRUD with no production requirements\n\n## Quick Reference\n\n| Problem                                   | Solution                                                   | Keywords                                               |\n|-------------------------------------------|------------------------------------------------------------|--------------------------------------------------------|\n| DB connections not closing on shutdown    | Use `lifespan` context manager with `engine.dispose()`     | connection leak, too many connections, pool exhaustion |\n| Pool exhaustion under load                | Set `pool_size`, `max_overflow`, create engine in lifespan | connection timeout, concurrent requests, workers       |\n| Tests pass isolation but fail in parallel | Use async fixtures with proper isolation                   | flaky tests, test bleeding, async test                 |\n| PATCH partial updates not validating      | Use `Optional` fields with `exclude_unset=True`            | partial updates, None overwriting, PATCH               |\n| Converting sync utilities to async        | Replace blocking libraries with async equivalents          | blocking, async conversion, requests to httpx          |\n| Long operations timeout HTTP              | Use `BackgroundTasks` or Celery                            | timeout, long running, background                      |\n\n## Core Patterns\n\n### 1. Database Lifecycle Management\n\n**The problem:** Engines created at import time never close connections. Deprecated `@app.on_event` handlers miss proper cleanup. Missing pool parameters cause exhaustion under load.\n\n**âŒ Common but broken (baseline failure):**\n```python\n# database.py - Created at import time!\nengine = create_async_engine(DATABASE_URL)\n\n# main.py - Deprecated pattern\n@app.on_event(\"startup\")\nasync def startup():\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n# NO shutdown handler - connections leak forever!\n```\n\n**âœ… Production pattern:**\n```python\nfrom contextlib import asynccontextmanager\nfrom sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup - create engine HERE, not at import\n    engine = create_async_engine(\n        DATABASE_URL,\n        pool_size=10,           # Critical for multi-worker deployments\n        max_overflow=20,        # Allow bursting above pool_size\n        pool_recycle=3600,      # Recycle connections after 1 hour\n    )\n    app.state.db_engine = engine\n\n    # Create tables\n    async with engine.begin() as conn:\n        await conn.run_sync(Base.metadata.create_all)\n\n    yield\n\n    # Shutdown - CRITICAL: close connections\n    await engine.dispose()\n\napp = FastAPI(lifespan=lifespan)\n\nasync def get_db() -> AsyncSession:\n    async with AsyncSession(app.state.db_engine) as session:\n        yield session\n```\n\n**Key insight:** Engine creation in lifespan + dispose in shutdown = no connection leaks. Pool parameters prevent exhaustion when multiple workers start simultaneously.\n\n### 2. Pydantic Partial Updates\n\n**The problem:** PATCH endpoints should only update provided fields, but naive implementations overwrite everything with `None`.\n\n**âŒ Common mistake (None overwrites):**\n```python\n@app.patch(\"/users/{user_id}\")\nasync def update_user(user_id: int, update: UserUpdate, db: AsyncSession = Depends(get_db)):\n    user = await db.get(User, user_id)\n    # âŒ This sets unprovided fields to None!\n    user.name = update.name  # None if not provided\n    user.email = update.email  # None if not provided\n    await db.commit()\n    return user\n```\n\n**âœ… Production pattern:**\n```python\nfrom pydantic import BaseModel, Optional\nfrom typing import Optional\n\nclass UserUpdate(BaseModel):\n    name: Optional[str] = None\n    email: Optional[str] = None\n    age: Optional[int] = None\n\n@app.patch(\"/users/{user_id}\")\nasync def update_user(\n    user_id: int,\n    update: UserUpdate,\n    db: AsyncSession = Depends(get_db)\n):\n    user = await db.get(User, user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    # CRITICAL: Only update provided fields\n    update_data = update.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(user, field, value)\n\n    await db.commit()\n    await db.refresh(user)\n    return user\n```\n\n**Key insight:** `exclude_unset=True` only includes fields actually provided in the request, preventing `None` overwrites.\n\n### 3. Converting Python Functions to Endpoints\n\n**The problem:** Existing Python code needs API exposure. Common mistakes: blocking operations, missing validation, no error handling, wrong return types.\n\n**Transformation steps:**\n1. Add Pydantic models for request/response\n2. Make functions async if they do I/O\n3. Replace exceptions with `HTTPException`\n4. Add `response_model` for validation\n5. Use `Depends` for shared resources\n\n**Before - Blocking utility:**\n```python\ndef process_payment(user_id: int, amount: float, card: dict) -> dict:\n    result = db.execute(f\"SELECT * FROM users WHERE id = {user_id}\")  # Blocking!\n    if result['balance'] < amount:\n        raise ValueError(\"Insufficient funds\")  # 500 error!\n    return {\"status\": \"success\"}\n\n# Naive wrapper\n@app.post(\"/payment\")\ndef payment_endpoint(user_id: int, amount: float, card: dict):\n    return process_payment(user_id, amount, card)  # No validation!\n```\n\n**After - Production endpoint:**\n```python\nfrom pydantic import BaseModel, Field, validator\nfrom fastapi import HTTPException\n\nclass CreditCard(BaseModel):\n    number: str = Field(..., min_length=13, max_length=19)\n    expiry: str\n    cvv: str = Field(..., min_length=3, max_length=4)\n\n    @validator('number')\n    def luhn_check(cls, v):\n        if not luhn_valid(v):\n            raise ValueError('Invalid card number')\n        return v\n\nclass PaymentRequest(BaseModel):\n    user_id: int\n    amount: float = Field(..., gt=0)  # Must be positive\n    card: CreditCard\n\nclass PaymentResponse(BaseModel):\n    status: str\n    transaction_id: str\n\n@app.post(\"/payment\", response_model=PaymentResponse)\nasync def payment_endpoint(\n    request: PaymentRequest,\n    db: AsyncSession = Depends(get_db)\n):\n    # Async database call\n    user = await db.get(User, request.user_id)\n    if not user:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n\n    if user.balance < request.amount:\n        raise HTTPException(status_code=400, detail=\"Insufficient funds\")\n\n    transaction_id = await process_payment_async(request, db)\n    return PaymentResponse(status=\"success\", transaction_id=transaction_id)\n```\n\n### 4. Sync to Async Conversion\n\n**Sync â†’ Async library mapping:**\n\n| Sync Library   | Async Replacement           |\n|----------------|-----------------------------|\n| `requests`     | `httpx.AsyncClient`         |\n| `sqlalchemy`   | `sqlalchemy.ext.asyncio`    |\n| `time.sleep()` | `asyncio.sleep()`           |\n| `open()`       | `aiofiles`                  |\n| `subprocess`   | `asyncio.create_subprocess` |\n| `redis`        | `aioredis`                  |\n\n**Pattern:**\n```python\n# Before - blocking\ndef get_user_data(user_id: int) -> dict:\n    user = db.session.query(User).filter(User.id == user_id).first()\n    response = requests.get(f\"https://api.external.com/user/{user_id}\")\n    return {\"user\": user, \"external\": response.json()}\n\n# After - async\nasync def get_user_data(user_id: int, db: AsyncSession) -> dict:\n    result = await db.execute(select(User).where(User.id == user_id))\n    user = result.scalar_one_or_none()\n\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"https://api.external.com/user/{user_id}\")\n\n    return {\"user\": user, \"external\": response.json()}\n```\n\n### 5. Dependency Injection Patterns\n\n**Caching dependencies:**\n```python\nfrom functools import lru_cache\n\n@lru_cache()\ndef get_settings():\n    return Settings()  # Singleton, created once\n\n@lru_cache()\ndef get_redis_client():\n    return redis.Redis(host=settings.REDIS_HOST)\n```\n\n**Testing with overrides:**\n```python\nfrom fastapi.testclient import TestClient\n\ndef test_update_user():\n    async def override_get_db():\n        return test_session  # Use test DB\n\n    app.dependency_overrides[get_db] = override_get_db\n    try:\n        response = client.patch(\"/users/1\", json={\"name\": \"Test\"})\n    finally:\n        app.dependency_overrides.clear()  # Always clean up\n```\n\n**Yield dependencies for cleanup:**\n```python\nasync def get_db():\n    async with AsyncSession(engine) as session:\n        yield session\n        # Automatic cleanup after response\n```\n\n### 6. Async Testing\n\n**The problem:** Using sync `TestClient` with async endpoints causes hangs. Tests pass in isolation but fail together due to database bleeding.\n\n**âœ… Production pattern:**\n```python\nimport pytest\nfrom httpx import AsyncClient\n\n@pytest.fixture\nasync def async_client():\n    async with AsyncClient(app=app, base_url=\"http://test\") as ac:\n        yield ac\n\n@pytest.fixture\nasync def db_session():\n    engine = create_async_engine(TEST_DATABASE_URL)\n    async with AsyncSession(engine) as session:\n        yield session\n        await session.rollback()  # Clean up after test\n\n@pytest.mark.asyncio\nasync def test_create_user(async_client: AsyncClient):\n    response = await async_client.post(\"/users\", json={\n        \"name\": \"Alice\",\n        \"email\": \"alice@example.com\"\n    })\n    assert response.status_code == 200\n```\n\n### 7. File Upload Handling\n\n**Stream, don't load entirely:**\n```python\nfrom fastapi import UploadFile\nimport pandas as pd\n\n@app.post(\"/upload-