<!-- Chunk 821: bytes 2744958-2808096, type=class -->
class StreamingClient {
    async streamChat(options: StreamingOptions) {
        // Connect to SSE endpoint
        const response = await fetch('/api/v1/chat/stream', {
            method: 'POST',
            body: JSON.stringify({ message, context })
        });
        
        // Parse SSE stream
        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        
        while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            
            // Parse SSE format: "event: type\ndata: {...}\n\n"
            const line = decoder.decode(value);
            
            if (line.startsWith('event: thinking')) {
                options.onThinking(JSON.parse(data));
            } else if (line.startsWith('event: response')) {
                options.onResponse(JSON.parse(data));
            } else if (line.startsWith('event: complete')) {
                options.onComplete();
            }
        }
    }
}
```

### 4. Ink TUI Chat Component

**File**: `cli/tui/src/tabs/chat-tab.tsx`

```typescript
export const ChatTab: React.FC<ChatTabProps> = ({ apiUrl, isActive }) => {
    const [messages, setMessages] = useState<Message[]>([]);
    const streamingClient = new StreamingClient();

    const handleSubmit = async (message: string) => {
        // Add user message
        setMessages(prev => [...prev, { role: 'user', content: message }]);

        // Stream assistant response
        await streamingClient.streamChat({
            apiUrl,
            message,
            onThinking: (chunk) => {
                // Display thinking chunk (colored)
                setMessages(prev => [...prev, {
                    role: 'thinking',
                    content: formatThinking(chunk),
                    thinking_type: chunk.type
                }]);
            },
            onResponse: (chunk) => {
                // Accumulate and update response
                setMessages(prev => {
                    const last = prev[prev.length - 1];
                    if (last?.role === 'assistant') {
                        last.content += chunk.content;
                    }
                    return prev;
                });
            },
            onComplete: () => {
                // Generate suggestions
                generateSuggestions(message);
            }
        });
    };

    return (
        <Box flexDirection="column">
            {/* Display messages with thinking/response separation */}
            {messages.map(msg => (
                <Text color={msg.role === 'thinking' ? 'gray' : 'green'}>
                    {msg.role === 'thinking' ? `üí≠ ${msg.content}` : msg.content}
                </Text>
            ))}
            
            {/* Input field */}
            <TextInput value={input} onChange={setInput} onSubmit={handleSubmit} />
        </Box>
    );
};
```

## Event Types & Formats

### Thinking Event

```json
{
  "type": "thinking",
  "data": {
    "type": "thought|reasoning|internal|step",
    "content": "What the AI is thinking about",
    "step": 1
  }
}
```

**Types**:
- `thought` (üí≠): Initial observation or idea
- `reasoning` (ü§î): Logical deduction or analysis
- `internal` (‚öôÔ∏è): System/implementation detail
- `step` (‚ñ∂Ô∏è): Step in a multi-step process

### Response Event

```json
{
  "type": "response",
  "data": {
    "type": "response|complete",
    "content": "Chunk of text being generated"
  }
}
```

### Complete Event

```
event: complete
data:

```

Empty data signals end of stream.

### Error Event

```json
{
  "type": "error",
  "data": "Error message string"
}
```

## Usage Examples

### JavaScript/TypeScript

```typescript
const client = new StreamingClient();

await client.streamChat({
    apiUrl: "http://localhost:8000",
    message: "Create a skill for JSON parsing",
    
    onThinking: (chunk) => {
        console.log(`[${chunk.type}] ${chunk.content}`);
    },
    
    onResponse: (chunk) => {
        process.stdout.write(chunk.content);
    },
    
    onError: (error) => {
        console.error("Error:", error);
    },
    
    onComplete: () => {
        console.log("\n\nDone!");
    }
});
```

### Python (for testing)

```python
import httpx
import asyncio
import json

async def stream_chat():
    async with httpx.AsyncClient() as client:
        async with client.stream(
            "POST",
            "http://localhost:8000/api/v1/chat/stream",
            json={"message": "optimize my skill"},
            headers={"Accept": "text/event-stream"}
        ) as response:
            async for line in response.aiter_lines():
                if line.startswith("event:"):
                    event_type = line.split(":", 1)[1].strip()
                elif line.startswith("data:"):
                    data_str = line.split(":", 1)[1].strip()
                    if data_str:
                        data = json.loads(data_str)
                        print(f"[{event_type}] {data}")

asyncio.run(stream_chat())
```

## Benefits

1. **Real-time Visibility**: See the AI's thinking process as it happens
2. **Better UX**: Responsive interface with streaming chunks instead of waiting
3. **Transparency**: Understand how intent is parsed and responses are generated
4. **Debugging**: Trace through signature + reasoning for troubleshooting
5. **Educational**: Learn how LMs work by observing thinking steps
6. **Agentic**: Show suggestions based on intermediate thinking

## Performance Considerations

- **Small chunks**: Stream events are small (50-200 bytes typically)
- **Low latency**: SSE events are sent as soon as generated
- **Network efficient**: HTTP/1.1 with keep-alive
- **Memory efficient**: No buffering of full responses

## Fallback: Synchronous Mode

If streaming is unavailable:

```python
@router.post("/chat/sync")
async def chat_sync(request: ChatMessageRequest):
    """Non-streaming response (collects all events first)."""
    assistant = StreamingAssistant()
    
    thinking_steps = []
    responses = []
    
    async for event in assistant.forward_streaming(...):
        if event["type"] == "thinking":
            thinking_steps.append(...)
        elif event["type"] == "response":
            responses.append(...)
    
    return {
        "thinking": thinking_steps,
        "response": "".join(responses),
        "thinking_summary": assistant.get_thinking_summary()
    }
```

## Testing Streaming

```bash
# 1. Start the API server
uv run skill-fleet serve

# 2. In another terminal, test streaming with curl
curl -N -X POST http://localhost:8000/api/v1/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "create a skill for JSON validation"}'

# 3. Or test with the Ink TUI
cd cli/tui && npm install && npm run build
SKILL_FLEET_API_URL=http://localhost:8000 npm start
```

## Future Enhancements

- [ ] Support for structured outputs (JSON schema)
- [ ] Partial error recovery (continue on validation error)
- [ ] Thinking caching (avoid re-parsing for similar inputs)
- [ ] Custom thinking prompts per module
- [ ] Visualization of DSPy module flow


============================================================
END FILE: docs/architecture/STREAMING_ARCHITECTURE.md
============================================================

============================================================
FILE: docs/architecture/restructuring-status.md
============================================================

# Skills Fleet Architecture Status

**Last Updated**: 2026-01-29
**Status**: ‚úÖ DSPy Workflow Architecture Migration Complete

## Overview

The Skills Fleet codebase has been migrated to a clean DSPy workflow architecture following the pattern: **Signatures ‚Üí Modules ‚Üí Workflows**. This document describes the current architecture and completed work.

## What's New (Current Architecture)

### Clean DSPy Architecture

1. **Signatures Layer** (`core/signatures/`)
   - Pure type definitions using `dspy.Signature`
   - Organized by workflow phase: understanding, generation, validation, hitl
   - No business logic, just input/output field definitions

2. **Modules Layer** (`core/modules/`)
   - Reusable DSPy modules with `forward()` and `aforward()` methods
   - Extends `BaseModule` for consistent async support
   - Organized by workflow phase

3. **Workflows Layer** (`core/workflows/`)
   - High-level orchestration of multiple modules
   - Manages HITL checkpoints and state
   - Async-first design with proper error handling

4. **Centralized DSPy Config** (`dspy/`)
   - Single source of truth: `skill_fleet.dspy`
   - `configure_dspy()` and `get_task_lm()` functions
   - Replaces deprecated `infrastructure/llm/` and `core/dspy/`

### API Layer (FastAPI)

- **v1 API**: Main stable API for skill operations
- Clean service layer (`api/services/`)
- Pydantic schemas (`api/schemas/`)
- Proper dependency injection

### Removed Components

- ‚ùå `core/dspy/` - Legacy DSPy structure (50+ files deleted)
- ‚ùå `infrastructure/llm/` - Deprecated LLM configuration
- ‚ùå `onboarding/` - Deprecated onboarding module
- ‚ùå Old orchestrators (TaskAnalysisOrchestrator, etc.)

## Directory Structure

### Current Structure (Post-Migration)

```
src/skill_fleet/
‚îú‚îÄ‚îÄ api/                    # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ v1/                # API version 1 routers
‚îÇ   ‚îú‚îÄ‚îÄ schemas/           # Pydantic request/response models
‚îÇ   ‚îú‚îÄ‚îÄ services/          # Business logic layer
‚îÇ   ‚îú‚îÄ‚îÄ middleware/        # FastAPI middleware
‚îÇ   ‚îú‚îÄ‚îÄ factory.py         # App factory
‚îÇ   ‚îî‚îÄ‚îÄ main.py            # Application entry point
‚îÇ
‚îú‚îÄ‚îÄ cli/                   # CLI commands (Typer)
‚îÇ   ‚îú‚îÄ‚îÄ commands/          # Individual command implementations
‚îÇ   ‚îú‚îÄ‚îÄ hitl/             # HITL CLI handlers
‚îÇ   ‚îú‚îÄ‚îÄ ui/               # CLI UI components
‚îÇ   ‚îî‚îÄ‚îÄ app.py            # Main Typer application
‚îÇ
‚îú‚îÄ‚îÄ common/                # Shared utilities
‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # General utilities
‚îÇ   ‚îú‚îÄ‚îÄ security.py       # Path security functions
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py     # Shared exceptions
‚îÇ   ‚îî‚îÄ‚îÄ paths.py          # Path utilities
‚îÇ
‚îú‚îÄ‚îÄ core/                  # Domain logic + DSPy workflows
‚îÇ   ‚îú‚îÄ‚îÄ modules/          # DSPy modules (understanding, generation, validation, hitl)
‚îÇ   ‚îú‚îÄ‚îÄ signatures/       # DSPy signature definitions
‚îÇ   ‚îú‚îÄ‚îÄ workflows/        # Workflow orchestration layer
‚îÇ   ‚îú‚îÄ‚îÄ models.py         # Domain models
‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Configuration validation
‚îÇ   ‚îî‚îÄ‚îÄ hitl/             # Human-in-the-loop handlers
‚îÇ
‚îú‚îÄ‚îÄ dspy/                  # Centralized DSPy configuration ‚≠ê NEW
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py       # configure_dspy(), get_task_lm()
‚îÇ
‚îú‚îÄ‚îÄ infrastructure/        # Technical infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ db/               # Database layer (models, repositories)
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/       # MLflow setup
‚îÇ   ‚îî‚îÄ‚îÄ tracing/          # Distributed tracing
‚îÇ
‚îú‚îÄ‚îÄ taxonomy/             # Taxonomy management
‚îÇ   ‚îî‚îÄ‚îÄ manager.py        # Taxonomy operations
‚îÇ
‚îî‚îÄ‚îÄ validators/           # agentskills.io compliance
    ‚îî‚îÄ‚îÄ skill_validator.py
```

### Key Architectural Changes

| Before | After |
|--------|-------|
| `core/dspy/modules/workflows/` | `core/workflows/skill_creation/` |
| `core/dspy/signatures/` | `core/signatures/` |
| `core/dspy/modules/` | `core/modules/` |
| `infrastructure/llm/dspy_config.py` | `dspy/__init__.py` |
| Orchestrator classes | Workflow classes with HITL support |
| Sync-only modules | Async-first with `aforward()` |

## Import Guidelines

### Current Recommended Patterns

```python
# DSPy configuration (NEW location)
from skill_fleet.dspy import configure_dspy, get_task_lm

# Workflows
from skill_fleet.core.workflows.skill_creation import (
    UnderstandingWorkflow,
    GenerationWorkflow,
    ValidationWorkflow,
)

# Modules (if needed directly)
from skill_fleet.core.modules.understanding import GatherRequirementsModule

# API layer
from skill_fleet.api.services.skill_service import SkillService

# Domain models
from skill_fleet.core.models import SkillCreationResult
```

### Deprecated Patterns (Do Not Use)

```python
# ‚ùå These no longer work:
from skill_fleet.core.dspy import ...              # Deleted
from skill_fleet.infrastructure.llm import ...     # Deleted
from skill_fleet.core.dspy.modules.workflows import TaskAnalysisOrchestrator  # Deleted
```

## Migration Summary

### Phase 1: Architecture Migration ‚úÖ Complete

**Deleted:**
- `src/skill_fleet/core/dspy/` (entire directory, 50+ files)
- `src/skill_fleet/infrastructure/llm/` (3 deprecated files)
- `src/skill_fleet/onboarding/` (deprecated module)
- `src/skill_fleet/core/creator.py` (legacy creator)
- Old orchestrator test files (17 files)

**Created:**
- `src/skill_fleet/dspy/` - Centralized DSPy configuration
- `src/skill_fleet/core/modules/` - Clean module structure
- `src/skill_fleet/core/signatures/` - Signature definitions
- `src/skill_fleet/core/workflows/` - Workflow orchestration

**Updated:**
- API layer to use new workflows
- CLI commands (evaluate, optimize, onboard return 503)
- All imports from old to new locations
- AGENTS.md documentation

### Phase 2: Structural Cleanup ‚úÖ Complete

**Added:**
- Missing `__init__.py` files in 5 directories

**Removed:**
- Empty directories (6 total)
- Deprecated infrastructure/llm/
- Onboarding module
- Wildcard imports

**Fixed:**
- Import issues
- Linting errors
- Test organization

## Current Status

### What Works ‚úÖ

- **Understanding Workflow**: Requirements gathering, intent analysis, taxonomy path, dependencies
- **Generation Workflow**: Skill content generation with optional HITL
- **Validation Workflow**: Compliance checking with auto-refinement
- **API Endpoints**: Create, validate, refine skills
- **CLI**: Core commands functional
- **Tests**: 101 passing, 5 skipped
- **Linting**: All checks pass

### Temporarily Unavailable ‚ö†Ô∏è

The following return HTTP 503 (Service Unavailable):

- `/api/v1/optimization/*` - Signature optimization
- `/api/v1/conversational/*` - Chat endpoints
- CLI: `evaluate`, `evaluate-batch`, `optimize`, `onboard` commands

These features need to be rebuilt using the new workflow pattern.

## Key Design Decisions

### Why Signatures ‚Üí Modules ‚Üí Workflows?

1. **Separation of Concerns**: Each layer has a single responsibility
2. **Testability**: Signatures can be tested independently
3. **Reusability**: Modules can be composed into different workflows
4. **Async-First**: All modules support async/await
5. **HITL Support**: Workflows manage human-in-the-loop checkpoints

### Why Centralized DSPy Config?

1. **Single Source of Truth**: One place for LM configuration
2. **Simplified Imports**: `from skill_fleet.dspy import ...`
3. **No Circular Dependencies**: Clean separation from core logic
4. **Easy Testing**: Can mock at single point

### Why Delete Onboarding?

The onboarding module depended on deleted legacy code (`TaxonomySkillCreator`, `SkillBootstrapper`). It can be rebuilt using the new workflow architecture if needed.

## Testing

### Test Coverage
- **Unit tests**: 101 passing
- **Integration tests**: 5 skipped (require API keys)
- **Structural tests**: All package imports work

### Test Organization
```
tests/
‚îú‚îÄ‚îÄ unit/              # Fast unit tests
‚îú‚îÄ‚îÄ integration/       # Slow integration tests
‚îú‚îÄ‚îÄ api/              # API-specific tests
‚îú‚îÄ‚îÄ cli/              # CLI tests
‚îî‚îÄ‚îÄ common/           # Common utility tests
```

## API Changes

### Available Endpoints

```
POST   /api/v1/skills/           # Create skill
GET    /api/v1/skills/{id}      # Get skill
PATCH  /api/v1/skills/{id}      # Update skill
DELETE /api/v1/skills/{id}      # Delete skill
POST   /api/v1/skills/validate  # Validate skill
POST   /api/v1/skills/refine    # Refine skill with feedback

POST   /api/v1/quality/validate       # Validate quality
POST   /api/v1/quality/assess         # Assess quality
POST   /api/v1/quality/auto-fix       # Auto-fix issues
```

### Temporarily Unavailable (503)

```
POST /api/v1/optimization/analyze
POST /api/v1/optimization/improve
POST /api/v1/optimization/compare

POST /api/v1/conversational/message
GET  /api/v1/conversational/session/{id}/history
```

## Migration Guide for Developers

### If You Were Using Old Imports:

**Before:**
```python
from skill_fleet.core.dspy import configure_dspy
from skill_fleet.core.dspy.modules.workflows import TaskAnalysisOrchestrator
```

**After:**
```python
from skill_fleet.dspy import configure_dspy
from skill_fleet.core.workflows.skill_creation import UnderstandingWorkflow
```

### If You Were Using Onboarding:

The onboarding module has been removed. You can create skills directly using the API or CLI:

```bash
uv run skill-fleet create "Your task description"
```

Or via API:
```bash
curl -X POST http://localhost:8000/api/v1/skills/ \
  -H "Content-Type: application/json" \
  -d '{"task_description": "Your task", "user_id": "user123"}'
```

## Future Considerations

### Optional Enhancements

1. **Re-enable Optimization Endpoints**
   - Rebuild using new ValidationWorkflow
   - Add optimizer selection to workflow config

2. **Re-enable Conversational Interface**
   - Rebuild using new UnderstandingWorkflow
   - Implement session management

3. **Add More Tests**
   - Integration tests for HITL flows
   - Performance tests for workflows

4. **Documentation**
   - Add workflow diagrams
   - Create module usage examples

## Conclusion

The migration to the clean DSPy workflow architecture is complete. The codebase now has:

1. **Clear separation** of concerns (signatures/modules/workflows)
2. **Async-first design** throughout
3. **Centralized configuration** for DSPy
4. **No legacy code** from old architecture
5. **All tests passing** with no regressions

The current structure is stable, maintainable, and follows DSPy best practices.

## References

- [AGENTS.md](../../AGENTS.md) - Developer working guide
- [API Documentation](../api/index.md)
- [Contributing Guide](../development/CONTRIBUTING.md)


============================================================
END FILE: docs/architecture/restructuring-status.md
============================================================

============================================================
FILE: docs/architecture/skill-creation-workflow.md
============================================================

# Skill Creation Workflow (Agentic Skills System)

This document describes the Phase 1 skill creation workflow, its DSPy implementation, and how it integrates with the on-disk taxonomy.

## Architecture Overview

The system uses a **7-step pipeline** orchestrated by DSPy to transform a high-level task description into a fully validated, standards-compliant agent skill.

### Implementation Locations

- **Orchestrator**: `src/skill_fleet/workflow/creator.py`
- **Programs**: `src/skill_fleet/core/dspy/skill_creator.py` (New), `src/skill_fleet/core/dspy/programs.py` (Legacy)
- **Modules**: `src/skill_fleet/core/dspy/modules/` (phase1_understanding.py, phase2_generation.py, phase3_validation.py)
- **Signatures**: `src/skill_fleet/core/dspy/signatures/` (base.py, phase1_understanding.py, phase2_generation.py, phase3_validation.py)
- **Models**: `src/skill_fleet/core/models.py`
- **Taxonomy Manager**: `src/skill_fleet/taxonomy/manager.py`

## Workflow Programs

The system provides different DSPy Programs for various use cases:

1.  **`SkillCreationProgram` (Modern)**: The new unified 3-phase pipeline (default).
2.  **`LegacySkillCreationProgram` (Standard)**: The original end-to-end pipeline (Steps 0-6).
3.  **`LegacySkillCreationProgramQA` (Quality Assured)**: A high-fidelity version of the legacy program.
3.  **`QuickSkillProgram`**: A "fast path" for rapid prototyping that skips Initialization and Packaging (Steps 0, 1, 2, 4 only).
4.  **`SkillRevisionProgram`**: Used during the Iterate phase to regenerate content based on feedback (Steps 4-5).

## Detailed Workflow Steps

Each step is encapsulated in a DSPy Module that returns strict Pydantic models.

### 0. GATHER EXAMPLES
**Goal**: Collect concrete usage examples before creating skill content.
- **Input**: Initial task description, user responses to clarifying questions.
- **Module**: `GatherExamplesModule` (uses ReAct pattern: Reason ‚Üí Act ‚Üí Observe)
- **Output**: `ExampleGatheringResult`
    - `session.state`: `ExampleGatheringSession` with collected examples, domain terminology, and refined task.
    - `questions`: 1-3 focused clarifying questions (or empty list when ready).
    - `proceed`: Boolean indicating if readiness threshold is met.

**Process**:
1. Generates 1-3 focused clarifying questions about use cases, triggering conditions, and edge cases
2. Extracts `UserExample` objects from user responses (`{input_description, expected_output, context}`)
3. Builds domain-specific terminology dictionary
4. Scores readiness (0.0-1.0) based on example diversity (40%), clarity (30%), edge case coverage (30%)
5. Continues until `readiness_score >= threshold` (default 0.8) or max questions reached

**Configuration** (`ExampleGatheringConfig`):
- `min_examples`: Minimum examples before proceeding (default: 3)
- `readiness_threshold`: Score threshold to advance (default: 0.8)
- `max_questions`: Maximum clarifying questions (default: 10)
- `max_rounds`: Maximum feedback rounds (default: 3)

**Integration**: The `refined_task` output feeds into Step 1 (Understanding), and terminology is used throughout content generation. Examples become usage examples in the final skill.

### 1. UNDERSTAND
**Goal**: Map a user task to a specific taxonomy path.
- **Input**: Refined task description from Step 0.
- **Module**: `UnderstandModule` / `UnderstandModuleQA` (uses `dspy.Refine`)
- **Output**: `UnderstandingResult`
    - `task_intent`: Distilled requirements.
    - `taxonomy_path`: Proposed path (e.g., `technical_skills/programming/python/async`).
    - `dependency_analysis`: Missing vs. optional skill dependencies.

### 2. PLAN
**Goal**: Define the skill's structure and capabilities.
- **Input**: Taxonomy path, parent skills context.
- **Module**: `PlanModule` / `PlanModuleQA` (uses `dspy.Refine`)
- **Output**: `PlanResult`
    - `skill_metadata`: Full `agentskills.io` metadata (see below).
    - `capabilities`: List of discrete `Capability` objects.
    - `dependencies`: `DependencyRef` objects with justification.
    - `composition_strategy`: How this skill fits with others.

### 3. INITIALIZE
**Goal**: Create the file skeleton on disk.
- **Input**: Skill metadata.
- **Module**: `InitializeModule`
- **Output**: `InitializeResult`
    - `skill_skeleton`: Directory tree (`references/ (v2 standard, formerly capabilities/)`, `tests/`, etc.) and file paths.

### 4. EDIT
**Goal**: Generate the actual content.
- **Input**: Skeleton, parent context.
- **Module**: `EditModule` / `EditModuleQA` (uses `dspy.BestOfN` to pick the best of 3 drafts)
- **Output**: `EditResult`
    - `skill_content`: The Markdown body for `SKILL.md`.
    - `capability_implementations`: Detailed docs for each capability.
    - `usage_examples`: Runnable code snippets.

### 5. PACKAGE
**Goal**: Validate and manifest.
- **Input**: Generated content.
- **Module**: `PackageModule` / `PackageModuleQA`
- **Output**: `PackageResult`
    - `validation_report`: Errors, warnings, and compliance checks.
    - `packaging_manifest`: Checksums and file lists.

### 6. ITERATE (HITL)
**Goal**: Human-in-the-Loop refinement.
- **Input**: Validation report, user feedback.
- **Module**: `IterateModule`
- **Output**: `IterateResult`
    - `approval_status`: `approved`, `needs_revision`, or `rejected`.
    - `revision_plan`: Specific instructions for the `SkillRevisionProgram`.

## Data Structures

### Scalable Discovery Metadata
To support large-scale taxonomies (500+ skills), the `SkillMetadata` model includes specialized fields:

-   **`category`**: Hierarchical path for grouping (e.g., `tools/web`).
-   **`keywords`**: List of search terms (e.g., `["playwright", "e2e"]`).
-   **`scope`**: Explicit definition of what the skill *does* and *does not* cover.
-   **`see_also`**: Cross-references to related skills.

### Human-in-the-Loop (HITL) Models
The workflow supports structured interaction via:
-   `ClarifyingQuestion`: Multi-choice or free-text questions.
-   `HITLSession`: Tracks rounds of feedback (min 1, max 4).

## Model Configuration

This repo is configured to use **Gemini 3** models via `config/config.yaml`:

-   **`gemini-3-flash-preview`**: Primary model for all steps.
-   **`gemini-3-pro-preview`**: Used for GEPA reflection and high-reasoning tasks.

## Optimization

The workflow supports automatic optimization using DSPy's `MIPROv2` and `GEPA` optimizers.
Run `skills-fleet optimize` to tune the prompts against the `config/training/trainset.json`.

---

## Further Reading

### Detailed Documentation

| Topic | Description |
|-------|-------------|
| **[DSPy Programs](../dspy/programs.md)** | Complete DSPy program reference |
| **[DSPy Signatures](../dspy/signatures.md)** | All DSPy signature definitions |
| **[DSPy Modules](../dspy/modules.md)** | DSPy module implementations |
| **[DSPy Optimization](../dspy/optimization.md)** | MIPROv2, GEPA, and tuning |
| **[HITL System](../hitl/)** | Human-in-the-Loop interactions |
| **[LLM Configuration](../llm/)** | Task-specific model configuration |

### Related Documentation

- **[System Overview](../overview.md)** - High-level system architecture
- **[Developer Reference](../concepts/developer-reference.md)** - Development workflows
- **[Getting Started](../getting-started/)** - Installation and quick start

============================================================
END FILE: docs/architecture/skill-creation-workflow.md
============================================================

============================================================
FILE: docs/architecture/user_flow.md
============================================================

# User Flow: Interactive Skill Creation

This document outlines the user flow for the interactive skill creation process, highlighting the interaction between the CLI (Client), the FastAPI Backend, the Conversation Service, and the DSPy modules.

## Architecture Overview

The system uses an **API-First Architecture**:
1.  **CLI (Thin Client)**: Handles user input/output, connects to the API via streaming.
2.  **FastAPI Backend**: Exposes endpoints, manages session state (in-memory for MVP).
3.  **Conversation Service**: Orchestrates the state machine and business logic.
4.  **DSPy Modules**: Encapsulate specific LLM tasks (Intent, Understanding, TDD).

## User Flow Diagram

```mermaid
sequenceDiagram
    actor User
    participant CLI as CLI (Client)
    participant API as FastAPI /stream
    participant Service as ConversationService
    participant DSPy as DSPy Modules
    participant LLM as LLM (Gemini/DeepSeek)

    User->>CLI: "I want to create a skill for async testing"
    CLI->>API: POST /chat/stream {message, session_id}
    
    API->>Service: respond(message, session)
    
    rect rgb(240, 248, 255)
    Note over Service, LLM: Phase 1: Understanding
    Service->>DSPy: InterpretIntent(message)
    DSPy->>LLM: Analyze intent...
    LLM-->>DSPy: Intent: create_skill
    DSPy-->>Service: Result
    
    Service-->>API: Stream "thinking" event (Intent detected)
    API-->>CLI: Display thinking...
    
    Service->>DSPy: DeepUnderstanding(task)
    DSPy->>LLM: Generate clarifying questions...
    LLM-->>DSPy: Question + Reasoning
    DSPy-->>Service: Result
    end
    
    Service-->>API: Stream "response" event (Question)
    API-->>CLI: Render Question
    CLI-->>User: Display Question
    
    User->>CLI: "Yes, focused on pytest-asyncio"
    CLI->>API: POST /chat/stream {message, session_id}
    
    rect rgb(255, 240, 245)
    Note over Service, LLM: Phase 2: Confirmation & Creation
    Service->>DSPy: AssessReadiness()
    DSPy->>LLM: Score: 0.9 (Ready)
    Service->>DSPy: ConfirmUnderstanding()
    Service-->>API: Stream "response" (Confirmation Summary)
    end
    
    User->>CLI: "Yes, create it"
    CLI->>API: POST /chat/stream {message}
    
    rect rgb(240, 255, 240)
    Note over Service, LLM: Phase 3: Generation & TDD
    Service->>DSPy: SkillCreationProgram()
    Note right of Service: Executing Phase 1, 2, 3...
    Service->>DSPy: SuggestTests(skill_content)
    DSPy->>LLM: Generate Red/Green scenarios...
    Service-->>API: Stream "response" (TDD Checklist)
    end
```

## State Machine Transition

The `ConversationService` manages the following high-level states:

```mermaid
stateDiagram-v2
    [*] --> EXPLORING
    EXPLORING --> DEEP_UNDERSTANDING: Intent = create_skill
    DEEP_UNDERSTANDING --> EXPLORING: Clarification needed
    DEEP_UNDERSTANDING --> MULTI_SKILL_DETECTED: Multiple skills found
    DEEP_UNDERSTANDING --> CONFIRMING: Readiness >= 0.8
    MULTI_SKILL_DETECTED --> DEEP_UNDERSTANDING: User selects single
    CONFIRMING --> CREATING: User confirms
    CONFIRMING --> EXPLORING: User revises
    CREATING --> TDD_RED_PHASE: Draft generated
    TDD_RED_PHASE --> TDD_GREEN_PHASE: Baseline tests run
    TDD_GREEN_PHASE --> TDD_REFACTOR_PHASE: Compliance verified
    TDD_REFACTOR_PHASE --> CHECKLIST_COMPLETE: All checks passed
    CHECKLIST_COMPLETE --> COMPLETE: Skill saved
    COMPLETE --> [*]
```

## Module Organization

The DSPy modules are organized by function in `src/skill_fleet/core/dspy/modules/conversation/`:

| Module | Purpose |
| :--- | :--- |
| `intent.py` | Detect user intent (`InterpretIntentModule`) and multi-skill needs (`DetectMultiSkillModule`). |
| `understanding.py` | Gather context (`DeepUnderstandingModule`), ask questions (`GenerateQuestionModule`), and summarize (`UnderstandingSummaryModule`). |
| `tdd.py` | Generate test scenarios (`SuggestTestsModule`) and verify completion (`VerifyTDDModule`). |
| `feedback.py` | Present results (`PresentSkillModule`) and process user feedback (`ProcessFeedbackModule`). |

## Standards Alignment

### FastAPI
- **Dependencies**: Uses `Depends` for `TaxonomyManager` injection.
- **Pydantic**: Uses `BaseModel` for all request/response schemas.
- **Async**: Fully async route handlers and service methods.
- **Streaming**: Uses `StreamingResponse` with SSE format.

### DSPy
- **Declarative**: Uses `dspy.Signature` for all LLM interfaces.
- **Modular**: Logic encapsulated in `dspy.Module` classes.
- **Optimizable**: Uses `dspy.ChainOfThought` and supports `MultiChainComparison` for critical steps.
- **Typed**: Inputs/outputs are typed (e.g., `list[str]`, `bool`).


============================================================
END FILE: docs/architecture/user_flow.md
============================================================

============================================================
FILE: docs/archive/README.md
============================================================

# Documentation Archive

**Archived Date**: 2026-01-25

## Purpose

This directory contains historical documentation that has been superseded by newer content or is no longer actively maintained. Files are kept here for reference purposes.

## What's Archived

### Historical Notes (January 2025 cleanup)
Historical implementation notes and phase completion summaries moved to `historical-notes/`:

- **Phase completion notes**: PHASE1_COMPLETE.md, PHASE2_COMPLETE.md
- **Implementation summaries**: JOB_PERSISTENCE_*, FASTAPI_INTEGRATION, DATABASE_SYNC_SUMMARY
- **Update summaries**: UPDATE_SUMMARY.md, PHASE_0_FOUNDATION.md
- **Bug fix notes**: ASYNC_IO_BLOCKING_FIX, FIX_STREAMING_500, RUN_SOLUTION
- **Feature completion**: INK_UPGRADE_COMPLETE, GEPA_SETUP_COMPLETE, TUI_READY
- **Documentation restructuring**: Old DOCUMENTATION_RESTRUCTURING.md (superseded by current docs)

**Note**: These are preserved for historical context but reference current documentation for accurate information.

### Pre-Restructure Documentation
Documents that describe the architecture before the FastAPI-centric restructure (completed January 2025):

- **Legacy workflow patterns** - Replaced by workflow orchestrators
- **Old import paths** - Updated in [Import Path Guide](../development/IMPORT_PATH_GUIDE.md)
- **Pre-domain layer patterns** - Replaced by DDD patterns documented in [Domain Layer](../architecture/DOMAIN_LAYER.md)

### Historical Planning Documents
Planning documents that have been completed or superseded:

- **Cleanup plans** - Executed and completed
- **Migration notes** - Incorporated into current documentation
- **Legacy API references** - Replaced by current v2 API documentation

## Migration Guide

If you're looking for information that used to be in the archive:

| Archived Topic | Current Location |
|----------------|------------------|
| Import patterns | [Import Path Guide](../development/IMPORT_PATH_GUIDE.md) |
| API v1/v2 confusion | [API Migration Guide](../api/MIGRATION_V1_TO_V2.md) |
| Domain entities | [Domain Layer Architecture](../architecture/DOMAIN_LAYER.md) |
| Service layer | [Service Layer Architecture](../architecture/SERVICE_LAYER.md) |
| Caching strategy | [Caching Layer Architecture](../architecture/CACHING_LAYER.md) |
| Conversational interface | [Conversational Interface](../architecture/CONVERSATIONAL_INTERFACE.md) |

## Why Archive?

Documentation is archived when:

1. **Superseded**: Newer, more accurate documentation exists
2. **Outdated**: Describes deprecated patterns or APIs
3. **Completed**: Planning documents for finished work
4. **Historical**: Preserved for context but not actively maintained

## Using Archived Content

Archived content is provided **as-is** without updates. It may:

- Reference deprecated import paths
- Describe outdated architectural patterns
- Contain broken links to moved content
- Use obsolete API endpoints

**Use archived content for:**
- Understanding historical context
- Researching past decisions
- Recovering information from old links

**For current information, always refer to the main documentation index.**

## See Also

- **[Documentation Index](../index.md)** - Current documentation
- **[Restructuring Status](../architecture/restructuring-status.md)** - Architecture evolution


============================================================
END FILE: docs/archive/README.md
============================================================

============================================================
FILE: docs/archive/historical-notes/ASYNC_IO_BLOCKING_FIX.md
============================================================

# Async I/O Blocking Fix

**Date**: Jan 20, 2026  
**Issue**: Synchronous file I/O in async route handler blocking event loop  
**Status**: ‚úÖ FIXED  

---

## Problem

### Location
`src/skill_fleet/api/routes/jobs.py` (L52)

### Issue
```python
# OLD: Blocking synchronous call in async context
loaded = load_job_session(job_id)  # ‚ùå Blocks event loop
```

The `load_job_session()` function performs synchronous file I/O:
1. Reads JSON file from disk (`session_file.read_text()`)
2. Parses JSON (`json.loads()`)
3. Reconstructs Python objects
4. Creates asyncio.Event() and asyncio.Lock() objects

This runs in the FastAPI async route handler **without offloading**, which:
- ‚ùå Blocks the asyncio event loop
- ‚ùå Prevents other requests from being processed
- ‚ùå Freezes the server if there are many saved sessions
- ‚ùå Violates async best practices

### Example Impact
```
Request 1: list_jobs() with 100 saved sessions
  ‚Üí loads 100 session files synchronously
  ‚Üí event loop blocked for ~100ms-1s
  ‚Üí all other requests waiting

Request 2: get_job_state() comes in during Request 1
  ‚Üí BLOCKED: has to wait for Request 1 to finish
  ‚Üí user sees slow/frozen server
```

---

## Solution

### Fix
```python
# NEW: Offload to thread pool
loaded = await asyncio.to_thread(load_job_session, job_id)  # ‚úÖ Non-blocking
```

### How It Works
1. `asyncio.to_thread()` runs blocking function in default ThreadPoolExecutor
2. Async handler yields control back to event loop
3. Event loop can process other requests concurrently
4. When thread completes, result is returned to handler
5. Handler continues execution

### Benefits
- ‚úÖ Event loop never blocked
- ‚úÖ Concurrent request handling maintained
- ‚úÖ Server remains responsive
- ‚úÖ Scales better with multiple clients
- ‚úÖ Minimal code change (1 line)

---

## Implementation

### File Changed
`src/skill_fleet/api/routes/jobs.py`

### Changes
```python
# Added import
import asyncio

# Modified list_jobs() handler
async def list_jobs(...):
    # ... existing code ...
    
    if include_saved:
        saved_ids = list_saved_sessions()
        for job_id in saved_ids:
            if not manager.memory.get(job_id):
                # Offload blocking file I/O to thread pool
                loaded = await asyncio.to_thread(load_job_session, job_id)
                if loaded:
                    jobs.append(loaded)
```

### Why This Approach
- **asyncio.to_thread()** is the modern Python async pattern (3.9+)
- **Thread pool** has built-in concurrency control
- **No changes to underlying function** - `load_job_session()` stays as-is
- **Backward compatible** - existing code works unchanged
- **Minimal overhead** - thread creation is cheap for I/O operations

---

## Alternative Approaches (Not Used)

### 1. Make load_job_session() async
```python
async def load_job_session(job_id: str) -> JobState | None:
    # Would need to refactor file operations to use aiofiles
    # More invasive, more testing required
```
**Not chosen**: Overkill for this use case, high refactor cost

### 2. Pre-load all sessions on startup
```python
# Load all saved sessions into memory at startup
# Copy to cache
```
**Not chosen**: Wastes memory, doesn't match "lazy load" pattern

### 3. Use ProcessPoolExecutor
```python
loaded = await asyncio.to_thread(
    load_job_session, 
    job_id, 
    executor=ProcessPoolExecutor()
)
```
**Not chosen**: Thread pool is sufficient for I/O, process pool adds overhead

---

## Verification

### ‚úÖ Code Compiles
```bash
uv run python -c "from src.skill_fleet.api.routes.jobs import router"
# Result: ‚úÖ Success
```

### ‚úÖ Router Loads
```
‚úÖ routes/jobs.py imports successfully
‚úÖ Router has 2 routes
```

### ‚úÖ Type Safe
- `asyncio.to_thread()` properly awaited
- Return type matches original function
- No type errors

---

## Testing

### Unit Test (To Be Added)
```python
@pytest.mark.asyncio
async def test_list_jobs_with_saved_sessions(client):
    """Test that saved sessions load without blocking."""
    # Create saved session file
    job_id = "test-session-123"
    # ... setup ...
    
    # Call list_jobs
    response = await client.get("/api/v2/jobs?include_saved=true")
    assert response.status_code == 200
    
    # Verify job was loaded from disk
    jobs = response.json()
    assert any(j["job_id"] == job_id for j in jobs)
```

### Integration Test
```python
@pytest.mark.asyncio
async def test_concurrent_list_jobs_requests():
    """Test that multiple list_jobs requests don't block each other."""
    # Create 100 saved sessions
    job_ids = [f"session-{i}" for i in range(100)]
    # ... setup ...
    
    # Make 10 concurrent requests to list_jobs
    tasks = [
        client.get("/api/v2/jobs?include_saved=true")
        for _ in range(10)
    ]
    
    start = time.time()
    responses = await asyncio.gather(*tasks)
    elapsed = time.time() - start
    
    # All should complete quickly (parallel, not sequential)
    assert elapsed < 5.0  # Would be >> 5s if blocking
    assert all(r.status_code == 200 for r in responses)
```

---

## Performance Impact

### Before (Blocking)
```
Request A: list_jobs() with 100 sessions
  Timeline: [========= 1000ms =========]
  
Request B: get_job_state() arrives at 100ms
  Timeline:       [blocked][blocked][blocked] [30ms]
  Total latency: 1030ms ‚ùå (should be ~30ms)
```

### After (Non-Blocking)
```
Request A: list_jobs() with 100 sessions
  Timeline: [====100ms==] (yields to thread)
           
Request B: get_job_state() arrives at 100ms
  Timeline: [30ms] ‚úÖ (processed immediately)
  Total latency: 30ms ‚úÖ
```

### Estimated Improvement
- **Single request**: Minimal change (still takes same wall time)
- **Concurrent requests**: 10-100x faster server responsiveness
- **Memory efficiency**: No degradation (thread reuse via pool)

---

## Related Issues

This fix addresses the async/await best practice issue. Related areas that might benefit from similar treatment:

1. `list_saved_sessions()` - also reads from disk, but returns list (minimal impact)
2. Database operations in `job_manager.py` - already handled via repository pattern (async-ready)
3. HITL route handlers - already use `await` where needed

---

## Deployment Notes

### No Configuration Changes
- No environment variables to set
- No dependency updates needed
- Works with existing Python 3.9+

### Backward Compatible
- ‚úÖ Existing API unchanged
- ‚úÖ Existing callers work as-is
- ‚úÖ No database changes
- ‚úÖ No breaking changes

### Safe Rollback
If issues arise, can revert to single line:
```python
# Revert to blocking version (temporary)
loaded = load_job_session(job_id)
```

---

## Summary

| Aspect | Details |
|--------|---------|
| **Problem** | Synchronous file I/O blocking async event loop |
| **Solution** | Use `asyncio.to_thread()` to offload I/O |
| **Impact** | Better concurrency, server responsiveness |
| **Risk** | Very low (1-line change, standard pattern) |
| **Testing** | Compiles, imports working, type safe |
| **Rollback** | Easy (single line revert) |

---

## References

- [asyncio.to_thread() documentation](https://docs.python.org/3/library/asyncio-task-utils.html#asyncio.to_thread)
- [FastAPI async patterns](https://fastapi.tiangolo.com/async-sql-databases/)
- [Python async best practices](https://docs.python.org/3/library/asyncio.html#asyncio-best-practices)

---

**Status**: ‚úÖ COMPLETE & VERIFIED


============================================================
END FILE: docs/archive/historical-notes/ASYNC_IO_BLOCKING_FIX.md
============================================================

============================================================
FILE: docs/archive/historical-notes/DATABASE_SYNC_SUMMARY.md
============================================================

# Database Sync Implementation Summary

Bidirectional synchronization between local `skills/` directory and Neon database is now complete.

---

## ‚úÖ What Was Created

### 1. CLI Commands

**File**: `src/skill_fleet/cli/commands/db_sync.py`

Three new CLI commands:

#### `skill-fleet export-to-db`
Export skills from local directory to Neon database
- Parses `SKILL.md` files with YAML frontmatter
- Extracts metadata (name, description, keywords, tags)
- Infers taxonomy path from directory structure
- Creates skills with full relations (categories, capabilities, files)
- Updates existing skills (use `--force` to overwrite)

**Usage**:
```bash
uv run skill-fleet export-to-db                    # Export all
uv run skill-fleet export-to-db --dry-run          # Preview
uv run skill-fleet export-to-db --force            # Force update
```

#### `skill-fleet import-from-db`
Import skills from Neon database to local directory
- Reads skills from database with full metadata
- Filters by path or status (active/draft/all)
- Writes `SKILL.md` files with YAML frontmatter
- Maintains directory structure from skill paths

**Usage**:
```bash
uv run skill-fleet import-from-db                          # Import all active
uv run skill-fleet import-from-db --status draft        # Import drafts only
uv run skill-fleet import-from-db --status all         # Import all
uv run skill-fleet import-from-db --skill-path "development/languages/python"  # Import specific
```

#### `skill-fleet sync-db`
Bidirectional synchronization between local files and database
- Runs export-to-db first (local ‚Üí database)
- Runs import-from-db second (database ‚Üí local)
- Ensures both sources are consistent

**Usage**:
```bash
uv run skill-fleet sync-db                      # Full sync
uv run skill-fleet sync-db --dry-run          # Preview
```

### 2. Documentation

#### `docs/DATABASE_SYNC.md`
Comprehensive guide for database synchronization
- Detailed workflow explanations
- Environment setup instructions
- Troubleshooting tips
- Conflict resolution strategies
- Database queries for verification

#### `docs/CLI_SYNC_COMMANDS.md`
Quick reference for sync commands
- Command syntax and options
- Usage examples for all commands
- Common workflows
- Performance tips

### 3. Test Suite

**File**: `scripts/test_db_sync.py`

Automated tests for sync commands:
- Export dry-run test
- Export to database test
- Import from database test
- Import specific skill test
- Sync dry-run test

**Usage**:
```bash
# Run all tests (requires DATABASE_URL set)
uv run python scripts/test_db_sync.py
```

### 4. CLI Integration

**File**: `src/skill_fleet/cli/app.py` (modified)

New commands registered in CLI:
```python
from .commands.db_sync import export_to_db_command, import_from_db_command, sync_command

app.command(name="export-to-db")(export_to_db_command)
app.command(name="import-from-db")(import_from_db_command)
app.command(name="sync-db")(sync_command)
```

---

## üöÄ Quick Start

### Step 1: Set DATABASE_URL

```bash
# In .env file
DATABASE_URL="postgresql://neondb_owner:npg_DroldK7R6Bci@ep-divine-voice-ahu0xhvb.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"

# Or export directly
export DATABASE_URL="postgresql://neondb_owner:npg_DroldK7R6Bci@ep-divine-voice-ahu0xhvb.c-3.us-east-1.aws.neon.tech/neondb?sslmode=require"
```

### Step 2: Export Skills to Database

```bash
# Export all local skills to Neon
uv run skill-fleet export-to-db

# Preview first (recommended)
uv run skill-fleet export-to-db --dry-run
```

### Step 3: Verify in Database

```sql
-- Run in Neon Console SQL Editor
SELECT COUNT(*) as skill_count FROM skills;
SELECT s.name, s.skill_path, s.status FROM skills s ORDER BY s.skill_path;
```

### Step 4: Import Back to Local (Optional)

```bash
# Import all skills from database
uv run skill-fleet import-from-db --status all

# Verify skills were imported
ls -R skills/
```

---

## üìä What Gets Synced

### Export to Database (Local ‚Üí DB)

‚úÖ **Skill Metadata**
- Name, description, version
- Type, weight, load priority
- Status (draft/active)
- Scope

‚úÖ **Relations**
- Taxonomy categories (inferred from path)
- Keywords and tags
- Capabilities
- Skill files (if present)
- Dependencies and references

‚úÖ **Content**
- Full markdown content
- YAML frontmatter preserved

### Import from Database (DB ‚Üí Local)

‚úÖ **All Above Fields**
- Complete skill metadata
- All relations
- YAML frontmatter reconstructed

‚úÖ **Directory Structure**
- Skills organized by taxonomy path
- Example: `skills/development/languages/python/SKILL.md`

### What Doesn't Get Synced

‚ùå **Usage Analytics**
- Kept in database only
- Not exported to files

‚ùå **Job History**
- Kept in database only
- Not exported to files

‚ùå **Validation Reports**
- Kept in database only
- Not exported to files

---

## üîÑ Common Workflows

### Local-First Development

```bash
# 1. Edit skills locally
vim skills/python/async/SKILL.md

# 2. Export to database
uv run skill-fleet export-to-db

# 3. Repeat for each change
```

### Database-First Development

```bash
# 1. Create skill via API (background job)
curl -X POST http://localhost:8000/api/v2/skills \
  -d '{"task_description": "Create Docker skill"}'

# 2. Import draft to local files
uv run skill-fleet import-from-db --status draft

# 3. Edit and test locally
vim skills/operations/docker/SKILL.md

# 4. Re-export changes
uv run skill-fleet export-to-db
```

### Team Collaboration

```bash
# Developer A: Exports changes
uv run skill-fleet export-to-db

# Developer B: Pulls latest from database
uv run skill-fleet import-from-db

# Both work via database as shared source
```

### Sync Routine

```bash
# Run sync regularly to stay up to date
uv run skill-fleet sync-db

# Or set up cron/automated schedule
# 0 * * * * cd /path/to/skills-fleet && uv run skill-fleet sync-db
```

---

## üéØ Benefits

1. **Bidirectional Sync**: Work with skills locally or in database, sync both ways
2. **Full Metadata Preservation**: Keywords, tags, capabilities all maintained
3. **Conflict Resolution**: `--force` flag and `--dry-run` for safe operations
4. **Taxonomy Awareness**: Automatic categorization based on directory structure
5. **Incremental Updates**: Only changed skills need re-exporting
6. **Team Collaboration**: Multiple developers can share database
7. **Version Control**: Skills can be managed in Git and database independently

---

## üìù Next Steps

1. **Test Commands**: Run `uv run python scripts/test_db_sync.py`
2. **Start Using**: Export your skills to database
3. **Monitor**: Check Neon Console for synced skills
4. **Automate**: Add to CI/CD pipeline if desired
5. **Customize**: Edit `scripts/import_skills.py` for custom needs

---

## üìö Documentation

- **[DATABASE_SYNC.md](docs/DATABASE_SYNC.md)**: Comprehensive sync guide
- **[CLI_SYNC_COMMANDS.md](docs/CLI_SYNC_COMMANDS.md)**: Command quick reference
- **[BACKGROUND_JOBS.md](docs/BACKGROUND_JOBS.md)**: Background job architecture
- **[AGENTS.md](AGENTS.md)**: Complete agent working guide

---

## üîß Technical Details

### Export Implementation
- Scans `.skills/` directory for `SKILL.md` files
- Parses YAML frontmatter using PyYAML
- Extracts capabilities using regex on content sections
- Infers taxonomy path from directory structure
- Uses SQLAlchemy ORM for database operations
- Updates existing skills (checks skill_path uniqueness)

### Import Implementation
- Queries skills from database with joins
- Filters by path or status
- Reconstructs YAML frontmatter from database fields
- Writes files preserving directory structure
- Handles overwrites of existing files

### Sync Implementation
- Calls export-to-db command first
- Calls import-from-db command second
- Propagates `--dry-run` flag
- Continues even if one phase fails
- Shows summary of both operations

---

**Status**: ‚úÖ Complete and ready to use!

**Last Updated**: 2026-01-19


============================================================
END FILE: docs/archive/historical-notes/DATABASE_SYNC_SUMMARY.md
============================================================

============================================================
FILE: docs/archive/historical-notes/DEV_COMMAND_FIXED.md
============================================================

# Fixed: `skill-fleet dev` Command

## Problem
The `skill-fleet dev` command had auto-reload enabled by default, which caused port binding errors when uvicorn tried to reload after file changes. This was particularly problematic in development because the port (8000) couldn't be cleanly re-bound, causing the API server to crash.

**Error Message:**
```
ERROR:    [Errno 48] Address already in use
```

## Root Cause
When `--reload` is enabled (default was `True`), uvicorn watches for file changes. Upon detecting changes, it attempts to restart the server and rebind to the port. However, the OS doesn't immediately release the port, causing a binding conflict.

## Solution
Changed the default reload behavior from **enabled** to **disabled**:

```python
# Before
reload: bool = typer.Option(True, ...)

# After
reload: bool = typer.Option(False, ...)
```

### Changes Made

**File:** `src/skill_fleet/cli/commands/dev.py`

1. **Default reload disabled** - Auto-reload now defaults to `False` to prevent port binding issues
2. **Better help text** - Updated docstring to explain the default behavior
3. **Optional reload** - Users can still enable reload with `--reload` flag if needed
4. **Helpful tip** - Added a friendly tip showing how to enable reload when disabled

## Usage

### Start dev mode (no reload)
```bash
uv run skill-fleet dev
```

Output:
```
üöÄ Starting Skill Fleet (API + TUI)...
API URL: http://127.0.0.1:8000
User ID: default
Reload: disabled
üí° Tip: To enable auto-reload, use: skill-fleet dev --reload
```

### Start dev mode with reload (if needed)
```bash
uv run skill-fleet dev --reload
```

### Without TUI (faster startup)
```bash
uv run skill-fleet dev --no-tui
```

### With custom port
```bash
uv run skill-fleet dev --port 9000
```

## Testing

‚úÖ **All tests passing:**
- Syntax validation: ‚úì
- Linting (ruff): ‚úì
- CLI tests: 47/47 ‚úì
- Type checking: ‚úì

## Why This Approach

1. **Stability over convenience** - Dev mode prioritizes stability
2. **Manual reload control** - Developers can opt-in with `--reload` if they prefer watch mode
3. **Backward compatible** - Existing workflows still work
4. **Clear messaging** - Users know the current state and how to change it

## Related Commands

- `skill-fleet serve` - Start API server only (with interactive config)
- `skill-fleet chat` - Interactive skill creation in terminal
- `skill-fleet create` - One-shot skill creation

## Notes

- In-memory job state is lost on reload anyway (stored in-memory by default)
- For persistent job state, configure external storage (Redis, database)
- TUI auto-connects to the API with environment variables
- Logs are written to `.skill_fleet_logs/api-dev.log`


============================================================
END FILE: docs/archive/historical-notes/DEV_COMMAND_FIXED.md
============================================================

============================================================
FILE: docs/archive/historical-notes/DOCUMENTATION_RESTRUCTURING.md
============================================================

# Documentation Restructuring Summary

**Date**: 2026-01-21
**Purpose**: Clean up and improve documentation structure for better navigation

## Changes Made

### 1. Created New Documentation Hub

**File**: `docs/index.md` (NEW)
- Central documentation hub for all Skills Fleet documentation
- Organized by category: Getting Started, Core Architecture, DSPy, API, CLI, LLM, HITL, Concepts, Development
- Includes recommended reading paths for different user types
- Documentation status table showing coverage

### 2. Enhanced Root README.md

**File**: `README.md` (UPDATED)
- Added complete installation instructions (previously missing)
- Expanded Documentation section with categorized links
- Added links to new documentation hub
- Better organized Quick Start section

### 3. Updated Root AGENTS.md

**File**: `AGENTS.md` (UPDATED)
- Added "Documentation Navigation" section with clear categorization
- Links to new docs/index.md hub
- Added "Deep Dives by Topic" section
- Added "Advanced Topics" section
- Maintained all existing comprehensive content

### 4. Removed Misplaced File

**File**: `src/skill_fleet/AGENTS.md` (DELETED)
- Contained general DSPy knowledge (1700+ lines) not specific to skill-fleet
- Wrong location (should be in docs/, not src/)
- Replaced by comprehensive DSPy documentation in `docs/dspy/` directory

### 5. Enhanced DSPy Documentation

**File**: `docs/dspy/index.md` (UPDATED)
- Added "External DSPy Resources" section
- References official DSPy documentation for comprehensive learning
- Clarifies that skill-fleet provides focused DSPy integration

### 6. Updated Documentation Map

**File**: `docs/intro/introduction.md` (UPDATED)
- Updated docs tree structure to reflect current organization
- Added `docs/index.md` to tree
- Added new DSPy evaluation.md to tree
- Updated CLI section with new files

## Documentation Structure After Changes

```
skill-fleet/
‚îú‚îÄ‚îÄ README.md                    # Enhanced with better structure
‚îú‚îÄ‚îÄ AGENTS.md                    # Enhanced with navigation
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ index.md                # NEW: Central documentation hub
‚îÇ   ‚îú‚îÄ‚îÄ intro/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ introduction.md     # Updated: docs tree
‚îÇ   ‚îú‚îÄ‚îÄ getting-started/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.md
‚îÇ   ‚îú‚îÄ‚îÄ dspy/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.md            # Updated: external resources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signatures.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ modules.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ programs.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ optimization.md
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ endpoints.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jobs.md
‚îÇ   ‚îú‚îÄ‚îÄ cli/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interactive-chat.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev-command.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ architecture.md
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ providers.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dspy-config.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ task-models.md
‚îÇ   ‚îú‚îÄ‚îÄ hitl/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interactions.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runner.md
‚îÇ   ‚îú‚îÄ‚îÄ concepts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ concept-guide.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ developer-reference.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agentskills-compliance.md
‚îÇ   ‚îú‚îÄ‚îÄ overview.md
‚îÇ   ‚îî‚îÄ‚îÄ development/
‚îÇ       ‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îÇ       ‚îî‚îÄ‚îÄ ARCHITECTURE_DECISIONS.md
‚îî‚îÄ‚îÄ src/skill_fleet/
    # (NO AGENTS.md - removed, was misplaced)
```

## Benefits

### Improved Navigation
- **Single entry point**: docs/index.md provides clear organization
- **User-specific paths**: Different reading paths for new users, developers, and AI agents
- **Better discoverability**: Categorized sections make finding information easier

### Reduced Confusion
- **No duplicate content**: Removed misplaced DSPy general knowledge
- **Clear separation**: General DSPy vs skill-fleet-specific DSPy integration
- **Consistent cross-references**: All files properly link to each other

### Enhanced README
- **Complete quick start**: Added installation steps
- **Better documentation links**: Organized by category
- **Clearer purpose**: Improved project overview

### Updated AGENTS.md
- **Navigation section**: Added guide through documentation
- **Cross-references**: Better linking to docs/
- **Maintained comprehensiveness**: All 909 lines of working guide preserved

## Verification

All documentation cross-references verified:
- ‚úÖ README.md ‚Üí AGENTS.md
- ‚úÖ README.md ‚Üí docs/index.md
- ‚úÖ AGENTS.md ‚Üí docs/index.md
- ‚úÖ docs/index.md ‚Üí All major sections
- ‚úÖ docs/intro/introduction.md ‚Üí All sections
- ‚úÖ No broken links to removed src/skill_fleet/AGENTS.md

## Next Steps (Optional)

If you want to further improve documentation:

1. **Add visual diagrams**: Create architecture diagrams for README and docs/overview.md
2. **Create video tutorials**: Add video links to getting-started guide
3. **Add examples**: Create interactive examples in docs/examples/
4. **Improve search**: Add search functionality to documentation site
5. **Create troubleshooting FAQ**: Expand docs/notes/ into organized FAQ

---

**Status**: ‚úÖ Complete
**Impact**: Improved documentation navigation and organization without removing content


============================================================
END FILE: docs/archive/historical-notes/DOCUMENTATION_RESTRUCTURING.md
============================================================

============================================================
FILE: docs/archive/historical-notes/FASTAPI_INTEGRATION.md
============================================================

# FastAPI Reflection Metrics Integration

**Status**: ‚úÖ Complete and Ready  
**Date**: January 19, 2026  
**Endpoints**: 3 new (1 fast, 2 supporting)

---

## Quick Start

### 1. Start the API server
```bash
uv run skill-fleet serve --reload
```

### 2. Use the FAST optimization endpoint (Recommended)
```bash
# Quick optimization with Reflection Metrics
curl -X POST http://localhost:8000/api/v1/optimization/fast \
  -H "Content-Type: application/json" \
  -d '{
    "trainset_file": "config/training/trainset_v4.json"
  }'

# Response: {"job_id": "abc123", "status": "pending", ...}
```

### 3. Check the status
```bash
curl http://localhost:8000/api/v1/optimization/status/abc123
```

### 4. View available optimizers
```bash
curl http://localhost:8000/api/v1/optimization/optimizers
```

---

## API Endpoints

### POST `/api/v1/optimization/fast` ‚ö° RECOMMENDED
**Fast optimization with Reflection Metrics (new endpoint)**

- **Speed**: 0.06s (instant)
- **Cost**: $0.01-0.05
- **Quality**: +1.5% improvement
- **Efficiency**: 11.1x (best value)

**Example Request**:
```bash
curl -X POST http://localhost:8000/api/v1/optimization/fast \
  -H "Content-Type: application/json" \
  -d '{
    "trainset_file": "config/training/trainset_v4.json",
    "save_path": "fast_optimized_v1.json"
  }'
```

**Response**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "message": "Fast optimization started. Check status with GET /optimization/status/{job_id}"
}
```

---

### POST `/api/v1/optimization/start` (Updated)
**Traditional optimization with configurable optimizer**

Now supports `reflection_metrics` in the optimizer field!

**Example Request**:
```bash
curl -X POST http://localhost:8000/api/v1/optimization/start \
  -H "Content-Type: application/json" \
  -d '{
    "optimizer": "reflection_metrics",
    "trainset_file": "config/training/trainset_v4.json"
  }'
```

**Supported Optimizers**:
- `reflection_metrics` - **Fast + cheap (0.06s, $0.01-0.05)** ‚≠ê
- `miprov2` - Thorough (265s, $5-10)
- `gepa` - Reflection-based (slower but detailed)
- `bootstrap_fewshot` - Free (0.39s, $0.00)

---

### GET `/api/v1/optimization/status/{job_id}`
**Check optimization job status**

```bash
curl http://localhost:8000/api/v1/optimization/status/550e8400-e29b-41d4-a716-446655440000
```

**Response**:
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "progress": 1.0,
  "message": "Fast optimization completed (Reflection Metrics + BootstrapFewShot)",
  "result": {
    "optimizer": "reflection_metrics",
    "baseline_score": 46.7,
    "optimized_score": 47.4,
    "improvement": 0.7,
    "improvement_percent": 1.5,
    "time_seconds": 0.06,
    "cost_estimate": "$0.01-0.05",
    "training_examples_count": 40
  }
}
```

---

### GET `/api/v1/optimization/optimizers`
**List available optimizers**

```bash
curl http://localhost:8000/api/v1/optimization/optimizers
```

**Response** (includes 4 optimizers):
```json
[
  {
    "name": "reflection_metrics",
    "description": "Reflection Metrics - FAST optimization (RECOMMENDED)",
    "parameters": {
      "speed": "Completes in <1 second",
      "cost": "$0.01-0.05",
      "quality": "+1.5% typical",
      "efficiency": "11.1x (best value)"
    }
  },
  {
    "name": "miprov2",
    "description": "MIPROv2 optimizer - Multi-stage Instruction Proposal",
    "parameters": {...}
  },
  ...
]
```

---

## Implementation Details

### New Components

#### 1. `/api/v1/optimization/fast` Endpoint
```python
@router.post("/fast", response_model=OptimizeResponse)
async def fast_optimization(
    request: OptimizeRequest,
    background_tasks: BackgroundTasks,
    skills_root: SkillsRoot,
) -> OptimizeResponse:
    """Fast optimization with Reflection Metrics + BootstrapFewShot"""
    # Forces optimizer to "reflection_metrics"
    # Runs in background like other optimization endpoints
```

#### 2. `_run_fast_optimization()` Function
Handles the fast optimization pipeline:
- Loads training data (JSON or skill paths)
- Configures DSPy with Gemini 3 Flash
- Runs reflection metrics evaluation
- Saves results

#### 3. `_reflection_metrics_optimize()` Function
The core optimization logic:
```python
