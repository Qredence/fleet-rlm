<!-- Chunk 825: bytes 2878547-2883532, type=class -->
class JobManager:
    """Manage job lifecycle across memory and database layers."""
    
    def __init__(self, memory_store: Optional[JobMemoryStore] = None):
        self.memory = memory_store or JobMemoryStore(ttl_minutes=60)
        self.db_repo: Optional[JobRepository] = None
    
    def set_db_repo(self, db_repo: JobRepository) -> None:
        """Set database repository (called at API startup)."""
        self.db_repo = db_repo
    
    def get_job(self, job_id: str) -> Optional[JobState]:
        """Retrieve job from memory (fast), fall back to DB (durable)."""
        # Try memory first (hot cache)
        job = self.memory.get(job_id)
        if job:
            logger.debug(f"Job {job_id} found in memory cache")
            return job
        
        # Fall back to database
        if self.db_repo:
            db_job = self.db_repo.get_by_id(job_id)
            if db_job:
                # Reconstruct JobState from DB model
                job_state = self._db_to_memory(db_job)
                # Warm the memory cache for future access
                self.memory.set(job_id, job_state)
                logger.info(f"Job {job_id} loaded from database")
                return job_state
        
        logger.warning(f"Job {job_id} not found in memory or database")
        return None
    
    def create_job(self, job_state: JobState) -> None:
        """Create a new job (memory + DB)."""
        # Store in memory immediately
        self.memory.set(job_state.job_id, job_state)
        
        # Persist to DB asynchronously
        if self.db_repo:
            self._save_to_db(job_state)
            logger.info(f"Job {job_state.job_id} created (memory + DB)")
    
    def update_job(self, job_id: str, updates: dict[str, Any]) -> Optional[JobState]:
        """Update job in both layers."""
        # Update memory (fast path for in-flight updates)
        job = self.memory.get(job_id)
        if not job:
            job = self.get_job(job_id)  # Try DB fallback
        
        if not job:
            logger.error(f"Cannot update: job {job_id} not found")
            return None
        
        # Apply updates
        for key, value in updates.items():
            if hasattr(job, key):
                setattr(job, key, value)
        
        # Update both layers
        self.memory.set(job_id, job)
        if self.db_repo:
            self._save_to_db(job)
        
        logger.debug(f"Job {job_id} updated")
        return job
    
    def save_job(self, job: JobState) -> bool:
        """Explicit save to DB (for completed/important jobs)."""
        self.memory.set(job.job_id, job)
        
        if self.db_repo:
            try:
                self._save_to_db(job)
                logger.info(f"Job {job.job_id} saved to database")
                return True
            except Exception as e:
                logger.error(f"Failed to save job {job.job_id}: {e}")
                return False
        
        return True
    
    def _save_to_db(self, job: JobState) -> None:
        """Internal: Save JobState to database."""
        if not self.db_repo:
            return
        
        # Serialize nested objects
        deep_understanding = None
        tdd_workflow = None
        hitl_interactions = []
        
        if job.deep_understanding:
            deep_understanding = job.deep_understanding.model_dump()
        
        if job.tdd_workflow:
            tdd_workflow = job.tdd_workflow.model_dump()
        
        # Note: HITL interactions should be stored separately
        # See Phase 2 for implementation
        
        job_data = {
            'job_id': UUID(job.job_id),
            'status': job.status,
            'result': job.result,
            'error': job.error,
            'progress_percent': job.progress_percent,
            'updated_at': job.updated_at,
            'deep_understanding': deep_understanding,
            'tdd_workflow': tdd_workflow,
        }
        
        # Upsert to database
        existing = self.db_repo.get_by_id(job.job_id)
        if existing:
            self.db_repo.update(db_obj=existing, obj_in=job_data)
        else:
            self.db_repo.create(obj_in=job_data)
    
    def _db_to_memory(self, db_job: Any) -> JobState:
        """Internal: Reconstruct JobState from database model."""
        # Implementation in Phase 2
        # For now: schema compatibility layer
        job_state = JobState(job_id=str(db_job.job_id))
        job_state.status = db_job.status
        job_state.result = db_job.result
        job_state.error = db_job.error
        job_state.progress_percent = db_job.progress_percent or 0
        job_state.updated_at = db_job.updated_at or datetime.now(UTC)
        return job_state
    
    def cleanup_expired(self) -> int:
        """Clean up expired memory entries (call from background task)."""
        return self.memory.cleanup_expired()


# Global instance
_job_manager: Optional[JobManager] = None

