<!-- Chunk 459: bytes 662668-719745, type=function -->
def main():
    parser = argparse.ArgumentParser(description="Validate DSPy signatures")
    parser.add_argument("--signature", required=True, help="Name of the signature class")
    parser.add_argument(
        "--module",
        default="agentic_fleet.dspy_modules.signatures",
        help="Module path",
    )
    parser.add_argument("--strict", action="store_true", help="Enable strict validation")

    args = parser.parse_args()

    # Import the module
    try:
        module = importlib.import_module(args.module)
    except ImportError as e:
        print(f"Error importing module: {e}")
        sys.exit(1)

    # Get the signature class
    if not hasattr(module, args.signature):
        print(f"Error: Signature '{args.signature}' not found in module")
        print(f"Available signatures: {[name for name in dir(module) if not name.startswith('_')]}")
        sys.exit(1)

    signature_class = getattr(module, args.signature)

    # Validate
    success = validate_signature(signature_class, args.strict)
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()


============================================================
END FILE: .fleet/letta/skills/dspy-optimization/scripts/test-signature.py
============================================================

============================================================
FILE: .fleet/letta/skills/fleet-management/SKILL.md
============================================================

---
name: letta-fleet-management
description: Manage Letta AI agent fleets declaratively with kubectl-style CLI. Use when creating, updating, or managing multiple Letta agents with shared configurations, memory blocks, tools, and folders.
license: MIT
---

# lettactl

kubectl-style CLI for managing Letta AI agent fleets declaratively.

## When to Use

- Deploying multiple agents with shared configurations
- Managing agent memory blocks, tools, and folders
- Applying templates to existing agents
- Programmatic fleet management via SDK

## Core Workflow

1. Define agents in `fleet.yaml`
2. Apply with `lettactl apply -f fleet.yaml`
3. Verify with `lettactl get agents` and `lettactl describe agent <name>`

## Fleet YAML Structure

```yaml
shared_blocks:
  - name: company-context
    description: Shared company knowledge
    limit: 5000
    from_file: ./context/company.md

agents:
  - name: support-agent
    description: Customer support assistant
    system_prompt:
      from_file: ./prompts/support.md
    llm_config:
      model: gpt-4o
      context_window: 128000
    memory_blocks:
      - name: persona
        description: Agent personality
        limit: 2000
        value: "You are a helpful support agent."
    shared_blocks:
      - company-context
    tools:
      - send_email
      - search_docs
```

See `reference/fleet-config.md` for full schema.

## CLI Commands

### Apply Configuration
```bash
lettactl apply -f fleet.yaml              # Create/update agents
lettactl apply -f fleet.yaml --dry-run    # Preview changes
lettactl apply -f fleet.yaml --match "*-draper"  # Template mode
```

### Inspect Resources
```bash
lettactl get agents                    # List all agents
lettactl get agents -o wide            # With details
lettactl get blocks --shared           # Shared blocks only
lettactl get tools --orphaned          # Unused tools
lettactl describe agent <name>         # Full agent details
```

### Messaging
```bash
lettactl send <agent> "Hello"          # Send message
lettactl send <agent> "Hi" --stream    # Stream response
lettactl messages list <agent>         # View history
lettactl messages reset <agent>        # Clear history
```

See `reference/cli-commands.md` for all options.

## Template Mode

Apply configuration to existing agents matching a pattern:

```bash
lettactl apply -f template.yaml --match "*-draper"
```

Uses three-way merge: preserves user-added resources while updating managed ones. See `reference/template-mode.md`.

## SDK Usage

```typescript
import { LettaCtl } from 'lettactl';

const ctl = new LettaCtl({ lettaBaseUrl: 'http://localhost:8283' });

await ctl.deployFromYaml('./fleet.yaml');
await ctl.deployFromYaml('./template.yaml', { match: '*-prod' });
```

See `reference/sdk-usage.md` for full API and `reference/cli-commands.md` for environment variables.


============================================================
END FILE: .fleet/letta/skills/fleet-management/SKILL.md
============================================================

============================================================
FILE: .fleet/letta/skills/fleet-management/reference/cli-commands.md
============================================================

# CLI Commands Reference

Complete command reference for lettactl.

## Global Options

```bash
--verbose, -v          # Verbose output
--no-spinner           # Disable spinner (for CI/CD)
--help, -h             # Show help
```

## apply

Apply fleet configuration to create or update agents.

```bash
lettactl apply -f <file>
```

### Options

| Option | Description |
|--------|-------------|
| `-f, --file <path>` | Path to fleet YAML file (required) |
| `--dry-run` | Preview changes without applying |
| `--agent <pattern>` | Filter agents by name pattern |
| `--match <pattern>` | Template mode: apply to existing agents matching pattern |
| `--root <path>` | Root path for resolving relative file paths |

### Examples

```bash
# Apply all agents
lettactl apply -f fleet.yaml

# Preview changes
lettactl apply -f fleet.yaml --dry-run

# Apply specific agent
lettactl apply -f fleet.yaml --agent support-agent

# Template mode: update existing agents
lettactl apply -f template.yaml --match "*-draper"
```

## get

List resources.

```bash
lettactl get <resource>
```

### Resources

- `agents` - List agents
- `blocks` - List memory blocks
- `tools` - List tools
- `folders` - List folders
- `mcp-servers` - List MCP servers

### Options

| Option | Description |
|--------|-------------|
| `-o, --output <format>` | Output format: `json`, `yaml`, `wide` |
| `--agent <name>` | Filter by agent (for blocks, tools, folders) |
| `--shared` | Show only shared resources (2+ agents) |
| `--orphaned` | Show only orphaned resources (0 agents) |

### Examples

```bash
# List agents
lettactl get agents
lettactl get agents -o wide
lettactl get agents -o json

# List blocks for specific agent
lettactl get blocks --agent my-agent

# Find orphaned tools
lettactl get tools --orphaned

# Find shared blocks
lettactl get blocks --shared
```

## describe

Show detailed information about a resource.

```bash
lettactl describe <resource> <name>
```

### Resources

- `agent` - Agent details
- `block` - Block details
- `tool` - Tool details

### Examples

```bash
lettactl describe agent support-agent
lettactl describe block company-context
lettactl describe tool send_email
```

## send

Send a message to an agent.

```bash
lettactl send <agent> <message>
```

### Options

| Option | Description |
|--------|-------------|
| `--stream` | Stream the response |
| `--async` | Send asynchronously (returns run ID) |
| `--max-steps <n>` | Maximum agent steps |
| `--enable-thinking` | Enable thinking mode |

### Examples

```bash
# Simple message
lettactl send my-agent "Hello, how are you?"

# Stream response
lettactl send my-agent "Explain quantum computing" --stream

# Async (returns immediately)
lettactl send my-agent "Process this data" --async
```

## messages

Manage agent message history.

### list

```bash
lettactl messages list <agent>
```

| Option | Description |
|--------|-------------|
| `--limit <n>` | Number of messages |
| `--order <asc\|desc>` | Sort order |
| `--before <id>` | Messages before ID |
| `--after <id>` | Messages after ID |
| `-o json` | JSON output |

### reset

Clear agent message history.

```bash
lettactl messages reset <agent>
lettactl messages reset <agent> --add-default  # Keep default messages
```

### compact

Compact/summarize message history.

```bash
lettactl messages compact <agent>
```

### cancel

Cancel running async messages.

```bash
lettactl messages cancel <agent>
lettactl messages cancel <agent> --run-ids id1,id2
```

## delete

Delete resources.

```bash
lettactl delete <resource> <name>
```

### Resources

- `agent` - Delete agent
- `block` - Delete block
- `tool` - Delete tool

### Examples

```bash
lettactl delete agent old-agent
lettactl delete block unused-block
lettactl delete tool deprecated-tool
```

## Environment Variables

| Variable | Description |
|----------|-------------|
| `LETTA_BASE_URL` | Letta server URL (required) |
| `LETTA_API_KEY` | API key for Letta Cloud |
| `SUPABASE_URL` | Supabase URL for bucket storage |
| `SUPABASE_SERVICE_ROLE_KEY` | Supabase service role key |
| `SUPABASE_ANON_KEY` | Supabase anonymous key |


============================================================
END FILE: .fleet/letta/skills/fleet-management/reference/cli-commands.md
============================================================

============================================================
FILE: .fleet/letta/skills/fleet-management/reference/fleet-config.md
============================================================

# Fleet Configuration Reference

Complete YAML schema for lettactl fleet configuration.

## Top-Level Structure

```yaml
shared_blocks: []      # Optional: blocks shared across agents
tools: []              # Optional: tool definitions
mcp_servers: []        # Optional: MCP server configs
agents: []             # Required: agent definitions
```

## Shared Blocks

```yaml
shared_blocks:
  - name: block-name           # Required: unique identifier
    description: Description   # Required: block purpose
    limit: 5000                # Required: max characters
    value: "Inline content"    # Option 1: inline value
    from_file: ./path.md       # Option 2: local file
    from_bucket:               # Option 3: Supabase storage
      bucket: bucket-name
      path: file/path.md
```

## Agent Definition

```yaml
agents:
  - name: agent-name                    # Required: unique name
    description: Agent description      # Optional

    system_prompt:                      # Required
      value: "Inline prompt"            # Option 1
      from_file: ./prompt.md            # Option 2
      from_bucket:                      # Option 3
        bucket: prompts
        path: agent/system.md

    llm_config:                         # Optional
      model: gpt-4o                     # Model name
      context_window: 128000            # Context size

    embedding: text-embedding-3-small   # Required for self-hosted, optional for Cloud

    memory_blocks: []                   # Optional: agent-specific blocks
    shared_blocks: []                   # Optional: references to shared_blocks
    tools: []                           # Optional: tool names
    folders: []                         # Optional: file folders
```

## Memory Blocks

Agent-specific memory blocks:

```yaml
memory_blocks:
  - name: persona                 # Required
    description: Agent persona    # Required
    limit: 2000                   # Required
    value: "Content here"         # Option 1: inline
    from_file: ./persona.md       # Option 2: file
    from_bucket:                  # Option 3: bucket
      bucket: memory
      path: personas/support.md
```

## Tools

### Inline Tool Definition

```yaml
tools:
  - name: search_docs
    description: Search documentation
    source_code: |
      def search_docs(query: str) -> str:
          """Search the documentation."""
          return f"Results for: {query}"
```

### File-Based Tool

```yaml
tools:
  - name: send_email
    from_file: ./tools/send_email.py
```

### Referencing Tools in Agents

```yaml
agents:
  - name: my-agent
    tools:
      - search_docs      # Reference by name
      - send_email
```

## MCP Servers

```yaml
mcp_servers:
  - name: github-server
    type: sse
    url: http://localhost:3000/sse

  - name: local-tools
    type: stdio
    command: npx
    args: ["-y", "@modelcontextprotocol/server-filesystem", "/tmp"]
```

## Folders

Attach file folders to agents for RAG:

```yaml
agents:
  - name: docs-agent
    folders:
      - name: documentation
        files:
          - ./docs/guide.md
          - ./docs/api.md
          - ./docs/**/*.md    # Glob patterns supported
```

## File Source Priority

When multiple sources specified, priority is:
1. `from_bucket` (Supabase storage)
2. `from_file` (local filesystem)
3. `value` (inline content)

## Variable Interpolation

Environment variables can be used:

```yaml
agents:
  - name: ${AGENT_NAME:-default-agent}
    llm_config:
      model: ${MODEL_NAME}
```

## Complete Example

```yaml
shared_blocks:
  - name: company-knowledge
    description: Company policies and procedures
    limit: 10000
    from_file: ./context/company.md

tools:
  - name: lookup_customer
    from_file: ./tools/lookup_customer.py

mcp_servers:
  - name: slack-server
    type: sse
    url: http://localhost:3001/sse

agents:
  - name: support-agent
    description: Customer support assistant
    system_prompt:
      from_file: ./prompts/support.md
    llm_config:
      model: gpt-4o
      context_window: 128000
    memory_blocks:
      - name: persona
        description: Agent personality traits
        limit: 2000
        value: |
          You are a friendly, professional support agent.
          Always be helpful and concise.
    shared_blocks:
      - company-knowledge
    tools:
      - lookup_customer
    folders:
      - name: faq
        files:
          - ./faq/*.md
```


============================================================
END FILE: .fleet/letta/skills/fleet-management/reference/fleet-config.md
============================================================

============================================================
FILE: .fleet/letta/skills/fleet-management/reference/sdk-usage.md
============================================================

# SDK Usage Reference

Programmatic API for managing Letta agent fleets.

## Installation

```bash
npm install lettactl
# or
pnpm add lettactl
```

## Quick Start

```typescript
import { LettaCtl } from 'lettactl';

const ctl = new LettaCtl({
  lettaBaseUrl: 'http://localhost:8283'
});

await ctl.deployFromYaml('./fleet.yaml');
```

## LettaCtl Class

### Constructor

```typescript
const ctl = new LettaCtl({
  lettaBaseUrl?: string,           // Letta server URL
  lettaApiKey?: string,            // For Letta Cloud
  supabaseUrl?: string,            // For bucket storage
  supabaseAnonKey?: string,        // Supabase auth
  supabaseServiceRoleKey?: string  // Supabase service role
});
```

Environment variables are used as defaults if options not provided.

### deployFromYaml

Deploy agents from a YAML file.

```typescript
await ctl.deployFromYaml(
  yamlPath: string,
  options?: {
    dryRun?: boolean,        // Preview only
    agentPattern?: string,   // Filter agents
    match?: string,          // Template mode pattern
    rootPath?: string        // Root for relative paths
  }
);
```

### deployFromYamlString

Deploy from YAML string content.

```typescript
const yaml = `
agents:
  - name: my-agent
    system_prompt:
      value: You are helpful.
`;

await ctl.deployFromYamlString(yaml, {
  dryRun: false
});
```

### deployFleet

Deploy from a FleetConfig object.

```typescript
await ctl.deployFleet(
  config: FleetConfig,
  options?: {
    dryRun?: boolean,
    agentPattern?: string,
    match?: string
  }
);
```

### validateFleet

Validate configuration without deploying.

```typescript
const isValid = ctl.validateFleet(config);
```

### createFleetConfig

Builder for creating fleet configs programmatically.

```typescript
const config = ctl.createFleetConfig()
  .addSharedBlock({
    name: 'context',
    description: 'Shared context',
    limit: 5000,
    value: 'Company info here'
  })
  .addAgent({
    name: 'support-agent',
    system_prompt: { value: 'You are helpful.' },
    shared_blocks: ['context'],
    tools: ['search']
  })
  .build();

await ctl.deployFleet(config);
```

## FleetConfig Type

```typescript
interface FleetConfig {
  shared_blocks?: SharedBlock[];
  tools?: ToolConfig[];
  mcp_servers?: McpServerConfig[];
  agents: AgentConfig[];
}

interface AgentConfig {
  name: string;
  description?: string;
  system_prompt: ContentSource;
  llm_config?: {
    model?: string;
    context_window?: number;
  };
  embedding?: string;
  memory_blocks?: MemoryBlock[];
  shared_blocks?: string[];
  tools?: string[];
  folders?: FolderConfig[];
}

interface ContentSource {
  value?: string;
  from_file?: string;
  from_bucket?: {
    bucket: string;
    path: string;
  };
}

interface MemoryBlock {
  name: string;
  description: string;
  limit: number;
  value?: string;
  from_file?: string;
  from_bucket?: BucketSource;
}

interface SharedBlock extends MemoryBlock {}
```

## Template Mode

Apply configuration to existing agents:

```typescript
// Update all agents matching pattern
await ctl.deployFromYaml('./template.yaml', {
  match: '*-production'
});

// Programmatic template mode
await ctl.deployFleet(templateConfig, {
  match: 'support-*'
});
```

## Error Handling

```typescript
try {
  await ctl.deployFromYaml('./fleet.yaml');
} catch (error) {
  if (error.message.includes('validation')) {
    console.error('Invalid configuration:', error.message);
  } else if (error.message.includes('LETTA_BASE_URL')) {
    console.error('Missing environment variable');
  } else {
    throw error;
  }
}
```

## Example: Dynamic Fleet Creation

```typescript
import { LettaCtl } from 'lettactl';

async function createAgentFleet(customers: string[]) {
  const ctl = new LettaCtl();

  const config = ctl.createFleetConfig()
    .addSharedBlock({
      name: 'product-info',
      description: 'Product documentation',
      limit: 10000,
      from_file: './docs/products.md'
    });

  for (const customer of customers) {
    config.addAgent({
      name: `${customer}-support`,
      description: `Support agent for ${customer}`,
      system_prompt: {
        value: `You are a support agent for ${customer}.`
      },
      shared_blocks: ['product-info'],
      tools: ['lookup_order', 'send_email']
    });
  }

  await ctl.deployFleet(config.build());
}
```


============================================================
END FILE: .fleet/letta/skills/fleet-management/reference/sdk-usage.md
============================================================

============================================================
FILE: .fleet/letta/skills/fleet-management/reference/template-mode.md
============================================================

# Template Mode Reference

Apply configurations to existing agents using kubectl-style three-way merge.

## Overview

Template mode updates existing agents while preserving user-added resources. Uses the `--match` flag to target agents by name pattern.

```bash
lettactl apply -f template.yaml --match "*-draper"
```

## How It Works

### Three-Way Merge

Compares three states to determine changes:

1. **Last Applied** - Previous configuration applied by lettactl
2. **Current State** - Agent's current state on server
3. **Desired State** - New configuration being applied

### Merge Semantics

| Last Applied | Current | Desired | Result |
|--------------|---------|---------|--------|
| Has tool A | Has tool A | Has tool A | Keep A |
| Has tool A | Has tool A | No tool A | Remove A |
| No tool A | Has tool A | No tool A | Keep A (user-added) |
| No tool A | No tool A | Has tool A | Add A |

**Key principle**: Resources added by users (not in last-applied) are preserved.

## First Apply Behavior

On first template apply to an agent:
- Uses MERGE semantics (no removals)
- Adds new resources from template
- Preserves all existing resources
- Stores configuration as baseline for future applies

## Conflict Detection

Content changes are tracked via SHA-256 hashes:

- **Tool source code** - Hash of tool implementation
- **Memory block content** - Hash of block value
- **File content** - Hash of files in folders

If server content differs from last-applied hash, lettactl detects potential conflicts.

## Template YAML Structure

Template files are standard fleet configs. The agent name in the template is ignored; configuration is applied to matched agents.

```yaml
agents:
  - name: template          # Name ignored in template mode
    system_prompt:
      from_file: ./prompts/standard.md
    llm_config:
      model: gpt-4o
    memory_blocks:
      - name: guidelines
        description: Standard guidelines
        limit: 3000
        from_file: ./blocks/guidelines.md
    tools:
      - standard_search
      - standard_reply
```

## Pattern Matching

The `--match` flag uses glob patterns:

```bash
--match "*-draper"        # Ends with -draper
--match "support-*"       # Starts with support-
--match "*-prod-*"        # Contains -prod-
--match "agent-001"       # Exact match
```

## Examples

### Update All Production Agents

```bash
# Template with production config
cat > prod-template.yaml << EOF
agents:
  - name: template
    llm_config:
      model: gpt-4o
      context_window: 128000
    tools:
      - production_logger
      - error_reporter
EOF

lettactl apply -f prod-template.yaml --match "*-prod"
```

### Add Shared Block to Existing Agents

```yaml
shared_blocks:
  - name: new-policy
    description: Updated company policy
    limit: 5000
    from_file: ./policy-2024.md

agents:
  - name: template
    shared_blocks:
      - new-policy
```

```bash
lettactl apply -f add-policy.yaml --match "*"
```

### SDK Template Mode

```typescript
import { LettaCtl } from 'lettactl';

const ctl = new LettaCtl();

// Apply template to matching agents
await ctl.deployFromYaml('./template.yaml', {
  match: '*-customer-*'
});

// Programmatic template
await ctl.deployFleet({
  agents: [{
    name: 'template',
    tools: ['new_tool'],
    memory_blocks: [{
      name: 'update',
      description: 'New memory block',
      limit: 2000,
      value: 'Updated content'
    }]
  }]
}, {
  match: 'support-*'
});
```

## Metadata Storage

Template mode stores last-applied configuration in agent metadata under `lettactl.lastApplied`. This enables accurate three-way merge on subsequent applies.

```json
{
  "lettactl.lastApplied": {
    "tools": ["tool1", "tool2"],
    "sharedBlocks": ["block1"],
    "toolHashes": {
      "tool1": "abc123..."
    },
    "blockHashes": {
      "block1": "def456..."
    }
  }
}
```

## Limitations

- Pattern must match at least one agent
- Cannot create new agents in template mode
- Shared blocks are updated globally (affect all agents using them)


============================================================
END FILE: .fleet/letta/skills/fleet-management/reference/template-mode.md
============================================================

============================================================
FILE: .fleet/letta/skills/initiate-memory/SKILL.md
============================================================

---
name: initializing-memory
description: Comprehensive guide for initializing or reorganizing agent memory. Load this skill when running /init, when the user asks you to set up your memory, or when you need guidance on creating effective memory blocks.
---

# Initializing Memory

The user has requested that you initialize or reorganize your memory state. You have access to the `memory` tool which allows you to create, edit, and manage memory blocks.

## Understanding Your Context

**Important**: You are a Letta Code agent, which is fundamentally different from typical AI coding assistants. Letta Code agents are **stateful** - users expect to work with the same agent over extended periods, potentially for the entire lifecycle of a project or even longer. Your memory is not just a convenience; it's how you get better over time and maintain continuity across sessions.

This command may be run in different scenarios:
- **Fresh agent**: You may have default memory blocks that were created when you were initialized
- **Existing agent**: You may have been working with the user for a while, and they want you to reorganize or significantly update your memory structure
- **Shared blocks**: Some memory blocks may be shared across multiple agents - be careful about modifying these

Before making changes, use the `memory` tool to inspect your current memory blocks and understand what already exists.

## What Coding Agents Should Remember

### 1. Procedures (Rules & Workflows)
Explicit rules and workflows that should always be followed:
- "Never commit directly to main - always use feature branches"
- "Always run lint before running tests"
- "Use conventional commits format for all commit messages"
- "Always check for existing tests before adding new ones"

### 2. Preferences (Style & Conventions)
User and project coding style preferences:
- "Never use try/catch for control flow"
- "Always add JSDoc comments to exported functions"
- "Prefer functional components over class components"
- "Use early returns instead of nested conditionals"

### 3. History & Context
Important historical context that informs current decisions:
- "We fixed this exact pagination bug two weeks ago - check PR #234"
- "This monorepo used to have 3 modules before the consolidation"
- "The auth system was refactored in v2.0 - old patterns are deprecated"
- "User prefers verbose explanations when debugging"

Note: For historical recall, you may also have access to `conversation_search` which can search past conversations. Memory blocks are for distilled, important information worth persisting permanently.

## Memory Scope Considerations

Consider whether information is:

**Project-scoped** (store in `project` block):
- Build commands, test commands, lint configuration
- Project architecture and key directories
- Team conventions specific to this codebase
- Technology stack and framework choices

**User-scoped** (store in `human` block):
- Personal coding preferences that apply across projects
- Communication style preferences
- General workflow habits

**Session/Task-scoped** (consider separate blocks like `ticket` or `context`):
- Current branch or ticket being worked on
- Debugging context for an ongoing investigation
- Temporary notes about a specific task

## Recommended Memory Structure

### Core Blocks (Usually Present)

**`persona`**: Your behavioral guidelines that augment your base system prompt.
- Your system prompt already contains comprehensive instructions for how to code and behave
- The persona block is for **learned adaptations** - things you discover about how the user wants you to behave
- Examples: "User said never use emojis", "User prefers terse responses", "Always explain reasoning before making changes"
- This block may start empty and grow over time as you learn the user's preferences

**`project`**: Project-specific information, conventions, and commands
- Build/test/lint commands
- Key directories and architecture
- Project-specific conventions from README, AGENTS.md, etc.

**`human`**: User preferences, communication style, general habits
- Cross-project preferences
- Working style and communication preferences

### Optional Blocks (Create as Needed)

**`ticket`** or **`task`**: Scratchpad for current work item context.
- **Important**: This is different from the TODO or Plan tools!
- TODO/Plan tools track active task lists and implementation plans (structured lists of what to do)
- A ticket/task memory block is a **scratchpad** for pinned context that should stay visible
- Examples: Linear ticket ID and URL, Jira issue key, branch name, PR number, relevant links
- Information that's useful to keep in context but doesn't fit in a TODO list

**`context`**: Debugging or investigation scratchpad
- Current hypotheses being tested
- Files already examined
- Clues and observations

**`decisions`**: Architectural decisions and their rationale
- Why certain approaches were chosen
- Trade-offs that were considered

## Writing Good Memory Blocks

**This is critical**: In the future, you (or a future version of yourself) will only see three things about each memory block:
1. The **label** (name)
2. The **description**
3. The **value** (content)

The reasoning you have *right now* about why you're creating a block will be lost. Your future self won't easily remember this initialization conversation (it can be searched, but it will no longer be in-context). Therefore:

**Labels should be:**
- Clear and descriptive (e.g., `project-conventions` not `stuff`)
- Consistent in style (e.g., all lowercase with hyphens)

**Descriptions are especially important:**
- Explain *what* this block is for and *when* to use it
- Explain *how* this block should influence your behavior
- Write as if explaining to a future version of yourself who has no context
- Good: "User's coding style preferences that should be applied to all code I write or review. Update when user expresses new preferences."
- Bad: "Preferences"

**Values should be:**
- Well-organized and scannable
- Updated regularly to stay relevant
- Pruned of outdated information

Think of memory block descriptions as documentation for your future self. The better you write them now, the more effective you'll be in future sessions.

## Research Depth

You can ask the user if they want a standard or deep research initialization:

**Standard initialization** (~5-20 tool calls):
- Inspect existing memory blocks
- Scan README, package.json/config files, AGENTS.md, CLAUDE.md
- Review git status and recent commits (from context below)
- Explore key directories and understand project structure
- Create/update your memory block structure to contain the essential information you need to know about the user, your behavior (learned preferences), the project you're working in, and any other information that will help you be an effective collaborator.

**Deep research initialization** (~100+ tool calls):
- Everything in standard initialization, plus:
- Use your TODO or Plan tool to create a systematic research plan
- Deep dive into git history for patterns, conventions, and context
- Analyze commit message conventions and branching strategy
- Explore multiple directories and understand architecture thoroughly
- Search for and read key source files to understand patterns
- Create multiple specialized memory blocks
- May involve multiple rounds of exploration

**What deep research can uncover:**
- **Contributors & team dynamics**: Who works on what areas? Who are the main contributors? (`git shortlog -sn`)
- **Coding habits**: When do people commit? (time patterns) What's the typical commit size?
- **Writing & commit style**: How verbose are commit messages? What conventions are followed?
- **Code evolution**: How has the architecture changed? What major refactors happened?
- **Review patterns**: Are there PR templates? What gets reviewed carefully vs rubber-stamped?
- **Pain points**: What areas have lots of bug fixes? What code gets touched frequently?
- **Related repositories**: Ask the user if there are other repos you should know about (e.g., a backend monorepo, shared libraries, documentation repos). These relationships can be crucial context.

This kind of deep context can make you significantly more effective as a long-term collaborator on the project.

If the user says "take as long as you need" or explicitly wants deep research, use your TODO or Plan tool to orchestrate a thorough, multi-step research process.

## Research Techniques

**File-based research:**
- README.md, CONTRIBUTING.md, AGENTS.md, CLAUDE.md
- Package manifests (package.json, Cargo.toml, pyproject.toml, go.mod)
- Config files (.eslintrc, tsconfig.json, .prettierrc)
- CI/CD configs (.github/workflows/, .gitlab-ci.yml)

**Git-based research** (if in a git repo):
- `git log --oneline -20` - Recent commit history and patterns
- `git branch -a` - Branching strategy
- `git log --format="%s" -50 | head -20` - Commit message conventions
- `git shortlog -sn --all | head -10` - Main contributors
- `git log --format="%an <%ae>" | sort -u` - Contributors with emails (more reliable for deduplication)
- Recent PRs or merge commits for context on ongoing work

**Important: Deduplicate contributors!** Git groups by exact author string, so the same person may appear multiple times with different names (e.g., "jsmith" and "John Smith" are likely the same person). Use emails to deduplicate, and apply common sense - usernames often match parts of full names.

## How to Do Thorough Research

**Don't just collect data - analyze and cross-reference it.**

Shallow research (bad):
- Run commands, copy output
- Take everything at face value
- List facts without understanding

Thorough research (good):
- **Cross-reference findings**: If two pieces of data seem inconsistent, dig deeper
- **Resolve ambiguities**: Don't leave questions unanswered (e.g., "are these two contributors the same person?")
- **Read actual content**: Don't just list file names - read key files to understand them
- **Look for patterns**: What do the commit messages tell you about workflow? What do file structures tell you about architecture?
- **Form hypotheses and verify**: "I think this team uses feature branches" → check git branch patterns to confirm
- **Think like a new team member**: What would you want to know on your first day?

**Questions to ask yourself during research:**
- Does this make sense? (e.g., why would there be two contributors with similar names?)
- What's missing? (e.g., no tests directory - is testing not done, or done differently?)
- What can I infer? (e.g., lots of "fix:" commits in one area → that area is buggy or complex)
- Am I just listing facts, or do I understand the project?

The goal isn't to produce a report - it's to genuinely understand the project and how this human(s) works so you can be an effective collaborator.

## On Asking Questions

**Ask important questions upfront, then be autonomous during execution.**

### Recommended Upfront Questions

You should ask these questions at the start (bundle them together in one AskUserQuestion call):

1. **Research depth**: "Standard or deep research (comprehensive, as long as needed)?"
2. **Identity**: "Which contributor are you?" (You can often infer this from git logs - e.g., if git shows "cpacker" as a top contributor, ask "Are you cpacker?")
3. **Related repos**: "Are there other repositories I should know about and consider in my research?" (e.g., backend monorepo, shared libraries)
4. **Memory updates**: "How often should I check if I should update my memory?" with options "Frequent (every 3-5 turns)" and "Occasional (every 8-10 turns)". This should be a binary question with "Memory" as the header.
5. **Communication style**: "Terse or detailed responses?"
6. **Any specific rules**: "Rules I should always follow?"

**Why these matter:**
- Identity lets you correlate git history to the user (their commits, PRs, coding style)
- Related repos provide crucial context (many projects span multiple repos)
- Workflow/communication style should be stored in the `human` block
- Rules go in `persona` block

### What NOT to ask

- Things you can find by reading files ("What's your test framework?")
- "What kind of work do you do? Reviewing PRs vs writing code?" - obvious from git log, most devs do everything
- Permission for obvious actions - just do them
- Questions one at a time - bundle them (but don't exhaust the user with too many questions at once)

**During execution**, be autonomous. Make reasonable choices and proceed.

## Memory Block Strategy

### Split Large Blocks

**Don't create monolithic blocks.** If a block is getting long (>50-100 lines), split it:

Instead of one huge `project` block, consider:
- `project-overview`: High-level description, tech stack, repo links
- `project-commands`: Build, test, lint, dev commands
- `project-conventions`: Commit style, PR process, code style
- `project-architecture`: Directory structure, key modules
- `project-gotchas`: Footguns, things to watch out for

This makes memory more scannable and easier to update and share with other agents.

### Update Memory Incrementally

**For deep research: Update memory as you go, not all at once at the end.**

Why this matters:
- Deep research can take many turns and millions of tokens
- Context windows overflow and trigger rolling summaries
- If you wait until the end to write memory, you may lose important details
- Write findings to memory blocks as you discover them

Good pattern:
1. Create block structure early (even with placeholder content)
2. Update blocks after each research phase
3. Refine and consolidate at the end

Remember, your memory tool allows you to easily add, edit, and remove blocks. There's no reason to wait until you "know everything" to write memory. Treat your memory blocks as a living scratchpad.

### Initialize ALL Relevant Blocks

Don't just update a single memory block. Based on your upfront questions, also update:

- **`human`**: Store the user's identity, workflow preferences, communication style
- **`persona`**: Store rules the user wants you to follow, behavioral adaptations
- **`project-*`**: Split project info across multiple focused blocks

And add memory blocks that you think make sense to add (e.g., `project-architecture`, `project-conventions`, `project-gotchas`, etc, or even splitting the `human` block into more focused blocks, or even multiple blocks for multiple users).

## Your Task

1. **Ask upfront questions**: Use AskUserQuestion with the recommended questions above (bundled together). This is critical - don't skip it.
2. **Inspect existing memory**: You may already have some memory blocks initialized. See what already exists, and analyze how it is or is not insufficient or incomplete.
3. **Identify the user**: From git logs and their answer, figure out who they are and store in `human` block. If relevant, ask questions to gather information about their preferences that will help you be a useful assistant to them.
4. **Update human/persona early**: Based on answers, update your memory blocks eagerly before diving into project research. You can always change them as you go, you're not locked into any memory configuration.
5. **Research the project**: Explore based on chosen depth. Use your TODO or plan tool to create a systematic research plan.
6. **Create/update project blocks incrementally**: Don't wait until the end - write findings as you go.
7. **Reflect and review**: See "Reflection Phase" below - this is critical for deep research.
8. **Ask user if done**: Check if they're satisfied or want you to continue refining.

## Reflection Phase (Critical for Deep Research)

Before finishing, you MUST do a reflection step. **Your memory blocks are visible to you in your system prompt right now.** Look at them carefully and ask yourself:

1. **Redundancy check**: Are there blocks with overlapping content? Either literally overlapping (due to errors while making memory edits), or semantically/conceptually overlapping?

2. **Completeness check**: Did you actually update ALL relevant blocks? For example:
   - Did you update `human` with the user's identity and preferences?
   - Did you update `persona` with behavioral rules they expressed?
   - Or did you only update project blocks and forget the rest?

3. **Quality check**: Are there typos, formatting issues, or unclear descriptions in your blocks?

4. **Structure check**: Would this make sense to your future self? Is anything missing? Is anything redundant?

**After reflection**, fix any issues you found. Then ask the user:
> "I've completed the initialization. Here's a brief summary of what I set up: [summary]. Should I continue refining, or is this good to proceed?"

This gives the user a chance to provide feedback or ask for adjustments before you finish.

Remember: Good memory management is an investment. The effort you put into organizing your memory now will pay dividends as you work with this user over time.


============================================================
END FILE: .fleet/letta/skills/initiate-memory/SKILL.md
============================================================

============================================================
FILE: .fleet/letta/skills/meta/skill-creator/SKILL.md
============================================================

---
name: skill-creator
description: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.
license: Complete terms in LICENSE.txt
---

# Skill Creator

This skill provides guidance for creating effective skills.

## About Skills

Skills are modular, self-contained packages that extend Claude's capabilities by providing
specialized knowledge, workflows, and tools. Think of them as "onboarding guides" for specific
domains or tasks—they transform Claude from a general-purpose agent into a specialized agent
equipped with procedural knowledge that no model can fully possess.

### What Skills Provide

1. Specialized workflows - Multi-step procedures for specific domains
2. Tool integrations - Instructions for working with specific file formats or APIs
3. Domain expertise - Company-specific knowledge, schemas, business logic
4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks

### Anatomy of a Skill

Every skill consists of a required SKILL.md file and optional bundled resources:

```
skill-name/
├── SKILL.md (required)
│   ├── YAML frontmatter metadata (required)
│   │   ├── name: (required)
│   │   └── description: (required)
│   └── Markdown instructions (required)
└── Bundled Resources (optional)
    ├── scripts/          - Executable code (Python/Bash/etc.)
    ├── references/       - Documentation intended to be loaded into context as needed
    └── assets/           - Files used in output (templates, icons, fonts, etc.)
```

#### SKILL.md (required)

**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. "This skill should be used when..." instead of "Use this skill when...").

#### Bundled Resources (optional)

##### Scripts (`scripts/`)

Executable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.

- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed
- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks
- **Benefits**: Token efficient, deterministic, may be executed without loading into context
- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments

##### References (`references/`)

Documentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.

- **When to include**: For documentation that Claude should reference while working
- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications
- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides
- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed
- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md
- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.

##### Assets (`assets/`)

Files not intended to be loaded into context, but rather used within the output Claude produces.

- **When to include**: When the skill needs files that will be used in the final output
- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography
- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified
- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context

### Progressive Disclosure Design Principle

Skills use a three-level loading system to manage context efficiently:

1. **Metadata (name + description)** - Always in context (~100 words)
2. **SKILL.md body** - When skill triggers (<5k words)
3. **Bundled resources** - As needed by Claude (Unlimited*)

*Unlimited because scripts can be executed without reading into context window.

## Skill Creation Process

To create a skill, follow the "Skill Creation Process" in order, skipping steps only if there is a clear reason why they are not applicable.

### Step 1: Understanding the Skill with Concrete Examples

Skip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.

To create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.

For example, when building an image-editor skill, relevant questions include:

- "What functionality should the image-editor skill support? Editing, rotating, anything else?"
- "Can you give some examples of how this skill would be used?"
- "I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?"
- "What would a user say that should trigger this skill?"

To avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.

Conclude this step when there is a clear sense of the functionality the skill should support.

### Step 2: Planning the Reusable Skill Contents

To turn concrete examples into an effective skill, analyze each example by:

1. Considering how to execute on the example from scratch
2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly

Example: When building a `pdf-editor` skill to handle queries like "Help me rotate this PDF," the analysis shows:

1. Rotating a PDF requires re-writing the same code each time
2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill

Example: When designing a `frontend-webapp-builder` skill for queries like "Build me a todo app" or "Build me a dashboard to track my steps," the analysis shows:

1. Writing a frontend webapp requires the same boilerplate HTML/React each time
2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill

Example: When building a `big-query` skill to handle queries like "How many users have logged in today?" the analysis shows:

1. Querying BigQuery requires re-discovering the table schemas and relationships each time
2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill

To establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.

### Step 3: Initializing the Skill

At this point, it is time to actually create the skill.

Skip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.

When creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.

Usage:

```bash
scripts/init_skill.py <skill-name> --path <output-directory>
```

The script:

- Creates the skill directory at the specified path
- Generates a SKILL.md template with proper frontmatter and TODO placeholders
- Creates example resource directories: `scripts/`, `references/`, and `assets/`
- Adds example files in each directory that can be customized or deleted

After initialization, customize or remove the generated SKILL.md and example files as needed.

### Step 4: Edit the Skill

When editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.

#### Start with Reusable Skill Contents

To begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.

Also, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.

#### Update SKILL.md

**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., "To accomplish X, do Y" rather than "You should do X" or "If you need to do X"). This maintains consistency and clarity for AI consumption.

To complete SKILL.md, answer the following questions:

1. What is the purpose of the skill, in a few sentences?
2. When should the skill be used?
3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.

### Step 5: Packaging a Skill

Once the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:

```bash
scripts/package_skill.py <path/to/skill-folder>
```

Optional output directory specification:

```bash
scripts/package_skill.py <path/to/skill-folder> ./dist
```

The packaging script will:

1. **Validate** the skill automatically, checking:
   - YAML frontmatter format and required fields
   - Skill naming conventions and directory structure
   - Description completeness and quality
   - File organization and resource references

2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.

If validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.

### Step 6: Iterate

After testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.

**Iteration workflow:**
1. Use the skill on real tasks
2. Notice struggles or inefficiencies
3. Identify how SKILL.md or bundled resources should be updated
4. Implement changes and test again


============================================================
END FILE: .fleet/letta/skills/meta/skill-creator/SKILL.md
============================================================

============================================================
FILE: .fleet/letta/skills/meta/skill-creator/scripts/init_skill.py
============================================================

#!/usr/bin/env python3
"""
Skill Initializer - Creates a new skill from template

Usage:
    init_skill.py <skill-name> --path <path>

Examples:
    init_skill.py my-new-skill --path skills/public
    init_skill.py my-api-helper --path skills/private
    init_skill.py custom-skill --path /custom/location
"""

import sys
from pathlib import Path

SKILL_TEMPLATE = """---
name: {skill_name}
description: [TODO: Complete and informative explanation of what the skill does and when to use it. Include WHEN to use this skill - specific scenarios, file types, or tasks that trigger it.]
---

# {skill_title}

## Overview

[TODO: 1-2 sentences explaining what this skill enables]

## Structuring This Skill

[TODO: Choose the structure that best fits this skill's purpose. Common patterns:

**1. Workflow-Based** (best for sequential processes)
- Works well when there are clear step-by-step procedures
- Example: DOCX skill with "Workflow Decision Tree" → "Reading" → "Creating" → "Editing"
- Structure: ## Overview → ## Workflow Decision Tree → ## Step 1 → ## Step 2...

**2. Task-Based** (best for tool collections)
- Works well when the skill offers different operations/capabilities
- Example: PDF skill with "Quick Start" → "Merge PDFs" → "Split PDFs" → "Extract Text"
- Structure: ## Overview → ## Quick Start → ## Task Category 1 → ## Task Category 2...

**3. Reference/Guidelines** (best for standards or specifications)
- Works well for brand guidelines, coding standards, or requirements
- Example: Brand styling with "Brand Guidelines" → "Colors" → "Typography" → "Features"
- Structure: ## Overview → ## Guidelines → ## Specifications → ## Usage...

**4. Capabilities-Based** (best for integrated systems)
- Works well when the skill provides multiple interrelated features
- Example: Product Management with "Core Capabilities" → numbered capability list
- Structure: ## Overview → ## Core Capabilities → ### 1. Feature → ### 2. Feature...

Patterns can be mixed and matched as needed. Most skills combine patterns (e.g., start with task-based, add workflow for complex operations).

Delete this entire "Structuring This Skill" section when done - it's just guidance.]

## [TODO: Replace with the first main section based on chosen structure]

[TODO: Add content here. See examples in existing skills:
- Code samples for technical skills
- Decision trees for complex workflows
- Concrete examples with realistic user requests
- References to scripts/templates/references as needed]

## Resources

This skill includes example resource directories that demonstrate how to organize different types of bundled resources:

### scripts/
Executable code (Python/Bash/etc.) that can be run directly to perform specific operations.

**Examples from other skills:**
- PDF skill: `fill_fillable_fields.py`, `extract_form_field_info.py` - utilities for PDF manipulation
- DOCX skill: `document.py`, `utilities.py` - Python modules for document processing

**Appropriate for:** Python scripts, shell scripts, or any executable code that performs automation, data processing, or specific operations.

**Note:** Scripts may be executed without loading into context, but can still be read by Claude for patching or environment adjustments.

### references/
Documentation and reference material intended to be loaded into context to inform Claude's process and thinking.

**Examples from other skills:**
- Product management: `communication.md`, `context_building.md` - detailed workflow guides
- BigQuery: API reference documentation and query examples
- Finance: Schema documentation, company policies

**Appropriate for:** In-depth documentation, API references, database schemas, comprehensive guides, or any detailed information that Claude should reference while working.

### assets/
Files not intended to be loaded into context, but rather used within the output Claude produces.

**Examples from other skills:**
- Brand styling: PowerPoint template files (.pptx), logo files
- Frontend builder: HTML/React boilerplate project directories
- Typography: Font files (.ttf, .woff2)

**Appropriate for:** Templates, boilerplate code, document templates, images, icons, fonts, or any files meant to be copied or used in the final output.

---

**Any unneeded directories can be deleted.** Not every skill requires all three types of resources.
"""

EXAMPLE_SCRIPT = '''#!/usr/bin/env python3
"""
Example helper script for {skill_name}

This is a placeholder script that can be executed directly.
Replace with actual implementation or delete if not needed.

Example real scripts from other skills:
- pdf/scripts/fill_fillable_fields.py - Fills PDF form fields
- pdf/scripts/convert_pdf_to_images.py - Converts PDF pages to images
"""

