<!-- Chunk 1261: bytes 4695115-4697713, type=function -->
def main():
    """Main entry point."""
    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        demo_tracking()
    else:
        print("\n" + "=" * 70)
        print("üîç DSPy TRACKING UTILITY")
        print("=" * 70)
        print("\nUsage:")
        print("  python scripts/dspy_tracker.py demo    # Run tracking demonstration")
        print("\nIntegration:")
        print("  1. Wrap DSPy execution with tracker.track_execution()")
        print("  2. Wrap optimization with tracker.track_optimization()")
        print("  3. Call tracker.save_session() after work session")
        print("\nOutput:")
        print("  config/dspy_tracking/session_*.json")
        print("  config/dspy_tracking/executions_*.json")
        print("  config/dspy_tracking/optimizations_*.json")
        print("\n" + "=" * 70)


if __name__ == "__main__":
    main()


============================================================
END FILE: scripts/internal/opt/dspy_tracker.py
============================================================

============================================================
FILE: scripts/internal/opt/run_dspy_tools.py
============================================================

#!/usr/bin/env python3
"""
CLI tool for running DSPy evaluation and optimization.

This script provides commands for:
1. Evaluating existing skills quality
2. Optimizing skill creation programs
3. Comparing baseline vs optimized performance

Usage:
    # Evaluate all skills
    python scripts/run_dspy_tools.py evaluate

    # Evaluate specific directory
    python scripts/run_dspy_tools.py evaluate --skills-dir skills/technical_skills

    # Run optimization
    python scripts/run_dspy_tools.py optimize

    # Run optimization with specific optimizer
    python scripts/run_dspy_tools.py optimize --optimizer bootstrap_fewshot

    # List saved optimized programs
    python scripts/run_dspy_tools.py list-programs

    # Evaluate a single skill file
    python scripts/run_dspy_tools.py evaluate-file skills/path/to/SKILL.md
"""

from __future__ import annotations

import argparse
import json
import logging
import sys
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from skill_fleet.core.dspy.evaluation import run_evaluation
from skill_fleet.core.dspy.metrics import assess_skill_quality
from skill_fleet.core.dspy.optimization import SkillOptimizer, run_optimization

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


