{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f71b95b",
   "metadata": {},
   "source": [
    "# RLM with Modal Sandbox (DSPy 3.1.3)\n",
    "\n",
    "This tutorial shows how to use **`dspy.RLM`** (Recursive Language Model) with [Modal](https://modal.com) for secure, sandboxed code execution in the cloud.\n",
    "\n",
    "**What is RLM?** RLM is an inference strategy where the LLM writes Python code to programmatically explore data, call sub-LLMs over snippets, and iteratively build up answers — instead of feeding long contexts directly into the model.\n",
    "\n",
    "**Why Modal?** By default, `dspy.RLM` uses a local Deno/Pyodide WASM sandbox. Modal lets you run that code in an isolated cloud container with configurable resources, dependencies, and secrets.\n",
    "\n",
    "**What we'll do:**\n",
    "1. Implement a `ModalInterpreter` that satisfies DSPy's `CodeInterpreter` protocol\n",
    "2. Use `modal.Sandbox` to execute code inside an ephemeral cloud container\n",
    "3. Run an RLM agent that writes and executes code remotely\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Python 3.10+**\n",
    "- **Modal account**: Sign up at [modal.com](https://modal.com) and run `modal setup`\n",
    "- **Modal secret**: Create a secret named `LITELLM` that contains the environment variables used by DSPy/LiteLLM:\n",
    "  - `DSPY_LM_MODEL` (e.g., `openai/gemini-3-flash-preview`)\n",
    "  - `DSPY_LM_API_BASE` (your LiteLLM proxy base URL)\n",
    "  - `DSPY_LLM_API_KEY` (API key for the proxy/provider)\n",
    "  - optional: `DSPY_LM_MAX_TOKENS`\n",
    "\n",
    "  Example (run in a terminal):\n",
    "  ```bash\n",
    "  modal secret create LITELLM \\\n",
    "    DSPY_LM_MODEL=... \\\n",
    "    DSPY_LM_API_BASE=... \\\n",
    "    DSPY_LLM_API_KEY=... \\\n",
    "    DSPY_LM_MAX_TOKENS=...\n",
    "  ```\n",
    "\n",
    "- **Security note**: don’t hard-code API keys in notebooks, and don’t print them. If a key was ever pasted into a notebook/chat, rotate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc01761",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a4649fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -qU \"dspy==3.1.3\" modal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6451ed",
   "metadata": {},
   "source": [
    "## 2. Imports and Configuration\n",
    "\n",
    "We configure one LM locally for the *planner* (the model that writes Python code each iteration).\n",
    "\n",
    "This notebook expects the following environment variables to be set **locally** (for the planner):\n",
    "- `DSPY_LM_MODEL`\n",
    "- `DSPY_LM_API_BASE`\n",
    "- `DSPY_LLM_API_KEY`\n",
    "- optional: `DSPY_LM_MAX_TOKENS`\n",
    "\n",
    "The same variables are also injected into the Modal sandbox via the `LITELLM` secret, so any sandbox-side LM calls (via tool-bridged `llm_query`) use identical credentials without hard-coding secrets in the notebook.\n",
    "\n",
    "**Important**: Modal secrets are only available *inside* Modal containers/sandboxes. They do **not** automatically set environment variables for your local notebook kernel.\n",
    "This notebook will try to load a local `.env` from the project root (if present) to configure the planner LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38fe5e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner LM configured: openai/gemini-3-flash-preview\n",
      "(Tip: don’t print API keys.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import dspy\n",
    "\n",
    "# ---- Load local .env (for the planner LM) ----\n",
    "# Modal secrets are only available *inside* Modal; they do not configure your local kernel.\n",
    "def _find_project_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"pyproject.toml\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "def _load_dotenv(path: Path) -> None:\n",
    "    if not path.exists():\n",
    "        return\n",
    "    try:\n",
    "        for raw in path.read_text().splitlines():\n",
    "            line = raw.strip()\n",
    "            if not line or line.startswith(\"#\") or \"=\" not in line:\n",
    "                continue\n",
    "            k, v = line.split(\"=\", 1)\n",
    "            k, v = k.strip(), v.strip()\n",
    "            if len(v) >= 2 and ((v[0] == v[-1] == '\\\"') or (v[0] == v[-1] == \"'\")):\n",
    "                v = v[1:-1]\n",
    "            if k and k not in os.environ:\n",
    "                os.environ[k] = v\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not load {path}: {e}\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root(Path.cwd())\n",
    "_load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "# ---- Guard against module shadowing ----\n",
    "# A local `modal.py` (or even a stale compiled `__pycache__/modal.*.pyc`) in the\n",
    "# notebook's working directory can shadow the third-party `modal` package.\n",
    "shadow_py = Path.cwd() / \"modal.py\"\n",
    "shadow_pyc_dir = Path.cwd() / \"__pycache__\"\n",
    "shadow_pycs = list(shadow_pyc_dir.glob(\"modal.*.pyc\")) if shadow_pyc_dir.exists() else []\n",
    "\n",
    "if shadow_py.exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Found {shadow_py} which shadows the 'modal' package. \"\n",
    "        \"Rename/delete it (e.g., modal_get_started.py) and restart the kernel.\"\n",
    "    )\n",
    "\n",
    "if shadow_pycs:\n",
    "    removed: list[str] = []\n",
    "    failed: list[str] = []\n",
    "    for p in shadow_pycs:\n",
    "        try:\n",
    "            p.unlink()\n",
    "            removed.append(str(p))\n",
    "        except Exception:\n",
    "            failed.append(str(p))\n",
    "\n",
    "    if removed:\n",
    "        print(\"Removed shadowing bytecode files:\\n\" + \"\\n\".join(removed))\n",
    "    if failed:\n",
    "        raise RuntimeError(\n",
    "            \"Found shadowing bytecode files but could not remove them:\\n\"\n",
    "            + \"\\n\".join(failed)\n",
    "            + \"\\nDelete them manually and restart the kernel.\"\n",
    "        )\n",
    "\n",
    "# If a previous import attempt loaded a bad `modal` module, clear modal-related\n",
    "# modules to avoid weird partially-initialized states.\n",
    "#\n",
    "# Note: Modal uses a generated `modal_proto` package under the hood; when upgrading\n",
    "# modal in a running kernel, stale `modal_proto` modules can cause type mismatches.\n",
    "MODULE_PREFIXES_TO_PURGE = (\n",
    "    \"modal\",\n",
    "    \"modal_proto\",\n",
    "    \"grpclib\",\n",
    "    \"fleet_rlm\",\n",
    ")\n",
    "\n",
    "for name in list(sys.modules.keys()):\n",
    "    if name in MODULE_PREFIXES_TO_PURGE or any(name.startswith(p + \".\") for p in MODULE_PREFIXES_TO_PURGE):\n",
    "        sys.modules.pop(name, None)\n",
    "\n",
    "# Import modal after purging to ensure clean import\n",
    "import modal  # noqa: E402\n",
    "\n",
    "\n",
    "def configure_planner_from_env() -> bool:\n",
    "    \"\"\"Configure DSPy planner LM from environment variables.\n",
    "\n",
    "    Expected (local):\n",
    "      - DSPY_LM_MODEL\n",
    "      - DSPY_LLM_API_KEY (or DSPY_LM_API_KEY)\n",
    "      - optional: DSPY_LM_API_BASE, DSPY_LM_MAX_TOKENS\n",
    "\n",
    "    Returns True if configured, False if required env vars are missing.\n",
    "    \"\"\"\n",
    "\n",
    "    api_key = os.environ.get(\"DSPY_LLM_API_KEY\") or os.environ.get(\"DSPY_LM_API_KEY\")\n",
    "    missing: list[str] = []\n",
    "    if not os.environ.get(\"DSPY_LM_MODEL\"):\n",
    "        missing.append(\"DSPY_LM_MODEL\")\n",
    "    if not api_key:\n",
    "        # DSPy expects DSPY_LLM_API_KEY, but some setups use DSPY_LM_API_KEY.\n",
    "        missing.append(\"DSPY_LLM_API_KEY\")\n",
    "    if missing:\n",
    "        print(\n",
    "            \"Planner LM not configured yet. Missing env vars: \"\n",
    "            + \", \".join(missing)\n",
    "            + \"\\nSet them locally (e.g., export in your shell before starting Jupyter, or create a .env at the project root) and re-run this cell.\" \n",
    "        )\n",
    "        return False\n",
    "\n",
    "    planner_lm = dspy.LM(\n",
    "        os.environ[\"DSPY_LM_MODEL\"],\n",
    "        api_base=os.environ.get(\"DSPY_LM_API_BASE\"),\n",
    "        api_key=api_key,\n",
    "        max_tokens=int(os.environ.get(\"DSPY_LM_MAX_TOKENS\", \"16000\")),\n",
    "    )\n",
    "\n",
    "    dspy.configure(lm=planner_lm)\n",
    "    print(f\"Planner LM configured: {planner_lm.model}\")\n",
    "    print(\"(Tip: don’t print API keys.)\")\n",
    "    return True\n",
    "\n",
    "\n",
    "PLANNER_READY = configure_planner_from_env()\n",
    "\n",
    "# We’ll pass `modal.Secret.from_name('LITELLM')` into the sandbox so the *remote*\n",
    "# Python REPL can access the same environment variables without hard-coding them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d05203",
   "metadata": {},
   "source": [
    "### Optional: sanity-check the Modal secret (without leaking it)\n",
    "\n",
    "The snippet below confirms that the `LITELLM` secret is mounted in Modal by checking for the *presence* of environment variables. It deliberately does **not** print secret values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030754c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret env presence: {\"DSPY_LM_MODEL\": true, \"DSPY_LM_API_BASE\": true, \"DSPY_LLM_API_KEY\": true, \"DSPY_LM_MAX_TOKENS\": true}\n"
     ]
    }
   ],
   "source": [
    "# Sandboxes require an App when created from a local environment.\n",
    "app = modal.App.lookup(\"dspy-rlm-secret-check\", create_if_missing=True)\n",
    "\n",
    "sb = modal.Sandbox.create(\n",
    "    app=app,\n",
    "    secrets=[modal.Secret.from_name(\"LITELLM\")],\n",
    "    timeout=60,\n",
    ")\n",
    "try:\n",
    "    code = r\"\"\"\n",
    "import json, os\n",
    "keys = [\n",
    "  'DSPY_LM_MODEL',\n",
    "  'DSPY_LM_API_BASE',\n",
    "  'DSPY_LLM_API_KEY',\n",
    "  'DSPY_LM_MAX_TOKENS',\n",
    "]\n",
    "print(json.dumps({k: bool(os.environ.get(k)) for k in keys}))\n",
    "\"\"\"\n",
    "    p = sb.exec(\"python\", \"-c\", code, timeout=60)\n",
    "    p.wait()\n",
    "    print(\"Secret env presence:\", p.stdout.read().strip())\n",
    "finally:\n",
    "    sb.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aca65b",
   "metadata": {},
   "source": [
    "### Don’t print secrets\n",
    "\n",
    "This is **unsafe**:\n",
    "- `print(os.environ[\"DSPY_LLM_API_KEY\"])`\n",
    "\n",
    "Instead, verify the secret is present (and optionally its length), without revealing the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fdf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPY_LLM_API_KEY: {\"present\": true, \"length\": 67}\n"
     ]
    }
   ],
   "source": [
    "app = modal.App.lookup(\"dspy-rlm-secret-check\", create_if_missing=True)\n",
    "\n",
    "sb = modal.Sandbox.create(\n",
    "    app=app,\n",
    "    secrets=[modal.Secret.from_name(\"LITELLM\")],\n",
    "    timeout=60,\n",
    ")\n",
    "try:\n",
    "    code = r\"\"\"\n",
    "import json, os\n",
    "key = os.environ.get('DSPY_LLM_API_KEY', '')\n",
    "print(json.dumps({'present': bool(key), 'length': len(key)}))\n",
    "\"\"\"\n",
    "    p = sb.exec(\"python\", \"-c\", code, timeout=60)\n",
    "    p.wait()\n",
    "    print(\"DSPY_LLM_API_KEY:\", p.stdout.read().strip())\n",
    "finally:\n",
    "    sb.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039c470",
   "metadata": {},
   "source": [
    "## 3. The Modal Sandbox Driver\n",
    "\n",
    "Modal Sandboxes are ephemeral containers. We use a **driver program** pattern (from [Modal's code interpreter example](https://modal.com/docs/examples/simple_code_interpreter)):\n",
    "\n",
    "1. A Python driver script runs inside the sandbox, reading JSON commands from `stdin`.\n",
    "2. For each command, it `exec()`s the code, captures stdout/stderr, and checks for `SUBMIT()` calls.\n",
    "3. It writes the result as JSON to `stdout`.\n",
    "\n",
    "This keeps state between iterations (variables persist in the `globals` dict) — exactly what RLM needs.\n",
    "\n",
    "The driver implementation is in the `fleet_rlm.driver` module, which we'll import and use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff761307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Set up Modal Image and App name\n",
      "  App name: dspy-rlm-modal (resolved lazily at sandbox start)\n",
      "  Image: debian_slim + numpy, pandas\n",
      "\n",
      "✓ Imported ModalInterpreter and sandbox_driver from package\n",
      "  ModalInterpreter: fleet_rlm.interpreter\n",
      "  sandbox_driver: fleet_rlm.driver\n"
     ]
    }
   ],
   "source": [
    "# Add src/ to path to import the real ModalInterpreter with volume support\n",
    "import sys\n",
    "src_path = PROJECT_ROOT / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import the real ModalInterpreter from the package\n",
    "from fleet_rlm.interpreter import ModalInterpreter  # noqa: E402\n",
    "from fleet_rlm.driver import sandbox_driver  # noqa: E402\n",
    "\n",
    "# Create the sandbox Image (DSPy is NOT needed inside — llm_query() is bridged to the host)\n",
    "import modal  # noqa: E402\n",
    "\n",
    "# NOTE: We no longer create a global MODAL_APP here.\n",
    "# modal.App.lookup() returns a transient handle whose _client expires between\n",
    "# Jupyter cells.  Instead, ModalInterpreter defers the lookup to start() time\n",
    "# via the `app_name` parameter, keeping the client fresh.\n",
    "SANDBOX_IMAGE = modal.Image.debian_slim().pip_install(\"numpy\", \"pandas\")\n",
    "\n",
    "MODAL_APP_NAME = \"dspy-rlm-modal\"\n",
    "\n",
    "print(\"✓ Set up Modal Image and App name\")\n",
    "print(f\"  App name: {MODAL_APP_NAME} (resolved lazily at sandbox start)\")\n",
    "print(\"  Image: debian_slim + numpy, pandas\")\n",
    "print()\n",
    "print(\"✓ Imported ModalInterpreter and sandbox_driver from package\")\n",
    "print(f\"  ModalInterpreter: {ModalInterpreter.__module__}\")\n",
    "print(f\"  sandbox_driver: {sandbox_driver.__module__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d3b08",
   "metadata": {},
   "source": [
    "## 4. Implement the `ModalInterpreter`\n",
    "\n",
    "This class implements DSPy's [`CodeInterpreter`](https://github.com/stanfordnlp/dspy/blob/main/dspy/primitives/code_interpreter.py) protocol. The protocol requires:\n",
    "\n",
    "| Method | Purpose |\n",
    "|---|---|\n",
    "| `tools` (property) | Dict of callable tools available in the sandbox |\n",
    "| `start()` | Initialize resources (idempotent) |\n",
    "| `execute(code, variables)` | Run code, return stdout or `FinalOutput` |\n",
    "| `shutdown()` | Release resources |\n",
    "\n",
    "Our implementation creates a `modal.Sandbox`, launches the driver program, and communicates via stdin/stdout JSON messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85af30f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModalInterpreter Configuration\n",
      "============================================================\n",
      "Image: Image(<function _Image.pip_install.<locals>.build_dockerfile at 0x1132fec00>)\n",
      "App name: dspy-rlm-modal\n",
      "Features:\n",
      "  • Deferred App.lookup() — avoids stale _client across cells\n",
      "  • Modal sandbox lifecycle management (idempotent start)\n",
      "  • JSON protocol communication with driver\n",
      "  • Custom tools support\n",
      "  • Volume support (Volumes V2)\n",
      "  • upload_to_volume() — batch upload local dirs/files\n",
      "  • Timeout & idle_timeout configuration\n",
      "  • Sensitive text redaction\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# The ModalInterpreter class has been imported from the package above.\n",
    "# It implements DSPy's CodeInterpreter protocol with these key features:\n",
    "\n",
    "print(\"ModalInterpreter Configuration\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Image: {SANDBOX_IMAGE}\")\n",
    "print(f\"App name: {MODAL_APP_NAME}\")\n",
    "print(\"Features:\")\n",
    "print(\"  • Deferred App.lookup() — avoids stale _client across cells\")\n",
    "print(\"  • Modal sandbox lifecycle management (idempotent start)\")\n",
    "print(\"  • JSON protocol communication with driver\")\n",
    "print(\"  • Custom tools support\")\n",
    "print(\"  • Volume support (Volumes V2)\")\n",
    "print(\"  • upload_to_volume() — batch upload local dirs/files\")\n",
    "print(\"  • Timeout & idle_timeout configuration\")\n",
    "print(\"  • Sensitive text redaction\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Basic RLM Demo: Code Generation\n",
    "\n",
    "A simple example showing RLM writing Python code to solve a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "basic-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/07 23:36:04 INFO dspy.predict.rlm: RLM iteration 1/15\n",
      "Reasoning: The question asks for the first 12 Fibonacci numbers, separated by commas. I will write a simple Python script to calculate these numbers. By convention, the Fibonacci sequence starts with 0 and 1, or sometimes 1 and 1. I will provide the sequence starting from 0, 1, 1, 2... and confirm if 12 numbers are generated.\n",
      "Code:\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\n",
      "first_12 = fibonacci(12)\n",
      "result = \", \".join(map(str, first_12))\n",
      "print(result)\n",
      "```\n",
      "2026/02/07 23:36:07 INFO dspy.predict.rlm: RLM iteration 2/15\n",
      "Reasoning: The previous step successfully calculated the first 12 Fibonacci numbers starting from 0: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89. I will now submit this result as requested.\n",
      "Code:\n",
      "```python\n",
      "SUBMIT(\"0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89\")\n",
      "```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL ANSWER: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89\n"
     ]
    }
   ],
   "source": [
    "# Ensure the planner LM is configured\n",
    "if not PLANNER_READY and dspy.settings.lm is None:\n",
    "    raise RuntimeError(\"Planner LM not configured\")\n",
    "\n",
    "interpreter = ModalInterpreter(image=SANDBOX_IMAGE, app_name=MODAL_APP_NAME)\n",
    "\n",
    "rlm = dspy.RLM(\n",
    "    signature=\"question -> answer\",\n",
    "    interpreter=interpreter,\n",
    "    max_iterations=15,\n",
    "    max_llm_calls=30,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = rlm(question=\"What are the first 12 Fibonacci numbers? Return as comma-separated.\")\n",
    "    print(\"\\nFINAL ANSWER:\", result.answer)\n",
    "finally:\n",
    "    interpreter.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 6. Core Capability: Long Document Analysis\n",
    "\n",
    "RLM treats long documents as an external environment. The document lives in the sandbox,\n",
    "code navigates and extracts relevant sections, and only snippets are sent to llm_query().\n",
    "\n",
    "### Use Case: Extract DSPy Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "long-doc-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded DSPy docs: 81,397 chars from dspy-doc.txt\n"
     ]
    }
   ],
   "source": [
    "class ExtractArchitecture(dspy.Signature):\n",
    "    \"\"\"Extract architectural information from DSPy documentation.\"\"\"\n",
    "    \n",
    "    docs: str = dspy.InputField(desc=\"Full DSPy documentation text\")\n",
    "    query: str = dspy.InputField(desc=\"What to extract\")\n",
    "    modules: list = dspy.OutputField(desc=\"List of DSPy modules\")\n",
    "    optimizers: list = dspy.OutputField(desc=\"List of optimizers\")\n",
    "    design_principles: str = dspy.OutputField(desc=\"Key design principles\")\n",
    "\n",
    "\n",
    "docs_path = PROJECT_ROOT / \"rlm_content\" / \"dspy-knowledge\" / \"dspy-doc.txt\"\n",
    "with open(docs_path, \"r\") as f:\n",
    "    dspy_docs = f.read()\n",
    "\n",
    "print(f\"✓ Loaded DSPy docs: {len(dspy_docs):,} chars from {docs_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## 7. Parallel Processing with llm_query_batched()\n",
    "\n",
    "Process multiple chunks in parallel for dramatic speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "batched-queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/07 23:36:07 INFO dspy.predict.rlm: RLM iteration 1/20\n",
      "Reasoning: The goal is to extract API endpoints from the `docs` variable. The preview shows a directory structure of the DSPy documentation. API endpoints in this context likely refer to class/method definitions or REST endpoints, but given this is a Python library (DSPy), it's more likely to be documentation of programmatic APIs (classes, functions, etc.).\n",
      "\n",
      "I will start by exploring the contents of `docs` to understand the structure and how the endpoints are documented. Since the documentation is large (~81k characters), I'll print the first few thousand characters and check if there are explicit lists of endpoints or if they are scattered across markdown files.\n",
      "\n",
      "Plan:\n",
      "1. Print the beginning of `docs` to understand the format.\n",
      "2. Search for common API keywords (e.g., \"GET\", \"POST\", \"class\", \"def\", \"endpoint\").\n",
      "3. Determine if the documentation contains REST endpoints or programmatic API references.\n",
      "4. Use `llm_query` or `llm_query_batched` to extract the specific endpoints.\n",
      "Code:\n",
      "```python\n",
      "print(f\"Total length: {len(docs)}\")\n",
      "print(\"First 2000 characters:\")\n",
      "print(docs[:2000])\n",
      "\n",
      "# Look for patterns that might indicate where the actual content starts after the file list\n",
      "if \"docs/api\" in docs:\n",
      "    print(\"\\nFound api directory in docs. Searching for content...\")\n",
      "```\n",
      "2026/02/07 23:36:10 INFO dspy.predict.rlm: RLM iteration 2/20\n",
      "Reasoning: The `docs` variable starts with a large directory structure representing the documentation files of the `dspy` library. Given the context of a Python library, \"API endpoints\" typically refers to the public classes, functions, or modules documented. The directory structure itself reveals a significant list of API components under `docs/api/`. \n",
      "\n",
      "I need to see the actual content of the files to determine what constitutes an \"endpoint\" (e.g., specific URLs or just the class/function names). I'll search for where the file list ends and the content begins, and then I'll use `llm_query` to extract the relevant API endpoints from the content.\n",
      "\n",
      "Plan:\n",
      "1. Locate the transition from the file tree to the actual documentation content.\n",
      "2. Split the document into chunks if it's too large for a single query, focusing on the content part.\n",
      "3. Use a batch query to extract API endpoints (classes/methods/functions) from the content.\n",
      "\n",
      "Let's find where the content starts first.\n",
      "Code:\n",
      "```python\n",
      "# The directory structure seems to be quite long. Let's find where it ends.\n",
      "# Usually, there's a file content marker or just a shift in format.\n",
      "lines = docs.split('\\n')\n",
      "content_start_idx = 0\n",
      "for i, line in enumerate(lines):\n",
      "    if 'File: ' in line or '---' in line or (i > 100 and not any(c in line for c in ['│', '├──', '└──'])):\n",
      "        content_start_idx = i\n",
      "        break\n",
      "\n",
      "print(f\"Likely content start at line {content_start_idx}\")\n",
      "print(\"Sample content:\")\n",
      "print('\\n'.join(lines[content_start_idx:content_start_idx+20]))\n",
      "\n",
      "# Also check for mentions of \"HTTP\" or URLs to see if there are REST endpoints\n",
      "import re\n",
      "urls = re.findall(r'https?://[^\\s<>\"]+|/[a-zA-Z0-9/_-]+', docs[content_start_idx:])\n",
      "print(f\"\\nFound {len(urls)} potential paths/URLs in content.\")\n",
      "```\n",
      "2026/02/07 23:36:11 INFO dspy.predict.rlm: RLM iteration 3/20\n",
      "Reasoning: The documentation starts with a directory structure followed by the content of various files marked by `FILE: <path>`. Since the library is `dspy`, I am looking for the API endpoints. In the context of a library documentation, these are typically the public classes and methods. The file list showed many files under `docs/api/`, such as `Predict.md`, `ChainOfThought.md`, `BootstrapFewShot.md`, etc.\n",
      "\n",
      "I will scan the content for files located in the `docs/api/` directory and use the LLM to extract the specific API endpoints (classes and methods) defined in those files. I'll focus on sections of the document that contain the actual API definitions.\n",
      "\n",
      "Plan:\n",
      "1. Identify all file sections related to the API (starting with `FILE: docs/api/`).\n",
      "2. Extract the text of these sections.\n",
      "3. Use `llm_query_batched` to process these sections and extract the formal API endpoints.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Split the document by the FILE: markers\n",
      "file_sections = re.split(r'={48}\\nFILE: ', docs)\n",
      "\n",
      "api_sections = []\n",
      "for section in file_sections:\n",
      "    # We are interested in files under docs/api/\n",
      "    if section.startswith('docs/api/'):\n",
      "        api_sections.append(section)\n",
      "\n",
      "print(f\"Found {len(api_sections)} API-related file sections.\")\n",
      "\n",
      "# Take a look at one to see the structure\n",
      "if api_sections:\n",
      "    print(\"\\nExample API section (first 500 chars):\")\n",
      "    print(api_sections[0][:500])\n",
      "\n",
      "# Group sections to avoid too many small queries, but keep them within LLM limits\n",
      "# We'll batch them and ask the LLM to extract the class/function/method names.\n",
      "prompts = []\n",
      "current_batch = \"\"\n",
      "for section in api_sections:\n",
      "    if len(current_batch) + len(section) > 10000:\n",
      "        prompts.append(f\"Extract all API endpoints (class names, method names, or functions) documented in the following text. Return them as a JSON list of strings:\\n\\n{current_batch}\")\n",
      "        current_batch = section\n",
      "    else:\n",
      "        current_batch += \"\\n\" + section\n",
      "\n",
      "if current_batch:\n",
      "    prompts.append(f\"Extract all API endpoints (class names, method names, or functions) documented in the following text. Return them as a JSON list of strings:\\n\\n{current_batch}\")\n",
      "\n",
      "print(f\"Prepared {len(prompts)} prompts for batched analysis.\")\n",
      "```\n",
      "2026/02/07 23:36:12 INFO dspy.predict.rlm: RLM iteration 4/20\n",
      "Reasoning: The previous attempt to find API sections using `FILE: docs/api/` failed because the file path might not be formatted exactly that way or the directory structure in the documentation content differs from the initial tree view. I need to re-examine the file markers in the `docs` variable to identify how files are actually delimited and named. I'll search for the `FILE:` pattern more broadly and inspect the file names to correctly identify API-related documentation.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Let's see how the files are actually named and where the API documentation starts.\n",
      "# I'll look for any \"FILE: \" occurrence and print the first 10 matches.\n",
      "file_markers = re.findall(r'FILE: .+', docs)\n",
      "print(f\"Total file markers found: {len(file_markers)}\")\n",
      "print(\"First 20 file markers:\")\n",
      "for marker in file_markers[:20]:\n",
      "    print(marker)\n",
      "\n",
      "# Based on the initial tree, API files are likely under stanfordnlp-dspy/docs/docs/api/\n",
      "# Let's try searching for that pattern.\n",
      "api_markers = [m for m in file_markers if 'api/' in m]\n",
      "print(f\"\\nFound {len(api_markers)} markers containing 'api/'.\")\n",
      "for marker in api_markers[:10]:\n",
      "    print(marker)\n",
      "\n",
      "# If the markers exist, I will extract the content between them.\n",
      "# The content seems to be separated by \"================================================\"\n",
      "# followed by \"FILE: <path>\"\n",
      "```\n",
      "2026/02/07 23:36:14 INFO dspy.predict.rlm: RLM iteration 5/20\n",
      "Reasoning: The file markers in the document use the format `FILE: docs/docs/api/...`. I have identified 61 such markers. These files likely contain the definitions for the DSPy API (classes, methods, and functions). I will now extract the content of these specific sections and use `llm_query_batched` to parse the API endpoints from them. I'll group the sections into appropriately sized prompts to ensure efficient processing while staying within the LLM's context limit.\n",
      "\n",
      "Plan:\n",
      "1. Split the `docs` string into individual file contents based on the `================================================\\nFILE: ` delimiter.\n",
      "2. Filter for sections where the filename starts with `docs/docs/api/`.\n",
      "3. Use `llm_query_batched` to extract the formal API endpoints (class names, methods, and functions) from these sections.\n",
      "4. Consolidate the results into a final list.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "import json\n",
      "\n",
      "# Split by the header pattern\n",
      "parts = re.split(r'={48}\\nFILE: ', docs)\n",
      "\n",
      "api_docs_content = []\n",
      "for part in parts:\n",
      "    # Check if this part corresponds to an API file\n",
      "    if part.startswith('docs/docs/api/'):\n",
      "        api_docs_content.append(part)\n",
      "\n",
      "print(f\"Number of API sections to process: {len(api_docs_content)}\")\n",
      "\n",
      "# Group content into chunks for the LLM\n",
      "prompts = []\n",
      "current_chunk = \"\"\n",
      "for content in api_docs_content:\n",
      "    if len(current_chunk) + len(content) > 15000:\n",
      "        prompts.append(f\"Extract a list of all API endpoints (class names, functions, or methods) documented in the text below. Focus on the formal definitions provided in the documentation. Return only a JSON list of strings.\\n\\nText:\\n{current_chunk}\")\n",
      "        current_chunk = content\n",
      "    else:\n",
      "        current_chunk += \"\\n\\n\" + content\n",
      "\n",
      "if current_chunk:\n",
      "    prompts.append(f\"Extract a list of all API endpoints (class names, functions, or methods) documented in the text below. Focus on the formal definitions provided in the documentation. Return only a JSON list of strings.\\n\\nText:\\n{current_chunk}\")\n",
      "\n",
      "# Execute batched query\n",
      "results = llm_query_batched(prompts)\n",
      "\n",
      "all_endpoints = set()\n",
      "for res in results:\n",
      "    try:\n",
      "        # Clean the response if it contains markdown code blocks\n",
      "        clean_res = res.strip()\n",
      "        if \"```json\" in clean_res:\n",
      "            clean_res = clean_res.split(\"```json\")[1].split(\"```\")[0].strip()\n",
      "        elif \"```\" in clean_res:\n",
      "            clean_res = clean_res.split(\"```\")[1].split(\"```\")[0].strip()\n",
      "        \n",
      "        endpoints = json.loads(clean_res)\n",
      "        if isinstance(endpoints, list):\n",
      "            all_endpoints.update(endpoints)\n",
      "    except Exception as e:\n",
      "        print(f\"Error parsing response: {e}\")\n",
      "        print(f\"Response starts with: {res[:100]}\")\n",
      "\n",
      "final_list = sorted(list(all_endpoints))\n",
      "print(f\"Extracted {len(final_list)} unique API endpoints.\")\n",
      "print(\"Sample endpoints:\")\n",
      "print(final_list[:10])\n",
      "\n",
      "SUBMIT(final_list)\n",
      "```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 endpoints\n",
      "  - __call__\n",
      "  - acall\n",
      "  - adapt_to_native_lm_feature\n",
      "  - aforward\n",
      "  - append\n"
     ]
    }
   ],
   "source": [
    "class ExtractAPIEndpoints(dspy.Signature):\n",
    "    \"\"\"Extract API endpoints using batched analysis.\"\"\"\n",
    "    \n",
    "    docs: str = dspy.InputField(desc=\"API documentation\")\n",
    "    api_endpoints: list = dspy.OutputField(desc=\"List of API endpoints\")\n",
    "\n",
    "\n",
    "interpreter = ModalInterpreter(image=SANDBOX_IMAGE, app_name=MODAL_APP_NAME)\n",
    "\n",
    "rlm = dspy.RLM(\n",
    "    signature=ExtractAPIEndpoints,\n",
    "    interpreter=interpreter,\n",
    "    max_iterations=20,\n",
    "    max_llm_calls=30,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = rlm(docs=dspy_docs)\n",
    "    print(f\"Found {len(result.api_endpoints)} endpoints\")\n",
    "    for ep in result.api_endpoints[:5]:\n",
    "        print(f\"  - {ep}\")\n",
    "finally:\n",
    "    interpreter.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8",
   "metadata": {},
   "source": [
    "## 8. Stateful Multi-Step Reasoning\n",
    "\n",
    "RLM maintains state across iterations. Variables persist, enabling multi-step workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "multi-step-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/07 23:36:15 INFO dspy.predict.rlm: RLM iteration 1/30\n",
      "Reasoning: The documentation provided is for the `dspy` library. To find and categorize error patterns, I first need to understand the structure of the `docs` variable and what it contains. It seems to be a collection of directory structures and likely file contents. I will start by printing a larger sample of `docs` and checking if there are specific sections or files that mention common errors, troubleshooting, or bugs. I'll also look for keywords like \"Error\", \"Exception\", \"Fail\", \"Issue\", \"Fix\", \"Troubleshoot\", and \"Warning\".\n",
      "\n",
      "Plan:\n",
      "1. Explore the structure of `docs`.\n",
      "2. Extract sections or lines containing error-related keywords.\n",
      "3. Use `llm_query` to categorize these errors if the data is dense or complex.\n",
      "Code:\n",
      "```python\n",
      "# Initial exploration of the docs content\n",
      "print(f\"Total length of docs: {len(docs)}\")\n",
      "print(\"First 2000 characters of docs:\")\n",
      "print(docs[:2000])\n",
      "\n",
      "# Look for specific keywords related to errors\n",
      "keywords = [\"error\", \"exception\", \"fail\", \"issue\", \"troubleshoot\", \"warning\", \"fix\", \"bug\"]\n",
      "import re\n",
      "\n",
      "found_keywords = {}\n",
      "for kw in keywords:\n",
      "    matches = re.findall(kw, docs, re.IGNORECASE)\n",
      "    found_keywords[kw] = len(matches)\n",
      "\n",
      "print(\"\\nKeyword frequency:\")\n",
      "print(found_keywords)\n",
      "\n",
      "# Let's try to find some snippets containing 'error' or 'exception' to see context\n",
      "snippets = []\n",
      "for match in re.finditer(r\".{0,50}(error|exception|fail|issue|warning).{0,50}\", docs, re.IGNORECASE):\n",
      "    snippets.append(match.group(0))\n",
      "    if len(snippets) >= 10:\n",
      "        break\n",
      "\n",
      "print(\"\\nSample snippets containing keywords:\")\n",
      "for s in snippets:\n",
      "    print(f\"- {s}\")\n",
      "```\n",
      "2026/02/07 23:36:19 INFO dspy.predict.rlm: RLM iteration 2/30\n",
      "Reasoning: The keyword search revealed some potential leads (e.g., `CodeInterpreterError`, `ValueError`, and issue templates), but the overall counts for keywords like \"error\" are quite low (8 hits) given the 81k character length. This suggests that errors might be documented more implicitly or within specific function definitions as exceptions.\n",
      "\n",
      "I need to see the actual content of the documentation files rather than just the directory tree. I will split the `docs` string by file headers (if present) to understand the content of the API documentation and source code snippets provided. I'll search for typical error-handling patterns like `raise`, `try/except`, and specific error messages in the docstrings.\n",
      "\n",
      "Plan:\n",
      "1. Identify how files are separated in `docs` (it looks like `FILE: <path>` or similar headers might be used).\n",
      "2. Extract the content of relevant sections like `api/`, `modules/`, and `optimizers/`.\n",
      "3. Search for error-related patterns in the content.\n",
      "4. Use `llm_query` to help categorize and identify patterns from the extracted relevant text.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Let's see how the files are delineated. \n",
      "# Looking at the previous output, I saw \"FILE: .github/ISSUE_TEMPLATE/bug_report.yml\"\n",
      "# I'll check for this pattern.\n",
      "\n",
      "files = re.split(r'FILE: ', docs)\n",
      "print(f\"Number of 'files' found: {len(files)}\")\n",
      "\n",
      "# Print the first few characters of a few files to verify\n",
      "for i, f in enumerate(files[:5]):\n",
      "    print(f\"\\n--- File {i} (First 100 chars) ---\")\n",
      "    print(f[:100])\n",
      "\n",
      "# I'll search for common error/exception raising patterns and docstrings\n",
      "error_patterns = [\n",
      "    r\"raise \\w+\",\n",
      "    r\"Exception\",\n",
      "    r\"Error\",\n",
      "    r\"fail\",\n",
      "    r\"invalid\",\n",
      "    r\"assertion\"\n",
      "]\n",
      "\n",
      "all_matches = []\n",
      "for file_content in files:\n",
      "    lines = file_content.split('\\n')\n",
      "    filename = lines[0] if lines else \"Unknown\"\n",
      "    for line_no, line in enumerate(lines):\n",
      "        if any(re.search(p, line, re.IGNORECASE) for p in error_patterns):\n",
      "            all_matches.append(f\"[{filename} line {line_no}]: {line.strip()}\")\n",
      "\n",
      "print(f\"\\nFound {len(all_matches)} lines with error-related patterns.\")\n",
      "print(\"Sample matches:\")\n",
      "for m in all_matches[:20]:\n",
      "    print(m)\n",
      "\n",
      "# Since the number of errors might be small, I'll ask the LLM to identify the categories\n",
      "# from the matches found across the document.\n",
      "context_for_llm = \"\\n\".join(all_matches)\n",
      "```\n",
      "2026/02/07 23:36:21 INFO dspy.predict.rlm: RLM iteration 3/30\n",
      "Reasoning: The keyword search yielded a relatively small number of direct matches (12), but they point toward specific areas:\n",
      "1.  **Code Execution Errors**: `CodeInterpreterError` suggests issues related to running code via DSPy primitives.\n",
      "2.  **Signature/Schema Errors**: `ValueError` related to field types indicates potential issues when defining DSPy Signatures.\n",
      "3.  **Assertion Failures**: The \"assertions\" in the test JSON files suggest that validation of outputs (specifically boolean success/failure) is a pattern.\n",
      "4.  **Implementation/Interface Errors**: `NotImplementedError` in teleprompters.\n",
      "5.  **External/Tool Errors**: `ValueError(\"error!\")` in a mock server test.\n",
      "\n",
      "However, 12 matches out of 81k characters suggest I might be missing errors described in natural language (docstrings, guides) rather than just code. I will now look for common DSPy-specific failure modes like \"hallucination\", \"refusal\", \"formatting\", \"token limits\", or \"connection\" issues that might not be explicitly labeled as \"Error\" in the code but are \"error patterns\" in the context of LLM applications. I'll also perform a broader search for \"invalid\", \"missing\", \"incorrect\", and \"failed\".\n",
      "\n",
      "Plan:\n",
      "1. Scan for semantic error patterns using `llm_query` on chunks of the documentation that likely contain logic (e.g., adapters, modules, optimizers).\n",
      "2. Look for \"failure\" cases in the `evaluation` and `tests` sections.\n",
      "3. Consolidate these into categories.\n",
      "Code:\n",
      "```python\n",
      "# Focus on areas where error logic or failure modes are likely described\n",
      "relevant_files = []\n",
      "target_paths = [\"adapters\", \"evaluation\", \"modules\", \"optimizers\", \"signatures\"]\n",
      "\n",
      "for file_content in files:\n",
      "    header = file_content.split('\\n')[0]\n",
      "    if any(path in header for path in target_paths):\n",
      "        relevant_files.append(file_content)\n",
      "\n",
      "# Use llm_query to find and categorize error patterns in these relevant sections\n",
      "context = \"\\n\\n\".join(relevant_files)[:15000] # Stay within prompt limits\n",
      "prompt = f\"\"\"\n",
      "Analyze the following DSPy documentation snippets and identify common error patterns or failure modes. \n",
      "Categorize them (e.g., Validation Errors, Configuration Errors, Execution Failures) and count how many distinct types you find.\n",
      "\n",
      "Snippets:\n",
      "{context}\n",
      "\"\"\"\n",
      "\n",
      "print(\"Querying LLM for semantic error patterns...\")\n",
      "analysis = llm_query(prompt)\n",
      "print(analysis)\n",
      "\n",
      "# Also check for 'assertion' context in tests to see what is being validated\n",
      "assertion_snippets = re.findall(r\".{0,100}assertion.{0,100}\", docs, re.IGNORECASE)\n",
      "print(\"\\nAssertion contexts:\")\n",
      "for s in assertion_snippets[:5]:\n",
      "    print(f\"- {s}\")\n",
      "```\n",
      "2026/02/07 23:36:22 INFO dspy.predict.rlm: RLM iteration 4/30\n",
      "Reasoning: The previous analysis successfully identified 7 distinct error types across 3 categories (Validation, Configuration, and Execution) by analyzing the module and adapter documentation. However, the initial search for keyword \"error\" in Step 2 only found 12 specific instances, and the LLM analysis was based on a subset of the documentation. To ensure a comprehensive count and categorization, I need to:\n",
      "1. Examine the `evaluation` and `optimizer` sections more closely, as these often contain logic for handling failures (e.g., \"BootstrapFewShot\" failing to find examples).\n",
      "2. Look at the `tests` directory content in the `docs` variable more thoroughly to find what specific \"assertions\" are checking for, as these represent expected error patterns or quality failures.\n",
      "3. Check the `CodeInterpreterError` found earlier to see if there are other specific custom exceptions defined in the library.\n",
      "4. I will perform a broader scan of the `docs` to find any other unique error messages or \"raise\" statements I might have missed by looking at a larger sample of the matches.\n",
      "\n",
      "Plan:\n",
      "- Extract all \"raise\" and \"Error\" occurrences from the entire `docs` string to find unique exception types.\n",
      "- Query the LLM specifically on the `optimizers` and `evaluation` docs to find performance-related \"failure modes\" (e.g., optimization failing to converge or find valid examples).\n",
      "- Synthesize all findings into the final categories.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Extract all 'raise' statements and Exception classes\n",
      "all_raises = re.findall(r\"raise\\s+(\\w+)(?:\\((.*)\\))?\", docs)\n",
      "unique_exceptions = set([r[0] for r in all_raises])\n",
      "\n",
      "# Extract specific error messages\n",
      "error_messages = re.findall(r\"['\\\"]([^'\\\"]*(?:Error|Fail|Invalid|Required|Missing)[^'\\\"]*)['\\\"]\", docs, re.IGNORECASE)\n",
      "\n",
      "print(f\"Unique Exceptions raised in code: {unique_exceptions}\")\n",
      "print(f\"Sample error-related strings: {error_messages[:15]}\")\n",
      "\n",
      "# Look at evaluation/optimizers content for \"failure\" patterns\n",
      "opt_eval_files = [f for f in files if \"optimizer\" in f.lower() or \"evaluation\" in f.lower()]\n",
      "opt_eval_context = \"\\n\\n\".join(opt_eval_files)\n",
      "\n",
      "prompt_2 = f\"\"\"\n",
      "Identify error patterns, failure modes, or validation checks specifically in the DSPy Optimizers and Evaluation metrics. \n",
      "Look for things like:\n",
      "- Why an optimizer might fail to improve a program.\n",
      "- Common reasons for evaluation metrics to return 0 or fail.\n",
      "- Requirements for data or models that, if not met, cause errors.\n",
      "\n",
      "Context:\n",
      "{opt_eval_context[:10000]}\n",
      "\"\"\"\n",
      "\n",
      "print(\"\\nQuerying LLM for Optimizer/Evaluation error patterns...\")\n",
      "analysis_2 = llm_query(prompt_2)\n",
      "print(analysis_2)\n",
      "```\n",
      "2026/02/07 23:36:24 INFO dspy.predict.rlm: RLM iteration 5/30\n",
      "Reasoning: The analysis has identified several distinct error categories and failure modes. From the manual code scan and the LLM semantic analysis, I have found:\n",
      "1.  **Validation Errors**: Parsing mismatches (JSON/Chat), missing signature fields, and invalid task descriptions.\n",
      "2.  **Configuration Errors**: State serialization mismatches (load/save), missing LM context (essential for metrics/modules), and parameter desynchronization.\n",
      "3.  **Execution Failures**: Synchronicity mismatches (sync vs. async calls), and state leakage during optimization (deepcopy issues).\n",
      "4.  **Optimization/Learning Failures**: Bootstrapping \"deadlocks\" (teacher model failing to generate any valid traces), metric non-differentiability (lack of signal), and overfitting/contamination.\n",
      "5.  **Runtime/Environment Errors**: `CodeInterpreterError` for sandboxed execution and connection/retrial failures in setup scripts.\n",
      "\n",
      "The count of unique \"error patterns\" or \"failure modes\" identified so far is roughly 10-12 across these categories. I will do one final sweep of the `tests` and `primitives` content to see if there are any specific logic-related errors mentioned (e.g., token limits or refusal handling) to finalize the list.\n",
      "Code:\n",
      "```python\n",
      "# Final sweep for specific error strings in primitives and tests\n",
      "final_targets = [\"primitives\", \"tests\"]\n",
      "final_context = []\n",
      "for file_content in files:\n",
      "    header = file_content.split('\\n')[0]\n",
      "    if any(target in header for target in final_targets):\n",
      "        final_context.append(file_content)\n",
      "\n",
      "prompt_final = f\"\"\"\n",
      "Based on the following code and test snippets, list any additional specific error patterns or failure modes not previously covered (like token limits, empty outputs, or specific tool failures).\n",
      "Then, provide a final consolidated categorization of all error patterns found in the entire DSPy documentation provided.\n",
      "\n",
      "Context:\n",
      "{\"\\n\\n\".join(final_context)[:15000]}\n",
      "\"\"\"\n",
      "\n",
      "print(\"Final sweep for specific error patterns...\")\n",
      "final_analysis = llm_query(prompt_final)\n",
      "print(final_analysis)\n",
      "```\n",
      "2026/02/07 23:36:26 INFO dspy.predict.rlm: RLM iteration 6/30\n",
      "Reasoning: I have completed a comprehensive review of the DSPy documentation, including the directory structure, API documentation, and reliability tests. Through keyword searches, manual code inspection, and semantic analysis using the LLM across multiple specialized sections (Adapters, Modules, Optimizers, and Primitives), I have identified and categorized the core error patterns. \n",
      "\n",
      "The errors fall into five major categories:\n",
      "1. **Input & Serialization Failures**: Issues with media loading, MIME normalization, and type mapping.\n",
      "2. **Model Output & Parsing Failures**: Schema violations, structural drift in nested types, and token-limit truncation.\n",
      "3. **Execution & Logic Failures**: Runtime errors in the CodeInterpreter and tool call mismatches.\n",
      "4. **Evaluation & Reliability Failures**: Metric mismatches (Exact Match failures) and assertion violations in complex formats like Markdown.\n",
      "5. **Configuration & Meta-Programming Failures**: State serialization conflicts (Load/Save), missing LM contexts, and teleprompter compilation issues.\n",
      "\n",
      "I have identified approximately 18 distinct error types across these 5 categories. I am now ready to submit the final results.\n",
      "Code:\n",
      "```python\n",
      "error_categories = {\n",
      "    \"Input & Serialization Failures\": [\n",
      "        \"Audio/Image Protocol Errors (loading from URLs or local files)\",\n",
      "        \"MIME/Format Normalization Failures (e.g., wav vs x-wav mismatch)\",\n",
      "        \"Custom Type Mapping Errors (failure to extract schema from Python annotations)\"\n",
      "    ],\n",
      "    \"Model Output & Parsing Failures\": [\n",
      "        \"Schema Non-Compliance (missing required fields in LM response)\",\n",
      "        \"Structural Drift in Deep Nesting (losing track of keys in levels 3+)\",\n",
      "        \"JSON/Markdown Parsing Errors (malformed structure or heading hierarchy failure)\",\n",
      "        \"Token Limit/Truncation (incomplete JSON or code blocks)\",\n",
      "        \"Empty or Null Responses during streaming/parsing\"\n",
      "    ],\n",
      "    \"Execution & Logic Failures\": [\n",
      "        \"CodeInterpreterError (runtime errors in generated Python code)\",\n",
      "        \"Tool Call Schema Mismatches (invalid litellm function call formatting)\",\n",
      "        \"Synchronicity Mismatches (blocking calls in async loops or unawaited coroutines)\",\n",
      "        \"Context/History Bloat (exceeding window limits causing instruction loss)\"\n",
      "    ],\n",
      "    \"Evaluation & Reliability Failures\": [\n",
      "        \"Exact Match (EM) Misses (semantic equivalence vs. literal discrepancy)\",\n",
      "        \"Assertion Violations (failures in programmatic constraints defined in dspy.Assert)\",\n",
      "        \"Input Format Hallucination (including unintended content in structured output like TOCs)\"\n",
      "    ],\n",
      "    \"Configuration & Meta-Programming Failures\": [\n",
      "        \"State Serialization Conflict (mismatched signatures during load/save)\",\n",
      "        \"Unconfigured LM Context (executing metrics/modules without set_lm)\",\n",
      "        \"Teleprompter Compilation Failures (mapping student parameters to teacher outputs)\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "total_errors_found = 18\n",
      "\n",
      "SUBMIT(error_categories, total_errors_found)\n",
      "```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 error patterns\n",
      "Input & Serialization Failures: 3 errors\n",
      "Model Output & Parsing Failures: 5 errors\n",
      "Execution & Logic Failures: 4 errors\n",
      "Evaluation & Reliability Failures: 3 errors\n",
      "Configuration & Meta-Programming Failures: 3 errors\n"
     ]
    }
   ],
   "source": [
    "class FindErrorPatterns(dspy.Signature):\n",
    "    \"\"\"Find and categorize error patterns.\"\"\"\n",
    "    \n",
    "    docs: str = dspy.InputField(desc=\"Documentation text\")\n",
    "    error_categories: dict = dspy.OutputField(desc=\"Error types mapped to solutions\")\n",
    "    total_errors_found: int = dspy.OutputField(desc=\"Total errors identified\")\n",
    "\n",
    "\n",
    "def get_errors(docs: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"Find and categorize error patterns in documentation using RLM.\n",
    "    \n",
    "    Args:\n",
    "        docs: The documentation text to analyze\n",
    "        verbose: Whether to print RLM traces\n",
    "        \n",
    "    Returns:\n",
    "        Dict with 'total' count and 'categories' dict\n",
    "    \"\"\"\n",
    "    interpreter = ModalInterpreter(image=SANDBOX_IMAGE, app_name=MODAL_APP_NAME)\n",
    "\n",
    "    rlm = dspy.RLM(\n",
    "        signature=FindErrorPatterns,\n",
    "        interpreter=interpreter,\n",
    "        max_iterations=30,\n",
    "        max_llm_calls=40,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = rlm(docs=docs)\n",
    "        return {\n",
    "            \"total\": result.total_errors_found,\n",
    "            \"categories\": result.error_categories\n",
    "        }\n",
    "    finally:\n",
    "        interpreter.shutdown()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "error_data = get_errors(dspy_docs)\n",
    "\n",
    "print(f\"Found {error_data['total']} error patterns\")\n",
    "for cat, errors in error_data['categories'].items():\n",
    "    print(f\"{cat}: {len(errors)} errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section9",
   "metadata": {},
   "source": [
    "## 9. Inspecting the Trajectory\n",
    "\n",
    "Every RLM result includes a trajectory - complete history of reasoning, code, and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trajectory-inspection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory (3 steps):\n",
      "\n",
      "\n",
      "Step 1:\n",
      "  Reasoning: I need to summarize the content provided in the `text` variable, which appears to be a directory str...\n",
      "  Code: print(f\"Total length: {len(text)}\")\n",
      "print(\"--- Full Text Sta...\n",
      "\n",
      "Step 2:\n",
      "  Reasoning: The text provides a detailed directory structure of the `stanfordnlp-dspy` repository, specifically ...\n",
      "  Code: prompt = f\"\"\"Summarize the purpose and structure of the proj...\n",
      "\n",
      "Step 3:\n",
      "  Reasoning: The previous step successfully generated a comprehensive and well-structured summary of the `stanfor...\n",
      "  Code: # The summary was already generated in the previous step.\n",
      "# ...\n"
     ]
    }
   ],
   "source": [
    "interpreter = ModalInterpreter(image=SANDBOX_IMAGE, app_name=MODAL_APP_NAME)\n",
    "\n",
    "rlm = dspy.RLM(\n",
    "    signature=\"text -> summary\",\n",
    "    interpreter=interpreter,\n",
    "    max_iterations=10,\n",
    "    max_llm_calls=10,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "try:\n",
    "    text_sample = dspy_docs[:3000]\n",
    "    result = rlm(text=text_sample)\n",
    "    \n",
    "    print(f\"Trajectory ({len(result.trajectory)} steps):\\n\")\n",
    "    for i, step in enumerate(result.trajectory):\n",
    "        print(f\"\\nStep {i+1}:\")\n",
    "        print(f\"  Reasoning: {step.get('reasoning', 'N/A')[:100]}...\")\n",
    "        print(f\"  Code: {step.get('code', '')[:60]}...\")\n",
    "finally:\n",
    "    interpreter.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074af4c",
   "metadata": {},
   "source": [
    "## 10. Persistent Storage with Modal Volumes V2\n",
    "\n",
    "Modal Volumes V2 provide persistent storage across sandbox sessions with better performance and consistency. This is useful for:\n",
    "- Caching large documents to avoid re-uploading\n",
    "- Storing intermediate results\n",
    "- Sharing data between multiple RLM runs\n",
    "- **Hosting knowledge files** (RLM paper, DSPy docs) directly in the sandbox filesystem\n",
    "\n",
    "### Volume Setup\n",
    "First, create a V2 volume (one-time setup):\n",
    "```bash\n",
    "modal volume create --version=2 rlm-volume-dspy\n",
    "```\n",
    "\n",
    "### Volumes V2 Key Features\n",
    "- Uses `modal.Volume.from_name(name, create_if_missing=True, version=2)`\n",
    "- Mounts via `volumes={\"/data\": volume}` in `Sandbox.create()`\n",
    "- **No file count limit** (V1 had 500K inode limit)\n",
    "- **Concurrent writes** from hundreds of containers\n",
    "- Commit via `sync /data` from inside the sandbox (V2 only)\n",
    "- Background commits persist data automatically on container shutdown\n",
    "\n",
    "### Uploading Files from Local Machine\n",
    "```python\n",
    "vol = modal.Volume.from_name(\"my-volume\", create_if_missing=True, version=2)\n",
    "with vol.batch_upload() as batch:\n",
    "    batch.put_directory(\"/local/dir\", \"/remote/dir\")\n",
    "    batch.put_file(\"local.txt\", \"/remote/file.txt\")\n",
    "```\n",
    "\n",
    "Or via `ModalInterpreter.upload_to_volume()`:\n",
    "```python\n",
    "interpreter.upload_to_volume(\n",
    "    local_dirs={\"rlm_content/dspy-knowledge\": \"/dspy-knowledge\"},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d383c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume: '/rlm-knowledge' exists, skipping upload.\n",
      "Volume: '/dspy-knowledge' exists, skipping upload.\n",
      "✓ Uploaded knowledge directories to volume 'rlm-volume-dspy':\n",
      "  /Volumes/Samsung-SSD-T7/Workspaces/Github/qredence/agent-framework/v0.5/_WORLD/_RLM/fleet-rlm-dspy/rlm_content/rlm-knowledge → /data/rlm-knowledge/\n",
      "  /Volumes/Samsung-SSD-T7/Workspaces/Github/qredence/agent-framework/v0.5/_WORLD/_RLM/fleet-rlm-dspy/rlm_content/dspy-knowledge → /data/dspy-knowledge/\n",
      "\n",
      "Volume contents:\n",
      "  /dspy-knowledge\n",
      "    /dspy-knowledge/dspy-knowledge/dspy-RLM.md\n",
      "    /dspy-knowledge/dspy-knowledge/dspy-doc.txt\n",
      "    /dspy-knowledge/dspy-knowledge/mermaid.md\n",
      "  /rlm-knowledge\n",
      "    /rlm-knowledge/rlm-knowledge/rlm-pape.pdf\n",
      "    /rlm-knowledge/rlm-knowledge/rlm-paper.md\n",
      "  /notebook-demo.json\n",
      "  /dspy-doc-cached.txt\n"
     ]
    }
   ],
   "source": [
    "# Upload rlm-knowledge/ and dspy-knowledge/ to the Modal Volume\n",
    "# This makes files available at /data/rlm-knowledge/ and /data/dspy-knowledge/\n",
    "# inside every sandbox that mounts the volume.\n",
    "\n",
    "VOLUME_NAME = \"rlm-volume-dspy\"\n",
    "\n",
    "rlm_knowledge_dir = str(PROJECT_ROOT / \"rlm_content\" / \"rlm-knowledge\")\n",
    "dspy_knowledge_dir = str(PROJECT_ROOT / \"rlm_content\" / \"dspy-knowledge\")\n",
    "\n",
    "# Verify local directories exist\n",
    "for d in [rlm_knowledge_dir, dspy_knowledge_dir]:\n",
    "    assert os.path.isdir(d), f\"Directory not found: {d}\"\n",
    "\n",
    "# Use ModalInterpreter's upload helper\n",
    "upload_interpreter = ModalInterpreter(\n",
    "    image=SANDBOX_IMAGE,\n",
    "    app_name=MODAL_APP_NAME,\n",
    "    volume_name=VOLUME_NAME,\n",
    ")\n",
    "\n",
    "upload_interpreter.upload_to_volume(\n",
    "    local_dirs={\n",
    "        rlm_knowledge_dir: \"/rlm-knowledge\",\n",
    "        dspy_knowledge_dir: \"/dspy-knowledge\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"✓ Uploaded knowledge directories to volume '{VOLUME_NAME}':\")\n",
    "print(f\"  {rlm_knowledge_dir} → /data/rlm-knowledge/\")\n",
    "print(f\"  {dspy_knowledge_dir} → /data/dspy-knowledge/\")\n",
    "print()\n",
    "\n",
    "# List uploaded files for confirmation\n",
    "vol = modal.Volume.from_name(VOLUME_NAME, create_if_missing=True, version=2)\n",
    "print(\"Volume contents:\")\n",
    "for entry in vol.listdir(\"/\"):\n",
    "    print(f\"  /{entry.path}\")\n",
    "    if entry.type.name == \"DIRECTORY\":\n",
    "        for sub in vol.listdir(f\"/{entry.path}\"):\n",
    "            size_str = f\" ({sub.stat().size:,} bytes)\" if hasattr(sub, 'stat') and sub.stat() else \"\"\n",
    "            print(f\"    /{entry.path}/{sub.path}{size_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12d4596d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created ModalInterpreter with Volumes V2 support\n",
      "  Volume: rlm-volume-dspy → mounted at /data/\n",
      "\n",
      "\n",
      "Sandbox result: FinalOutput({'result': 'volume knowledge files verified'})\n",
      "\n",
      "✓ Knowledge files accessible inside sandbox via volume mount.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate reading uploaded knowledge files from the volume inside a sandbox\n",
    "volume_interpreter = ModalInterpreter(\n",
    "    image=SANDBOX_IMAGE,\n",
    "    app_name=MODAL_APP_NAME,\n",
    "    volume_name=VOLUME_NAME,\n",
    "    timeout=600,\n",
    ")\n",
    "\n",
    "print(\"✓ Created ModalInterpreter with Volumes V2 support\")\n",
    "print(f\"  Volume: {VOLUME_NAME} → mounted at /data/\")\n",
    "print()\n",
    "\n",
    "# Start sandbox and verify knowledge files are accessible\n",
    "volume_interpreter.start()\n",
    "\n",
    "code = \"\"\"\n",
    "import pathlib, json\n",
    "\n",
    "data_dir = pathlib.Path(\"/data\")\n",
    "print(f\"Volume mounted: {data_dir.exists()}\")\n",
    "\n",
    "# List top-level contents\n",
    "top_level = sorted([p.name for p in data_dir.iterdir()])\n",
    "print(f\"Top-level dirs: {top_level}\")\n",
    "\n",
    "# List dspy-knowledge contents\n",
    "dspy_dir = data_dir / \"dspy-knowledge\"\n",
    "if dspy_dir.exists():\n",
    "    files = sorted(p.name for p in dspy_dir.iterdir())\n",
    "    print(f\"dspy-knowledge/: {files}\")\n",
    "    for f in dspy_dir.iterdir():\n",
    "        size = f.stat().st_size\n",
    "        print(f\"  {f.name}: {size:,} bytes\")\n",
    "\n",
    "# List rlm-knowledge contents\n",
    "rlm_dir = data_dir / \"rlm-knowledge\"\n",
    "if rlm_dir.exists():\n",
    "    files = sorted(p.name for p in rlm_dir.iterdir())\n",
    "    print(f\"rlm-knowledge/: {files}\")\n",
    "    for f in rlm_dir.iterdir():\n",
    "        size = f.stat().st_size\n",
    "        print(f\"  {f.name}: {size:,} bytes\")\n",
    "\n",
    "# Read a snippet of dspy-RLM.md to confirm content\n",
    "rlm_doc = data_dir / \"dspy-knowledge\" / \"dspy-RLM.md\"\n",
    "if rlm_doc.exists():\n",
    "    content = rlm_doc.read_text()\n",
    "    print(f\"\\\\ndspy-RLM.md preview ({len(content):,} chars):\")\n",
    "    print(content[:300])\n",
    "    print(\"...\")\n",
    "\n",
    "SUBMIT(result=\"volume knowledge files verified\")\n",
    "\"\"\"\n",
    "\n",
    "result = volume_interpreter.execute(code)\n",
    "print(f\"\\nSandbox result: {result}\")\n",
    "volume_interpreter.shutdown()\n",
    "print(\"\\n✓ Knowledge files accessible inside sandbox via volume mount.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d793f17",
   "metadata": {},
   "source": [
    "### RLM on Volume-Hosted Docs\n",
    "\n",
    "The key benefit of hosting knowledge files on a Volume: the RLM sandbox can read\n",
    "documents directly from `/data/` instead of serializing them through Python variables.\n",
    "This is the canonical RLM pattern — treat context as an **external environment**, not input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ab5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/07 23:36:34 INFO dspy.predict.rlm: RLM iteration 1/15\n",
      "Reasoning: I will start by reading the contents of the file `/data/dspy-knowledge/dspy-RLM.md` to understand the documentation structure and identify the relevant sections for constructor parameters, built-in tools, and key concepts.\n",
      "Code:\n",
      "```python\n",
      "import os\n",
      "\n",
      "file_path = \"/data/dspy-knowledge/dspy-RLM.md\"\n",
      "\n",
      "if os.path.exists(file_path):\n",
      "    with open(file_path, 'r') as f:\n",
      "        content = f.read()\n",
      "    print(f\"File length: {len(content)}\")\n",
      "    print(\"First 1000 characters:\")\n",
      "    print(content[:1000])\n",
      "else:\n",
      "    print(f\"File {file_path} not found.\")\n",
      "```\n",
      "2026/02/07 23:36:36 INFO dspy.predict.rlm: RLM iteration 2/15\n",
      "Reasoning: The file is roughly 8KB, which is small enough to read entirely into memory. I'll read the full content and then use `llm_query` to extract the specific lists of constructor parameters, built-in tools, and key concepts as requested. I'll structure the prompt to ensure I get structured data for the lists.\n",
      "Code:\n",
      "```python\n",
      "file_path = \"/data/dspy-knowledge/dspy-RLM.md\"\n",
      "with open(file_path, 'r') as f:\n",
      "    full_content = f.read()\n",
      "\n",
      "# Using a single comprehensive prompt to extract all required information\n",
      "prompt = f\"\"\"\n",
      "Based on the following documentation for dspy.RLM, extract the following:\n",
      "1. Constructor parameters (list of strings or dicts describing them)\n",
      "2. Built-in tools (list of tool names or descriptions available in the RLM environment)\n",
      "3. Key concepts (a summary or list of how RLM works)\n",
      "\n",
      "Documentation:\n",
      "{full_content}\n",
      "\n",
      "Format your response as a JSON object with keys: \"parameters\", \"builtin_tools\", \"key_concepts\".\n",
      "\"\"\"\n",
      "\n",
      "result = llm_query(prompt)\n",
      "print(result)\n",
      "```\n",
      "2026/02/07 23:36:36 INFO dspy.predict.rlm: RLM iteration 3/15\n",
      "Reasoning: I have successfully extracted the constructor parameters, built-in tools, and key concepts from the provided documentation using the `llm_query` function. The output from the previous step is already in a structured format. I will now parse this JSON and call the `SUBMIT` function with the extracted information.\n",
      "Code:\n",
      "```python\n",
      "import json\n",
      "\n",
      "# The output from the previous iteration's llm_query\n",
      "llm_output = \"\"\"\n",
      "{\n",
      "  \"parameters\": [\n",
      "    \"signature: Defines inputs and outputs (e.g., 'context, query -> answer')\",\n",
      "    \"max_iterations: Maximum REPL interaction loops before fallback extraction\",\n",
      "    \"max_llm_calls: Maximum llm_query/llm_query_batched calls per execution\",\n",
      "    \"max_output_chars: Maximum characters to include from REPL output\",\n",
      "    \"verbose: Log detailed execution info\",\n",
      "    \"tools: Additional tool functions callable from interpreter code\",\n",
      "    \"sub_lm: LM for sub-queries (defaults to dspy.settings.lm)\",\n",
      "    \"interpreter: Custom interpreter (defaults to PythonInterpreter via Deno/Pyodide WASM)\"\n",
      "  ],\n",
      "  \"builtin_tools\": [\n",
      "    \"llm_query(prompt): Query a sub-LLM for semantic analysis\",\n",
      "    \"llm_query_batched(prompts): Query multiple prompts concurrently\",\n",
      "    \"print(): Required to see results in the REPL output\",\n",
      "    \"SUBMIT(...): Submit final output and end execution\",\n",
      "    \"Standard library: re, json, collections, math, etc.\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Context Separation: Solves 'context rot' by separating the variable space (stored in the REPL) from the token space (processed by the LLM).\",\n",
      "    \"Iterative REPL Loop: The LLM receives metadata about a large context and writes Python code to explore, filter, or aggregate it programmatically.\",\n",
      "    \"Sandboxed Execution: Code runs in a secure Deno/Pyodide WASM environment, returning only the results of execution to the LLM.\",\n",
      "    \"Recursive Analysis: Allows the main LLM to delegate semantic analysis of context snippets to smaller, cheaper sub-LLM calls via llm_query.\",\n",
      "    \"Dynamic Decomposition: The LLM decides how to navigate and chunk the data itself rather than relying on predefined extraction logic.\"\n",
      "  ]\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "data = json.loads(llm_output)\n",
      "\n",
      "SUBMIT(\n",
      "    parameters=data[\"parameters\"],\n",
      "    builtin_tools=data[\"builtin_tools\"],\n",
      "    key_concepts=data[\"key_concepts\"]\n",
      ")\n",
      "```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters: [\"signature: Defines inputs and outputs (e.g., 'context, query -> answer')\", 'max_iterations: Maximum REPL interaction loops before fallback extraction', 'max_llm_calls: Maximum llm_query/llm_query_batched calls per execution', 'max_output_chars: Maximum characters to include from REPL output', 'verbose: Log detailed execution info', 'tools: Additional tool functions callable from interpreter code', 'sub_lm: LM for sub-queries (defaults to dspy.settings.lm)', 'interpreter: Custom interpreter (defaults to PythonInterpreter via Deno/Pyodide WASM)']\n",
      "Built-in tools: ['llm_query(prompt): Query a sub-LLM for semantic analysis', 'llm_query_batched(prompts): Query multiple prompts concurrently', 'print(): Required to see results in the REPL output', 'SUBMIT(...): Submit final output and end execution', 'Standard library: re, json, collections, math, etc.']\n",
      "Key concepts: [\"Context Separation: Solves 'context rot' by separating the variable space (stored in the REPL) from the token space (processed by the LLM).\", 'Iterative REPL Loop: The LLM receives metadata about a large context and writes Python code to explore, filter, or aggregate it programmatically.', 'Sandbo...\n"
     ]
    }
   ],
   "source": [
    "# RLM task that reads docs directly from the Volume filesystem\n",
    "# instead of passing them as a Python variable.\n",
    "# The sandbox reads /data/dspy-knowledge/dspy-RLM.md and extracts info.\n",
    "\n",
    "class ExtractRLMCapabilities(dspy.Signature):\n",
    "    \"\"\"Extract RLM capabilities from documentation stored on a Volume.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Read /data/dspy-knowledge/dspy-RLM.md from the volume\n",
    "    2. Search for constructor parameters, built-in tools, and usage patterns\n",
    "    3. Use llm_query() on relevant sections for semantic extraction\n",
    "    \"\"\"\n",
    "    \n",
    "    query: str = dspy.InputField(desc=\"What to extract from the RLM docs\")\n",
    "    parameters: list = dspy.OutputField(desc=\"List of RLM constructor parameters\")\n",
    "    builtin_tools: list = dspy.OutputField(desc=\"List of built-in sandbox tools\")\n",
    "    key_concepts: str = dspy.OutputField(desc=\"Summary of key RLM concepts\")\n",
    "\n",
    "\n",
    "vol_rlm_interpreter = ModalInterpreter(\n",
    "    image=SANDBOX_IMAGE,\n",
    "    app_name=MODAL_APP_NAME,\n",
    "    volume_name=VOLUME_NAME,\n",
    "    timeout=600,\n",
    ")\n",
    "\n",
    "rlm = dspy.RLM(\n",
    "    signature=ExtractRLMCapabilities,\n",
    "    interpreter=vol_rlm_interpreter,\n",
    "    max_iterations=15,\n",
    "    max_llm_calls=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # NOTE: We do NOT pass docs as input — the RLM reads them from /data/ in the sandbox!\n",
    "    result = rlm(\n",
    "        query=\"Read /data/dspy-knowledge/dspy-RLM.md and extract all constructor parameters, built-in tools, and key concepts about how RLM works.\"\n",
    "    )\n",
    "    print(f\"\\nParameters: {result.parameters}\")\n",
    "    print(f\"Built-in tools: {result.builtin_tools}\")\n",
    "    print(f\"Key concepts: {result.key_concepts[:300]}...\")\n",
    "finally:\n",
    "    vol_rlm_interpreter.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "596871a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLI Commands - Using the Package\n",
      "============================================================\n",
      "\n",
      "The fleet-rlm package provides a Typer CLI with the following commands:\n",
      "\n",
      "1. Basic Code Generation:\n",
      "   $ uv run fleet-rlm run-basic \\\n",
      "       --question \"What are the first 10 Fibonacci numbers?\" \\\n",
      "       --volume-name rlm-volume-dspy\n",
      "\n",
      "2. Architecture Extraction:\n",
      "   $ uv run fleet-rlm run-architecture \\\n",
      "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\n",
      "       --query \"Extract all modules and optimizers\" \\\n",
      "       --volume-name rlm-volume-dspy\n",
      "\n",
      "3. API Endpoint Extraction:\n",
      "   $ uv run fleet-rlm run-api-endpoints \\\n",
      "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\n",
      "       --volume-name rlm-volume-dspy\n",
      "\n",
      "4. Error Pattern Analysis:\n",
      "   $ uv run fleet-rlm run-error-patterns \\\n",
      "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\n",
      "       --volume-name rlm-volume-dspy\n",
      "\n",
      "5. Execution Trajectory:\n",
      "   $ uv run fleet-rlm run-trajectory \\\n",
      "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt\n",
      "\n",
      "6. Custom Tool Demo:\n",
      "   $ uv run fleet-rlm run-custom-tool \\\n",
      "       --text \"Extract emails from [email protected] and [email protected]\"\n",
      "\n",
      "7. Check Modal Secrets:\n",
      "   $ uv run fleet-rlm check-secret\n",
      "   $ uv run fleet-rlm check-secret-key --key DSPY_LLM_API_KEY\n",
      "\n",
      "Volume Setup (One-time):\n",
      "   $ uv run modal volume create rlm-volume-dspy\n",
      "\n",
      "============================================================\n",
      "All Examples Support --volume-name Parameter\n",
      "============================================================\n",
      "Use --volume-name to enable persistent storage for:\n",
      "  • Document caching\n",
      "  • Intermediate results\n",
      "  • Data sharing between runs\n",
      "\n",
      "Data is persisted at /data/ inside the Modal sandbox\n",
      "and survives sandbox shutdown using Modal Volumes V2\n"
     ]
    }
   ],
   "source": [
    "# CLI Usage Examples\n",
    "print(\"=\"*60)\n",
    "print(\"CLI Commands - Using the Package\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "The fleet-rlm package provides a Typer CLI with the following commands:\n",
    "\n",
    "1. Basic Code Generation:\n",
    "   $ uv run fleet-rlm run-basic \\\\\n",
    "       --question \"What are the first 10 Fibonacci numbers?\" \\\\\n",
    "       --volume-name rlm-volume-dspy\n",
    "\n",
    "2. Architecture Extraction:\n",
    "   $ uv run fleet-rlm run-architecture \\\\\n",
    "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\\\n",
    "       --query \"Extract all modules and optimizers\" \\\\\n",
    "       --volume-name rlm-volume-dspy\n",
    "\n",
    "3. API Endpoint Extraction:\n",
    "   $ uv run fleet-rlm run-api-endpoints \\\\\n",
    "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\\\n",
    "       --volume-name rlm-volume-dspy\n",
    "\n",
    "4. Error Pattern Analysis:\n",
    "   $ uv run fleet-rlm run-error-patterns \\\\\n",
    "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt \\\\\n",
    "       --volume-name rlm-volume-dspy\n",
    "\n",
    "5. Execution Trajectory:\n",
    "   $ uv run fleet-rlm run-trajectory \\\\\n",
    "       --docs-path rlm_content/dspy-knowledge/dspy-doc.txt\n",
    "\n",
    "6. Custom Tool Demo:\n",
    "   $ uv run fleet-rlm run-custom-tool \\\\\n",
    "       --text \"Extract emails from [email protected] and [email protected]\"\n",
    "\n",
    "7. Check Modal Secrets:\n",
    "   $ uv run fleet-rlm check-secret\n",
    "   $ uv run fleet-rlm check-secret-key --key DSPY_LLM_API_KEY\n",
    "\n",
    "Volume Setup (One-time):\n",
    "   $ uv run modal volume create rlm-volume-dspy\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"All Examples Support --volume-name Parameter\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Use --volume-name to enable persistent storage for:\")\n",
    "print(\"  • Document caching\")\n",
    "print(\"  • Intermediate results\")\n",
    "print(\"  • Data sharing between runs\")\n",
    "print()\n",
    "print(\"Data is persisted at /data/ inside the Modal sandbox\")\n",
    "print(\"and survives sandbox shutdown using Modal Volumes V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1bb07b",
   "metadata": {},
   "source": [
    "## 11. Custom Tools\n",
    "\n",
    "RLM supports custom Python tools that the generated code can call. Below we define a `regex_extract()` tool and use it in an RLM signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "custom-tools",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/07 23:36:36 INFO dspy.predict.rlm: RLM iteration 1/15\n",
      "Reasoning: I will start by exploring the content of `docs` to understand its structure and how headers and code blocks are formatted. This will help me craft accurate regex patterns. I'll print the first 2000 characters and check for common markdown patterns.\n",
      "Code:\n",
      "```python\n",
      "print(f\"Total length: {len(docs)}\")\n",
      "print(\"First 2000 characters:\")\n",
      "print(docs[:2000])\n",
      "```\n",
      "2026/02/07 23:36:38 INFO dspy.predict.rlm: RLM iteration 2/15\n",
      "Reasoning: The initial exploration shows a directory structure but not the actual markdown content yet. I need to see more of the document to find the markdown headers (e.g., `# Header`, `## Header`) and code blocks (e.g., ` ```python ... ``` `). I'll print a segment from the middle and the end of the string to see where the actual content starts.\n",
      "Code:\n",
      "```python\n",
      "# The first part was just a directory tree. Let's look further in.\n",
      "print(\"Middle segment (4000-6000):\")\n",
      "print(docs[4000:6000])\n",
      "print(\"\\nEnd segment (8000-10000):\")\n",
      "print(docs[8000:])\n",
      "```\n",
      "2026/02/07 23:36:38 INFO dspy.predict.rlm: RLM iteration 3/15\n",
      "Reasoning: The document contains a directory listing followed by a series of file contents separated by `================================================` dividers. My goal is to extract markdown headers and code blocks.\n",
      "\n",
      "Looking at the content:\n",
      "1. Headers use the standard `#` and `##` format (e.g., `# dspy.Adapter`).\n",
      "2. Code blocks in markdown usually use ` ``` ` or sometimes indented blocks or specific tags like `:::`. In this specific document, there are `::: dspy.Adapter` blocks which act as reference documentation, but standard markdown code blocks (triple backticks) are the primary target. I need to scan for both.\n",
      "\n",
      "I will use `regex_extract` to find all matches for:\n",
      "- Headers: `^#+\\s+.+$` (with multiline flag).\n",
      "- Code blocks: ` ```[\\s\\S]*?``` `.\n",
      "\n",
      "I'll start by extracting headers and checking for any standard code blocks in the provided text.\n",
      "Code:\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Extract headers: # Header, ## Header, etc.\n",
      "# Using ^ at the start of lines\n",
      "headers = regex_extract(docs, r\"(?m)^#+\\s+.+$\")\n",
      "\n",
      "# Extract code blocks: ```language ... ```\n",
      "code_blocks = regex_extract(docs, r\"```[\\s\\S]*?```\")\n",
      "\n",
      "print(f\"Found {len(headers)} headers.\")\n",
      "print(f\"Found {len(code_blocks)} code blocks.\")\n",
      "\n",
      "if headers:\n",
      "    print(\"Sample headers:\", headers[:5])\n",
      "if code_blocks:\n",
      "    print(\"Sample code blocks:\", code_blocks[:2])\n",
      "else:\n",
      "    # If no triple backtick blocks, maybe they use other formats or I need to look closer.\n",
      "    # The preview showed some yaml in .pre-commit-config.yaml and ::: blocks.\n",
      "    print(\"No triple-backtick code blocks found yet. Checking for other patterns...\")\n",
      "```\n",
      "2026/02/07 23:36:39 INFO dspy.predict.rlm: RLM iteration 4/15\n",
      "Reasoning: The previous extraction found headers like `# dspy.Adapter` but zero triple-backtick code blocks. However, looking at the initial `docs` preview, there were code-like sections in the \"Directory structure\" and within `.pre-commit-config.yaml`. While the directory tree isn't a markdown code block, the YAML content under `FILE: .pre-commit-config.yaml` and the `::: dspy.Adapter` blocks are significant structural elements. \n",
      "\n",
      "I need to:\n",
      "1. Re-verify if any triple-backtick blocks exist in the parts of `docs` I haven't printed yet.\n",
      "2. Check for the `:::` blocks which seem to be used for API documentation.\n",
      "3. Check for the YAML content which, while not in backticks in this raw dump, represents code-like configuration.\n",
      "4. Finalize the structure summary based on the directory-tree start and the file-by-file content.\n",
      "\n",
      "I will perform a more thorough search for any backticks and also capture the `:::` blocks.\n",
      "Code:\n",
      "```python\n",
      "# Check for any backticks at all to see if my regex missed them\n",
      "backtick_check = regex_extract(docs, r\"```\")\n",
      "print(f\"Backtick occurrences: {len(backtick_check)}\")\n",
      "\n",
      "# Extract the ::: blocks as they represent the main \"code/config\" content in this doc\n",
      "api_blocks = regex_extract(docs, r\"(?s)::: dspy\\..*?:::\")\n",
      "print(f\"Found {len(api_blocks)} API reference blocks (:::).\")\n",
      "\n",
      "# Also look for the file dividers to understand the document structure better\n",
      "files = regex_extract(docs, r\"FILE: (.*)\")\n",
      "print(f\"Files documented: {files}\")\n",
      "\n",
      "# Let's see one of the ::: blocks to decide if it counts as a code block for the task\n",
      "if api_blocks:\n",
      "    print(\"Sample API block:\")\n",
      "    print(api_blocks[0])\n",
      "\n",
      "# Just in case, check for indented blocks (4 spaces) following a paragraph\n",
      "# though usually headers/triple-backticks are the target.\n",
      "```\n",
      "2026/02/07 23:36:39 INFO dspy.predict.rlm: RLM iteration 5/15\n",
      "Reasoning: The exploration reveals that while the document is a compilation of markdown files, it currently contains zero standard triple-backtick (```) code blocks. Instead, it uses `::: dspy.ClassName` blocks to define API documentation. The headers are standard markdown `#` headers. \n",
      "\n",
      "I will:\n",
      "1. Extract all markdown headers using `regex_extract`.\n",
      "2. Treat the `::: ... :::` blocks as \"code blocks\" in the context of this documentation extraction, as they contain structured configuration/code parameters for the API.\n",
      "3. Check if there are any other blocks that should be included (like the YAML in `.pre-commit-config.yaml`). Looking at the instructions, \"find all code blocks\" usually implies markdown code blocks. Since there are no backticks, I will include the `:::` blocks and the YAML configuration content which is presented as code.\n",
      "4. Synthesize the structure summary.\n",
      "\n",
      "Let's do one final sweep to ensure I haven't missed any headers or structured blocks in the middle of the document.\n",
      "Code:\n",
      "```python\n",
      "# Extract all markdown headers\n",
      "headers = regex_extract(docs, r\"(?m)^#+\\s+.+$\")\n",
      "\n",
      "# Extract the API reference blocks (:::) as they represent the code/structure here\n",
      "api_blocks = regex_extract(docs, r\"(?s):::\\s+dspy\\..*?:::\")\n",
      "\n",
      "# Extract YAML content from the .pre-commit-config.yaml section\n",
      "# It starts after the divider and ends before the next FILE divider or end of doc\n",
      "yaml_content = regex_extract(docs, r\"FILE: \\.pre-commit-config\\.yaml\\n=+\\n([\\s\\S]*?)(?=\\n=+)\")\n",
      "\n",
      "# Combine API blocks and the YAML content into code_blocks\n",
      "code_blocks = yaml_content + api_blocks\n",
      "\n",
      "print(f\"Headers found: {headers}\")\n",
      "print(f\"Code blocks found: {len(code_blocks)}\")\n",
      "\n",
      "# Prepare structure summary\n",
      "summary = \"The document consists of a directory tree followed by specific file contents for the stanfordnlp-dspy project. It includes API documentation for dspy.Adapter and dspy.ChatAdapter using custom ::: blocks and configuration files like .pre-commit-config.yaml.\"\n",
      "\n",
      "SUBMIT(headers, code_blocks, summary)\n",
      "```\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 3 headers\n",
      "Found 2 code blocks\n",
      "\n",
      "Structure: The document consists of a directory tree followed by specific file contents for the stanfordnlp-dspy project. It includes API documentation for dspy.Adapter and dspy.ChatAdapter using custom ::: bloc...\n"
     ]
    }
   ],
   "source": [
    "# Define a custom tool function\n",
    "def regex_extract(text: str, pattern: str, flags: int = 0) -> list:\n",
    "    \"\"\"Extract all matches of regex pattern from text.\n",
    "    \n",
    "    Args:\n",
    "        text: Source text to search\n",
    "        pattern: Regex pattern string\n",
    "        flags: Regex flags (e.g., re.IGNORECASE=2)\n",
    "    \n",
    "    Returns:\n",
    "        List of match groups or full matches\n",
    "    \"\"\"\n",
    "    import re\n",
    "    compiled = re.compile(pattern, flags)\n",
    "    matches = compiled.findall(text)\n",
    "    return matches\n",
    "\n",
    "\n",
    "class ExtractWithCustomTool(dspy.Signature):\n",
    "    \"\"\"Extract specific patterns using custom regex tool.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Use regex_extract() to find all markdown headers\n",
    "    2. Use regex_extract() to find all code blocks\n",
    "    3. Summarize structure\n",
    "    \"\"\"\n",
    "    \n",
    "    docs: str = dspy.InputField(desc=\"Documentation to analyze\")\n",
    "    headers: list = dspy.OutputField(desc=\"All markdown headers found\")\n",
    "    code_blocks: list = dspy.OutputField(desc=\"All code block languages found\")\n",
    "    structure_summary: str = dspy.OutputField(desc=\"Summary of document structure\")\n",
    "\n",
    "\n",
    "interpreter = ModalInterpreter(image=SANDBOX_IMAGE, app_name=MODAL_APP_NAME)\n",
    "\n",
    "rlm = dspy.RLM(\n",
    "    signature=ExtractWithCustomTool,\n",
    "    interpreter=interpreter,\n",
    "    tools=[regex_extract],  # Pass custom tool here\n",
    "    max_iterations=15,\n",
    "    max_llm_calls=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    result = rlm(docs=dspy_docs[:10000])  # First 10KB for demo\n",
    "    print(f\"\\nFound {len(result.headers)} headers\")\n",
    "    print(f\"Found {len(result.code_blocks)} code blocks\")\n",
    "    print(f\"\\nStructure: {result.structure_summary[:200]}...\")\n",
    "finally:\n",
    "    interpreter.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-comparison",
   "metadata": {},
   "source": [
    "## 12. RLM vs Direct LLM Comparison\n",
    "\n",
    "| Aspect | Direct LLM | RLM |\n",
    "|--------|-----------|-----|\n",
    "| **Context size** | ~128K tokens | Virtually unlimited |\n",
    "| **Attention** | Dilutes over long context | Focused (code selects snippets) |\n",
    "| **Cost** | High (all tokens in context) | Lower (targeted sub-LLM calls) |\n",
    "| **Accuracy** | Lower on long docs | Higher (targeted analysis) |\n",
    "| **Verifiability** | Black box | Transparent (full trajectory) |\n",
    "| **Tool use** | Limited | Full Python + custom tools |\n",
    "| **Iterative refinement** | Manual (chat) | Automated (code loops) |\n",
    "| **Structured output** | Prompt-dependent | Type-enforced via Signature |\n",
    "\n",
    "### When to use RLM:\n",
    "- Documents > 50KB\n",
    "- Need structured extraction (lists, dicts, nested data)\n",
    "- Multi-step analysis (filter → extract → validate)\n",
    "- Need programmatic validation or computation\n",
    "- Repetitive analysis across many documents\n",
    "\n",
    "### When NOT to use RLM:\n",
    "- Simple Q&A on short text (< 1K tokens)\n",
    "- Creative writing or brainstorming\n",
    "- Tasks that don't benefit from code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-best-practices",
   "metadata": {},
   "source": [
    "## 13. RLM Best Practices\n",
    "\n",
    "### Signature Design\n",
    "\n",
    "1. **Describe the strategy** in the docstring:\n",
    "   ```python\n",
    "   class MySignature(dspy.Signature):\n",
    "       \"\"\"Extract X from Y.\n",
    "       \n",
    "       Strategy:\n",
    "       1. Search for headers containing 'X'\n",
    "       2. Use llm_query() on matching sections\n",
    "       3. Aggregate results\n",
    "       \"\"\"\n",
    "   ```\n",
    "\n",
    "2. **Use typed output fields** — `list`, `dict`, `int` guide the code:\n",
    "   ```python\n",
    "   items: list = dspy.OutputField(desc=\"List of found items\")\n",
    "   count: int = dspy.OutputField(desc=\"Total count\")\n",
    "   ```\n",
    "\n",
    "### Tuning Parameters\n",
    "\n",
    "| Parameter | Typical Range | Notes |\n",
    "|-----------|---------------|-------|\n",
    "| `max_iterations` | 10-50 | Complex docs need more iterations |\n",
    "| `max_llm_calls` | 20-100 | Primary cost control |\n",
    "| `max_output_chars` | 10K-100K | Prevents output flooding |\n",
    "\n",
    "### Debugging Workflow\n",
    "\n",
    "1. **Start with `verbose=True`**: See real-time reasoning and code\n",
    "2. **Inspect `result.trajectory`**: Full execution history\n",
    "3. **Test on subsets**: Use `docs[:5000]` before full runs\n",
    "4. **Check sandbox logs**: Modal shows actual execution\n",
    "5. **Validate tools**: Test custom tools independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-conclusion",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "This notebook demonstrated the full capabilities of **dspy.RLM**:\n",
    "\n",
    "1. **Basic code generation** - LLM writes and executes Python\n",
    "2. **Long document analysis** - Process 80KB+ documents efficiently\n",
    "3. **Parallel processing** - `llm_query_batched()` for speed\n",
    "4. **Stateful reasoning** - Multi-step workflows with persistent variables\n",
    "5. **Trajectory inspection** - Full transparency into reasoning\n",
    "6. **Persistent storage** - Modal Volumes V2 for caching and persistence\n",
    "7. **Custom tools** - Extend sandbox capabilities with user-defined functions\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- RLM treats long context as an **environment**, not input\n",
    "- Code navigates data; `llm_query()` understands semantics\n",
    "- The **trajectory** provides unprecedented observability\n",
    "- **Modal Volumes V2** enable persistent storage across sandbox sessions\n",
    "- All capabilities are available via both notebook and CLI (`fleet-rlm`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleet-rlm-dspy (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
