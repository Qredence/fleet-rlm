{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: DSPy ReAct Agent with fleet-rlm\n",
    "\n",
    "Audience:\n",
    "- Developers exploring the `fleet-rlm` interactive ReAct agent APIs.\n",
    "\n",
    "Prerequisites:\n",
    "- `uv sync --extra dev --extra interactive`\n",
    "- `.env` configured with planner LM settings\n",
    "- Modal auth and `LITELLM` secret configured\n",
    "\n",
    "Learning goals:\n",
    "- Build and inspect `RLMReActChatAgent`\n",
    "- Run one sync turn and one streaming turn\n",
    "- Inspect history/doc state and register a custom tool safely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "1. Setup and environment diagnostics\n",
    "2. Instantiate agent in a context manager\n",
    "3. Run synchronous chat turn\n",
    "4. Run streaming chat turn (`iter_chat_turn_stream`)\n",
    "5. Inspect state and documents\n",
    "6. Add a custom tool (exercise scaffold)\n",
    "7. Troubleshooting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cwd\": \"/Users/zocho/.codex/worktrees/396e/fleet-rlm-dspy/notebooks\",\n",
      "  \"doc_exists\": false,\n",
      "  \"doc_path\": \"rlm_content/dspy-knowledge/dspy-doc.txt\",\n",
      "  \"secret_name\": \"LITELLM\",\n",
      "  \"run_live_calls\": true,\n",
      "  \"has_dspy_llm_api_key_env\": true,\n",
      "  \"has_dspy_lm_model_env\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "from fleet_rlm.runners import build_react_chat_agent\n",
    "from fleet_rlm.react_agent import list_react_tool_names\n",
    "\n",
    "DOC_PATH = Path('rlm_content/dspy-knowledge/dspy-doc.txt')\n",
    "SECRET_NAME = os.getenv('FLEET_RLM_SECRET', 'LITELLM')\n",
    "TIMEOUT = 900\n",
    "RUN_LIVE_CALLS = True  # Set True only after Modal auth + secret setup.\n",
    "\n",
    "info = {\n",
    "    'cwd': str(Path.cwd()),\n",
    "    'doc_exists': DOC_PATH.exists(),\n",
    "    'doc_path': str(DOC_PATH),\n",
    "    'secret_name': SECRET_NAME,\n",
    "    'run_live_calls': RUN_LIVE_CALLS,\n",
    "    'has_dspy_llm_api_key_env': bool(os.getenv('DSPY_LLM_API_KEY')),\n",
    "    'has_dspy_lm_model_env': bool(os.getenv('DSPY_LM_MODEL')),\n",
    "}\n",
    "print(json.dumps(info, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Build an Agent (Safe by Default)\n",
    "\n",
    "This cell shows the exact `build_react_chat_agent(...)` usage.\n",
    "\n",
    "By default (`RUN_LIVE_CALLS=False`) it does not start Modal sandboxes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 13 tools\n",
      "['load_document', 'set_active_document', 'list_documents', 'chunk_host', 'chunk_sandbox', 'parallel_semantic_map', 'analyze_long_document', 'summarize_long_document', 'extract_from_logs', 'read_buffer', 'clear_buffer', 'save_buffer_to_volume']\n"
     ]
    }
   ],
   "source": [
    "if RUN_LIVE_CALLS:\n",
    "    with build_react_chat_agent(\n",
    "        docs_path=DOC_PATH if DOC_PATH.exists() else None,\n",
    "        react_max_iters=10,\n",
    "        rlm_max_iterations=30,\n",
    "        rlm_max_llm_calls=50,\n",
    "        timeout=TIMEOUT,\n",
    "        secret_name=SECRET_NAME,\n",
    "    ) as agent:\n",
    "        tool_names = list_react_tool_names(agent.react_tools)\n",
    "        print(f'Loaded {len(tool_names)} tools')\n",
    "        print(tool_names[:12])\n",
    "else:\n",
    "    print('Skipping live agent build. Set RUN_LIVE_CALLS=True to run this step.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Run a Synchronous Turn\n",
    "\n",
    "`chat_turn(...)` returns a dictionary with `assistant_response`, `trajectory`, and `history_turns`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant_response:\n",
      "\n",
      "I am unable to summarize the project at this time because I cannot find a documentation file (such as `README.md` or `project.txt`) in the current environment. If you can provide the text or specify the correct file path, I would be happy to summarize it for you in 3 bullet points.\n",
      "\n",
      "meta:\n",
      "{'history_turns': 1, 'trajectory_keys': ['thought_0', 'tool_name_0', 'tool_args_0', 'observation_0', 'thought_1', 'tool_name_1', 'tool_args_1', 'observation_1', 'thought_2', 'tool_name_2']}\n"
     ]
    }
   ],
   "source": [
    "if RUN_LIVE_CALLS:\n",
    "    with build_react_chat_agent(\n",
    "        docs_path=DOC_PATH if DOC_PATH.exists() else None,\n",
    "        timeout=TIMEOUT,\n",
    "        secret_name=SECRET_NAME,\n",
    "    ) as agent:\n",
    "        result = agent.chat_turn('Summarize what this project does in 3 bullet points.')\n",
    "        print('assistant_response:')\n",
    "        print()\n",
    "        print(result['assistant_response'])\n",
    "        print()\n",
    "        print('meta:')\n",
    "        print({\n",
    "            'history_turns': result.get('history_turns'),\n",
    "            'trajectory_keys': list((result.get('trajectory') or {}).keys())[:10],\n",
    "        })\n",
    "else:\n",
    "    print('Skipping sync turn. Toggle RUN_LIVE_CALLS=True once your environment is configured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Run a Streaming Turn\n",
    "\n",
    "This demonstrates `iter_chat_turn_stream(...)` and collects:\n",
    "- assistant tokens\n",
    "- status lines\n",
    "- reasoning steps (if trace enabled)\n",
    "- tool timeline + final payload\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant_response:\n",
      "\n",
      "Here are the key interactive commands available for managing documents and data processing:\n",
      "\n",
      "### **Document Management**\n",
      "*   **`load_document`**: Loads a text document from the host filesystem into the agent's document memory.\n",
      "*   **`set_active_document`**: Sets a specific loaded document as the \"active\" one for subsequent operations.\n",
      "*   **`list_documents`**: Lists all currently loaded document aliases and identifies the active document.\n",
      "*   **`load_text_from_volume`**: Loads text from a persistent Modal Volume into the host-side document memory.\n",
      "\n",
      "### **Text Processing & Chunking**\n",
      "*   **`chunk_host`**: Splits a document on the host using strategies like size, headers, timestamps, or JSON keys.\n",
      "*   **`chunk_sandbox`**: Chunks the active document inside the sandbox environment and stores the results in a buffer.\n",
      "*   **`parallel_semantic_map`**: Runs parallel semantic analysis over text chunks using batched LLM queries.\n",
      "\n",
      "### **Analysis & Extraction**\n",
      "*   **`analyze_long_document`**: Performs deep analysis on extensive documents.\n",
      "*   **`summarize_long_document`**: Generates a summary for a long document.\n",
      "*   **`extract_from_logs`**: Extracts structured data patterns from log files.\n",
      "\n",
      "### **Buffer & Storage Operations**\n",
      "*   **`read_buffer`**: Retrieves the full contents of a sandbox buffer.\n",
      "*   **`clear_buffer`**: Clears a specific sandbox buffer (or all buffers if no name is specified).\n",
      "*   **`save_buffer_to_volume`**: Persists a sandbox buffer to Modal Volume storage as a JSON file.\n",
      "\n",
      "### **System**\n",
      "*   **`finish`**: Signals that the task is complete and provides a final response.\n",
      "\n",
      "summary:\n",
      "{'status_count': 4, 'reasoning_count': 8, 'tool_events': [], 'terminal_kind': 'final', 'history_turns': 1}\n"
     ]
    }
   ],
   "source": [
    "if RUN_LIVE_CALLS:\n",
    "    with build_react_chat_agent(\n",
    "        docs_path=DOC_PATH if DOC_PATH.exists() else None,\n",
    "        timeout=TIMEOUT,\n",
    "        secret_name=SECRET_NAME,\n",
    "    ) as agent:\n",
    "        assembled_tokens = []\n",
    "        statuses = []\n",
    "        reasoning = []\n",
    "        tools = []\n",
    "        terminal_event = None\n",
    "\n",
    "        for event in agent.iter_chat_turn_stream(\n",
    "            'List the key interactive commands and what each does.',\n",
    "            trace=True,\n",
    "        ):\n",
    "            if event.kind == 'assistant_token':\n",
    "                assembled_tokens.append(event.text)\n",
    "            elif event.kind == 'status':\n",
    "                statuses.append(event.text)\n",
    "            elif event.kind == 'reasoning_step':\n",
    "                reasoning.append(event.text)\n",
    "            elif event.kind in {'tool_call', 'tool_result'}:\n",
    "                tools.append(event.text)\n",
    "            elif event.kind in {'final', 'cancelled', 'error'}:\n",
    "                terminal_event = event\n",
    "\n",
    "        final_text = ''.join(assembled_tokens).strip()\n",
    "        print('assistant_response:')\n",
    "        print()\n",
    "        print(final_text)\n",
    "        print()\n",
    "        print('summary:')\n",
    "        print({\n",
    "            'status_count': len(statuses),\n",
    "            'reasoning_count': len(reasoning),\n",
    "            'tool_events': tools[:10],\n",
    "            'terminal_kind': terminal_event.kind if terminal_event else None,\n",
    "            'history_turns': (terminal_event.payload.get('history_turns') if terminal_event else None),\n",
    "        })\n",
    "else:\n",
    "    print('Skipping streaming turn. Toggle RUN_LIVE_CALLS=True to stream real events.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - State and Memory Inspection\n",
    "\n",
    "You can inspect in-memory chat state and loaded documents directly from the agent API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"history_messages\": 0,\n",
      "  \"documents\": {\n",
      "    \"documents\": [],\n",
      "    \"active_alias\": null,\n",
      "    \"cache_size\": 0,\n",
      "    \"cache_limit\": 100\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if RUN_LIVE_CALLS:\n",
    "    with build_react_chat_agent(\n",
    "        docs_path=DOC_PATH if DOC_PATH.exists() else None,\n",
    "        timeout=TIMEOUT,\n",
    "        secret_name=SECRET_NAME,\n",
    "    ) as agent:\n",
    "        if DOC_PATH.exists():\n",
    "            _ = agent.load_document(str(DOC_PATH), alias='active')\n",
    "\n",
    "        snapshot = {\n",
    "            'history_messages': len(agent.history.messages),\n",
    "            'documents': agent.list_documents(),\n",
    "        }\n",
    "        print(json.dumps(snapshot, indent=2, default=str))\n",
    "else:\n",
    "    print('No live state to inspect yet. Toggle RUN_LIVE_CALLS=True when ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Register a tiny custom tool that echoes a topic string.\n",
    "2. Ask the agent to call that tool in a short request.\n",
    "3. Inspect `history.messages` after the turn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'tool_name': 'echo_topic'}\n",
      "I have successfully executed the `echo_topic` tool with the topic \"agent-observability\". The tool returned a confirmation note indicating this was part of a custom tool demo.\n"
     ]
    }
   ],
   "source": [
    "def echo_topic(topic: str) -> dict[str, str]:\n",
    "    return {'topic': topic, 'note': 'custom tool demo'}\n",
    "\n",
    "if RUN_LIVE_CALLS:\n",
    "    with build_react_chat_agent(\n",
    "        docs_path=DOC_PATH if DOC_PATH.exists() else None,\n",
    "        timeout=TIMEOUT,\n",
    "        secret_name=SECRET_NAME,\n",
    "    ) as agent:\n",
    "        print(agent.register_extra_tool(echo_topic))\n",
    "        out = agent.chat_turn('Use the echo_topic tool with topic=agent-observability.')\n",
    "        print(out['assistant_response'])\n",
    "else:\n",
    "    print('Exercise scaffold ready. Set RUN_LIVE_CALLS=True to execute.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfalls / Troubleshooting\n",
    "\n",
    "- If Modal calls fail, run `uv run modal setup` and verify auth.\n",
    "- If LLM access fails, run `uv run fleet-rlm check-secret` and confirm `LITELLM` keys exist.\n",
    "- If document loading fails, confirm `DOC_PATH` exists.\n",
    "- If streaming is unavailable for your backend, `chat_turn_stream` falls back to non-streaming behavior.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fleet-rlm (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
